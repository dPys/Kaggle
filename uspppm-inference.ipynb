{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc\nimport glob\nimport spacy\nimport nltk\nimport random\nimport itertools\nimport torch\nimport unicodedata\nimport datasets, transformers\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom nltk.corpus import stopwords, wordnet\nfrom joblib import dump\nimport scipy as sp\nfrom scipy import stats\nfrom itertools import groupby\nfrom joblib import parallel_backend\nfrom sklearn import linear_model, decomposition\nfrom collections import OrderedDict\nfrom operator import itemgetter\nfrom sklearn import metrics\nfrom joblib import Parallel, delayed\nfrom transformers import TrainingArguments, Trainer, AutoModelForSequenceClassification, AutoTokenizer\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, FunctionTransformer, OneHotEncoder, LabelEncoder\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.compose import TransformedTargetRegressor\nfrom sklearn.ensemble import RandomForestRegressor, IsolationForest\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.model_selection import GridSearchCV, cross_validate, cross_val_score, train_test_split, KFold\nfrom sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin, clone, RegressorMixin\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import r2_score\nfrom spacy.tokenizer import Tokenizer\nfrom spacy.matcher import PhraseMatcher\nfrom spacy.lang.char_classes import CONCAT_QUOTES, LIST_ELLIPSES, LIST_ICONS, ALPHA, ALPHA_LOWER, ALPHA_UPPER\nfrom spacy.util import compile_infix_regex\n# from scispacy.abbreviation import AbbreviationDetector\nfrom spacy.pipeline import EntityRecognizer\n\ntry:\n    from sklearn.utils._testing import ignore_warnings\nexcept:\n    from sklearn.utils.testing import ignore_warnings\nfrom sklearn.exceptions import ConvergenceWarning\n\n%env TOKENIZERS_PARALLELISM=true\n\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"_uuid":"a942c950-ef86-481e-9bdd-4fc8ac222320","_cell_guid":"62ad6f3d-b227-4aaf-93bb-ca4860556fd2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T07:07:02.118426Z","iopub.execute_input":"2022-06-20T07:07:02.118891Z","iopub.status.idle":"2022-06-20T07:07:02.148233Z","shell.execute_reply.started":"2022-06-20T07:07:02.118845Z","shell.execute_reply":"2022-06-20T07:07:02.145759Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"env: TOKENIZERS_PARALLELISM=true\n","output_type":"stream"}]},{"cell_type":"code","source":"INPUT_DIR = '../input/us-patent-phrase-to-phrase-matching/'\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T07:07:02.151056Z","iopub.execute_input":"2022-06-20T07:07:02.151489Z","iopub.status.idle":"2022-06-20T07:07:02.160212Z","shell.execute_reply.started":"2022-06-20T07:07:02.151419Z","shell.execute_reply":"2022-06-20T07:07:02.159016Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"nlp = spacy.load('en_core_web_lg')\n# nlp.add_pipe(\"abbreviation_detector\")\nre_token_match = spacy.tokenizer._get_regex_pattern(nlp.Defaults.token_match)","metadata":{"_uuid":"561bcb8c-31c6-4e52-b925-97112600781b","_cell_guid":"147479a7-c7c8-472f-bfdd-2c560020546b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T07:07:02.162092Z","iopub.execute_input":"2022-06-20T07:07:02.163253Z","iopub.status.idle":"2022-06-20T07:07:07.663372Z","shell.execute_reply.started":"2022-06-20T07:07:02.163205Z","shell.execute_reply":"2022-06-20T07:07:07.662417Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.simplefilter('ignore')\n\npd.set_option('display.precision', 4)\n# pd.set_option('display.max_rows', 500)\n# pd.set_option('display.max_columns', 500)\n# pd.set_option('display.width', 1000)\n\ncm = sns.light_palette('green', as_cmap=True)\nprops_param = \"color:white; font-weight:bold; background-color:green;\"\n\nCUSTOM_SEED = 42\nCUSTOM_BATCH = 24\n\n# Stopwords and infixes\nADDITIONAL_STOPWORDS = ['one or more', 'a', 'needn', 'a', 'not', 'able', 'never', 'about', 'needn’t', 'accordance', 'now', 'often', 'above', 'no', 'according', 'of', 'mentioned', 'others', 'after', 'nor', 'all', 'on', 'accordingly', 'otherwise', 'again', 'not', 'also', 'onto', 'across', 'overall', 'against', 'now', 'an', 'or', 'along', 'rather', 'ain', 'o', 'and', 'other', 'already', 'remarkably', 'all', 'of', 'another', 'particularly', 'alternatively', 'significantly', 'am', 'off', 'are', 'preferably', 'always', 'simply', 'an', 'on', 'as', 'preferred', 'among', 'sometimes', 'and', 'once', 'at', 'present', 'and/or', 'specifically', 'any', 'only', 'be', 'provide', 'anything', 'straight', 'are', 'or', 'because', 'provided', 'anywhere', 'forward', 'aren', 'other', 'been', 'provides', 'better', 'substantially', 'aren’t', 'our', 'being', 'relatively', 'disclosure', 'thereafter', 'as', 'ours', 'by', 'respectively', 'due', 'therebetween', 'at', 'ourselves', 'claim', 'said', 'easily', 'therefor', 'be', 'out', 'comprises', 'comprising', 'should', 'easy', 'therefrom', 'because', 'over', 'since', 'e.g', 'therein', 'been', 'own', 'could', 'some', 'either', 'thereinto', 'before', 're', 'described', 'such', 'elsewhere', 'thereon', 'being', 's', 'desired', 'suitable', 'enough', 'therethrough', 'below', 'same', 'do', 'than', 'especially', 'therewith', 'between', 'shan', 'does', 'that', 'essentially', 'together', 'both', 'shan’t', 'each', 'the', 'et', 'al', 'toward', 'but', 'she', 'embodiment', 'their', 'etc', 'towards', 'by', 'she’s', 'fig', 'then', 'eventually', 'typical', 'can', 'should', 'figs', 'there', 'excellent', 'upon', 'couldn', 'should’ve', 'for', 'thereby', 'finally', 'via', 'couldn’t', 'shouldn', 'from', 'therefore', 'furthermore', 'vice', 'versa', 'd', 'shouldn’t', 'further', 'thereof', 'good', 'whatever', 'did', 'so', 'generally', 'thereto', 'hence', 'whereas', 'didn', 'some', 'had', 'these', 'he/she', 'whereat', 'didn’t', 'such', 'has', 'they', 'him/her', 'wherever', 'do', 't', 'have', 'this', 'his/her', 'whether', 'does', 'than', 'having', 'those', 'ie', 'whose', 'doesn', 'that', 'herein', 'thus', 'ii', 'within', 'doesn’t', 'that’ll', 'however', 'to', 'iii', 'without', 'doing', 'the', 'if', 'use', 'instead', 'yet', 'don', 'their', 'in', 'various', 'later', 'don’t', 'theirs', 'into', 'was', 'like', 'down', 'them', 'invention', 'were', 'little', 'during', 'themselves', 'is', 'what', 'many', 'each', 'there', 'it', 'when', 'may', 'few', 'these', 'its', 'where', 'meanwhile', 'for', 'they', 'means', 'whereby', 'might', 'from', 'this', 'wherein', 'moreover', 'further', 'those', 'which', 'much', 'had', 'through', 'while', 'must', 'hadn', 'to', 'who', 'hadn’t', 'too', 'will', 'has', 'under', 'with', 'hasn', 'until', 'Would', 'hasn’t', 'up', 'have', 've', 'haven', 'very', 'haven’t', 'was', 'having', 'wasn', 'he', 'wasn’t', 'her', 'we', 'here', 'were', 'hers', 'weren', 'herself', 'weren’t', 'him', 'what', 'himself', 'when', 'his', 'where', 'how', 'which', 'i', 'while', 'if', 'who', 'in', 'whom', 'into', 'why', 'is', 'will', 'isn', 'with', 'isn’t', 'won', 'it', 'won’t', 'it’s', 'wouldn', 'its', 'wouldn’t', 'itself', 'y', 'just', 'you', 'll', 'you’d', 'm', 'you’ll', 'ma', 'you’re', 'me', 'you’ve', 'mightn', 'your', 'mightn’t', 'yours', 'more', 'yourself', 'most', 'yourselves', 'mustn', 'mustn’t', 'my', 'myself']\n\npuncts = ['\\u200d','?', '....','..','...','', ',', '.', '\"', ':', ')', '(', '-', '!', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '*', '+', '\\\\',\n    '•', '~', '£', '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█',\n    '½', 'à', '…', '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓',\n    '—', '‹', '─', '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾',\n    'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø',\n    '¹', '≤', '‡', '√', '!','🅰','🅱']\n\ninfixes = (\n    LIST_ELLIPSES\n    + LIST_ICONS\n    + [\n        r\"(?<=[0-9])[+\\-\\*^](?=[0-9-])\",\n        r\"(?<=[{al}{q}])\\.(?=[{au}{q}])\".format(\n            al=ALPHA_LOWER, au=ALPHA_UPPER, q=CONCAT_QUOTES\n        ),\n        r\"(?<=[{a}]),(?=[{a}])\".format(a=ALPHA),\n        # ✅ Commented out regex that splits on hyphens between letters:\n        # r\"(?<=[{a}])(?:{h})(?=[{a}])\".format(a=ALPHA, h=HYPHENS),\n        r\"(?<=[{a}0-9])[:<>=/](?=[{a}])\".format(a=ALPHA),\n        r'''[-~]'''\n    ]\n)\n\nstopwords = nltk.corpus.stopwords.words('english') + ADDITIONAL_STOPWORDS\n\nprefix_re = spacy.util.compile_prefix_regex(nlp.Defaults.prefixes)\nsuffix_re = spacy.util.compile_suffix_regex(nlp.Defaults.suffixes)\ninfix_re = compile_infix_regex(infixes)\n\ndef customize_tokenizer(nlp):\n    # Adds support to use `-` as the delimiter for tokenization\n    return Tokenizer(nlp.vocab, prefix_search=prefix_re.search,\n                     suffix_search=suffix_re.search,\n                     infix_finditer=infix_re.finditer,\n                     token_match=None\n                    )\n\nnlp.tokenizer = customize_tokenizer(nlp)","metadata":{"_uuid":"8238d081-b92b-434a-8b85-4329fbcb278f","_cell_guid":"ba02c35f-90b7-4f80-905b-0391f96f2347","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T07:07:07.666954Z","iopub.execute_input":"2022-06-20T07:07:07.667474Z","iopub.status.idle":"2022-06-20T07:07:07.715919Z","shell.execute_reply.started":"2022-06-20T07:07:07.667413Z","shell.execute_reply":"2022-06-20T07:07:07.714885Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"table = {\n'A': 'Human Necessities',\n'B': 'Operations and Transport',\n'C': 'Chemistry and Metallurgy',\n'D': 'Textiles',\n'E': 'Fixed Constructions',\n'F': 'Mechanical Engineering',\n'G': 'Physics',\n'H': 'Electricity',\n'Y': 'Emerging Cross-Sectional Technologies'\n}","metadata":{"_uuid":"102bd6d4-c302-4fde-995f-decacdbce996","_cell_guid":"d97adb40-4f30-487b-aa22-c14a50be0f17","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T07:07:07.717571Z","iopub.execute_input":"2022-06-20T07:07:07.718748Z","iopub.status.idle":"2022-06-20T07:07:07.727465Z","shell.execute_reply.started":"2022-06-20T07:07:07.718700Z","shell.execute_reply":"2022-06-20T07:07:07.726237Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"def remove_from_list(x, stuff_to_remove) -> list:\n    for item in stuff_to_remove:\n        # Making sure to iterate through the entire token\n        for i,token in enumerate(x):\n            if item == token:\n                del x[i]\n    return x\n\ndef Remove_Duplicates(text_in):\n    return re.sub(r\"\\b(\\w+)(?:\\W\\1\\b)+\", r\"\\1\", text_in, flags=re.IGNORECASE)\n\n\ndef remove_consecutive_nums(text):\n    # Remove any chunks of consecutive numbers\n    number_strings = re.findall(r'\\d+[ \\t]\\d+', text)\n    ind_num_strings = []\n    for j in number_strings:\n        x = [int(i) for i in j.split()]\n        ind_num_strings.append(x)\n\n    flat_num_list = [item for sublist in ind_num_strings for item in sublist]\n\n    for i in flat_num_list:\n        j=re.sub(r'\\d+','',str(i))\n        text = text.replace(str(i),j)\n    return text\n\n\ndef basic_clean(text_list, infixes, stopwords):\n    \"\"\"\n    A simple function to clean up the data. All the words that\n    are not designated as a stop word is then lemmatized after\n    encoding and basic regex parsing are performed.\n    \"\"\"\n\n    text_list_clean = []\n    for text in text_list:\n        text = re.sub(r'[\\)\\(\\.\\,\\;\\\\\\?\\&\\%\\!\\+\\-]', '', re.sub(r'[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f\\x7f-\\xff\\xad\\x0c6§\\\\\\£\\Â*_<>\"\"⎫•{}Γ~]', ' ', str(' '.join(re.split('\\s*-\\s*', text)))))\n        if len(text.split(\"  \")) > 1000:\n            text = \" \".join([\"\".join(w.split(\" \")) if len(w.split(' '))>1 else w for w in text.split(\"  \")])\n        text_list_clean.append([i for i in remove_from_list(re.sub('\\s+', ' ', re.sub('\\s\\s+', ' ', re.sub('\\s+\\s+', ' ', Remove_Duplicates(re.sub(r\"\\b(?=[mdclxvii])m{0,4}(cm|cd|d?c{0,3})(xc|xl|l?x{0,3})([ii]x|[ii]v|v?[ii]{0,3})\\b\\.?\", '', (unicodedata.normalize('NFKD', re.sub(' +', ' ', re.sub(r\"\\s+\\s+\",\" \", re.sub(r\"\\\\,\",\",\", re.sub(r\" \\,\",\",\", re.sub(r\"\\\\.\",\".\", re.sub(r\" \\.\",\".\", re.sub(r\"\\(\\s+\\)\",\"\", re.sub(r\"\\(\\)\",\"\", re.sub(r\" \\)\",\"\", re.sub(r\"\\( \",\"\", remove_consecutive_nums(re.sub(r\"\\s+\",\" \", re.sub(r\"([A-z])\\- ([A-z])\", r\"\\1\\2\", re.sub(r'\\s', ' ', text)).replace('\\'','').replace('. .', '.').replace('\\'',''))))))))))))).lower())\n        .encode('ascii', 'ignore')\n        .decode('utf-8', 'ignore')\n        .lower())))))).split(), puncts) if not i.isdigit() or i in stopwords])\n        del text\n\n    return '. '.join(x.strip().capitalize() for x in '. '.join(' '.join([word for word in sent]) for sent in text_list_clean).split('.')) + '.'\n\n\ndef get_cpc_texts():\n    \"\"\"\n    Function taken from Y Nakama's notebook:\n    https://www.kaggle.com/code/yasufuminakama/pppm-deberta-v3-large-baseline-w-w-b-train\n    \"\"\"\n    contexts = []\n    pattern = '[A-Z]\\d+'\n    for file_name in os.listdir('cpc-data/CPCSchemeXML202105'):\n        result = re.findall(pattern, file_name)\n        if result:\n            contexts.append(result)\n    contexts = sorted(set(sum(contexts, [])))\n    results = {}\n    for cpc in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'Y']:\n        with open(f'cpc-data/CPCTitleList202202/cpc-section-{cpc}_20220201.txt') as f:\n            s = f.read()\n        pattern = f'{cpc}\\t\\t.+'\n        result = re.findall(pattern, s)\n        cpc_result = result[0].lstrip(pattern)\n        for context in [c for c in contexts if c[0] == cpc]:\n            pattern = f'{context}\\t\\t.+'\n            result = re.findall(pattern, s)\n            results[context] = cpc_result + \". \" + result[0].lstrip(pattern)\n    return results","metadata":{"_uuid":"d75199e1-2d90-4925-8857-fc15aa97eee9","_cell_guid":"4047b6a7-5604-4be7-ab3c-b02d7ea18512","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T07:07:07.729606Z","iopub.execute_input":"2022-06-20T07:07:07.729942Z","iopub.status.idle":"2022-06-20T07:07:07.760436Z","shell.execute_reply.started":"2022-06-20T07:07:07.729898Z","shell.execute_reply":"2022-06-20T07:07:07.759098Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/us-patent-phrase-to-phrase-matching/train.csv')\ntest = pd.read_csv('../input/us-patent-phrase-to-phrase-matching/test.csv')","metadata":{"_uuid":"f3ffefe0-201e-4750-b043-c76da4bab192","_cell_guid":"4ec8f13b-391a-48c7-a86c-c35526506b16","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T07:07:07.763845Z","iopub.execute_input":"2022-06-20T07:07:07.764468Z","iopub.status.idle":"2022-06-20T07:07:07.855394Z","shell.execute_reply.started":"2022-06-20T07:07:07.764420Z","shell.execute_reply":"2022-06-20T07:07:07.854306Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"train['general_context'] = train['context'].apply(lambda x: table[x[0].upper()])\ntest['general_context'] = test['context'].apply(lambda x: table[x[0].upper()])\n\ntrain = pd.concat([train, pd.get_dummies(train['general_context'])], axis=1)\ntest = pd.concat([test, pd.get_dummies(test['general_context'])], axis=1)\n\ncpc_texts = torch.load(f\"../input/cpc-texts/cpc_texts.pth\")\ntrain['context_text'] = train['context'].map(cpc_texts)\ntest['context_text'] = test['context'].map(cpc_texts)\n\ntrain['section'] = train['context'].astype(str).str[0]\ntrain['classes'] = train['context'].astype(str).str[1:]\ntest['section'] = test['context'].astype(str).str[0]\ntest['classes'] = test['context'].astype(str).str[1:]\n\ntrain['anchor_len'] = train['anchor'].str.split().str.len()\ntrain['target_len'] = train['target'].str.split().str.len()\n\ntest['anchor_len'] = test['anchor'].str.split().str.len()\ntest['target_len'] = test['target'].str.split().str.len()\n\ntrain['num_anchor_stops'] = test['anchor'].str.count('|'.join(stopwords))\ntest['num_anchor_stops'] = test['anchor'].str.count('|'.join(stopwords))\ntrain['num_target_stops'] = test['target'].str.count('|'.join(stopwords))\ntest['num_target_stops'] = test['target'].str.count('|'.join(stopwords))\n\ntrain['dataset'] = 'train'\ntest['dataset'] = 'test'","metadata":{"_uuid":"c05280f7-90a1-49ce-9868-0f03aaff67b9","_cell_guid":"cd06dd39-bba8-4aec-a547-23fe3ec4a32e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T07:07:07.857074Z","iopub.execute_input":"2022-06-20T07:07:07.857417Z","iopub.status.idle":"2022-06-20T07:07:08.096550Z","shell.execute_reply.started":"2022-06-20T07:07:07.857372Z","shell.execute_reply":"2022-06-20T07:07:08.095570Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"train = train.loc[~train.index.duplicated(keep='first')]\ntest = test.loc[~test.index.duplicated(keep='first')]\ntrain = train.reset_index(drop=True)\ntest = test.reset_index(drop=True)\ndf_all = train.append(test)","metadata":{"_uuid":"75838474-5f7f-4ee7-8362-9bc40a853e1b","_cell_guid":"ad17e21f-04a5-43a8-87f3-91a9694e6806","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T07:07:08.098667Z","iopub.execute_input":"2022-06-20T07:07:08.099267Z","iopub.status.idle":"2022-06-20T07:07:08.134102Z","shell.execute_reply.started":"2022-06-20T07:07:08.099218Z","shell.execute_reply":"2022-06-20T07:07:08.133019Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"df_all['anchor_parsed'] = df_all['anchor'].apply(\n    lambda text:\n        \" \".join(\n            token.lemma_ for token in nlp(text)\n                if token.lemma_.lower() not in stopwords and token.is_alpha\n        )\n)\n\ndf_all['target_parsed'] = df_all['target'].apply(\n    lambda text:\n        \" \".join(\n            token.lemma_ for token in nlp(text)\n                if token.lemma_.lower() not in stopwords and token.is_alpha\n        )\n)","metadata":{"_uuid":"f5aeb6b5-62a0-434d-a5d8-b09d05215ac0","_cell_guid":"a2ded0a7-ecc0-4625-9798-b1af9d525c51","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T07:07:08.138846Z","iopub.execute_input":"2022-06-20T07:07:08.139096Z","iopub.status.idle":"2022-06-20T07:15:41.872241Z","shell.execute_reply.started":"2022-06-20T07:07:08.139063Z","shell.execute_reply":"2022-06-20T07:15:41.871210Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"df_all['anchor_nlp'] = df_all.anchor.apply(lambda series: nlp(series))\ndf_all['target_nlp'] = df_all.target.apply(lambda series: nlp(series))\n\ndf_all['anchor_VERB'] = df_all.anchor_nlp.apply(lambda series: len([token for token in series if token.pos_ == 'VERB']))\ndf_all['target_VERB'] = df_all.target_nlp.apply(lambda series: len([token for token in series if token.pos_ == 'VERB']))\n\ndf_all['anchor_NOUN'] = df_all.anchor_nlp.apply(lambda series: len([token for token in series if token.pos_ == 'NOUN']))\ndf_all['target_NOUN'] = df_all.target_nlp.apply(lambda series: len([token for token in series if token.pos_ == 'NOUN']))\n\ndf_all['anchor_DET'] = df_all.anchor_nlp.apply(lambda series: len([token for token in series if token.pos_ == 'DET']))\ndf_all['target_DET'] = df_all.target_nlp.apply(lambda series: len([token for token in series if token.pos_ == 'DET']))\n\ndf_all['anchor_ADJ'] = df_all.anchor_nlp.apply(lambda series: len([token for token in series if token.pos_ == 'ADJ']))\ndf_all['target_ADJ'] = df_all.target_nlp.apply(lambda series: len([token for token in series if token.pos_ == 'ADJ']))\n\ndf_all['anchor_in_target'] = df_all.apply(lambda x: x[\"anchor_parsed\"] in x[\"target\"], axis=1)\ndf_all['target_in_anchor'] = df_all.apply(lambda x: x[\"target_parsed\"] in x[\"anchor\"], axis=1)","metadata":{"_uuid":"eb33244d-de87-45ba-90b9-541980ce4093","_cell_guid":"4fb10eae-003e-4f2e-a769-dc9f85dc81a1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T07:15:41.874239Z","iopub.execute_input":"2022-06-20T07:15:41.874617Z","iopub.status.idle":"2022-06-20T07:24:14.344383Z","shell.execute_reply.started":"2022-06-20T07:15:41.874545Z","shell.execute_reply":"2022-06-20T07:24:14.343484Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"sims = df_all[[\"anchor_parsed\", \"target_parsed\"]]\nsimilarityValue = []\nfor i in range(sims.count()[0]):\n    sentence_1 = nlp(sims.iloc[i][0])\n    sentence_2 = nlp(sims.iloc[i][1])\n    similarityValue.append(sentence_1.similarity(sentence_2))\n\ndf_all['anchor_target_cos_sim'] = similarityValue\n\ntrain = df_all.loc[df_all['dataset'] == 'train']\ntest = df_all.loc[df_all['dataset'] == 'test']","metadata":{"_uuid":"00148a52-36d5-48d5-8600-875693a2172c","_cell_guid":"ca883518-7c1f-4112-978b-5a0dac56b352","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T07:24:14.346389Z","iopub.execute_input":"2022-06-20T07:24:14.346773Z","iopub.status.idle":"2022-06-20T07:32:57.957021Z","shell.execute_reply.started":"2022-06-20T07:24:14.346714Z","shell.execute_reply":"2022-06-20T07:32:57.955739Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"train['text'] = train['anchor'] + '[SEP]' + train['target'] + '[SEP]' + train['context_text']\ntest['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]' + test['context_text']","metadata":{"execution":{"iopub.status.busy":"2022-06-20T07:32:57.962613Z","iopub.execute_input":"2022-06-20T07:32:57.965719Z","iopub.status.idle":"2022-06-20T07:32:58.023668Z","shell.execute_reply.started":"2022-06-20T07:32:57.963125Z","shell.execute_reply":"2022-06-20T07:32:58.022474Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"markdown","source":"# Transformers","metadata":{}},{"cell_type":"code","source":"class CFG:\n    input_path = '../input/us-patent-phrase-to-phrase-matching/'\n    model_path = [\n                  '../input/deberta-large-v1/',\n                  '../input/deberta-v3-5folds/',\n                  '../input/xlm-roberta-large-5folds/',\n                  '../input/electra-upppm/electra_upppm/',\n                  '../input/bert4patents-upppm/bert4patents_upppm/',\n                 ]\n    model_num = 5\n    num_fold = 5","metadata":{"execution":{"iopub.status.busy":"2022-06-20T08:38:40.348219Z","iopub.execute_input":"2022-06-20T08:38:40.348579Z","iopub.status.idle":"2022-06-20T08:38:40.354912Z","shell.execute_reply.started":"2022-06-20T08:38:40.348543Z","shell.execute_reply":"2022-06-20T08:38:40.353832Z"},"trusted":true},"execution_count":147,"outputs":[]},{"cell_type":"code","source":"def process_test(unit):\n        return {\n        **tokenizer(unit['text'])\n    }\n    \nfor i in range (CFG.model_num):   \n    tokenizer = AutoTokenizer.from_pretrained(f'{CFG.model_path[i]}fold0')\n    test_ds = datasets.Dataset.from_pandas(test[['text']])\n    test_ds = test_ds.map(process_test)\n\n    predictions_test = []\n    for fold in range(CFG.num_fold):        \n        trainer = Trainer(\n                AutoModelForSequenceClassification.from_pretrained(f'{CFG.model_path[i]}fold{fold}', \n                                                                   num_labels=1),\n                tokenizer=tokenizer,\n            )\n        \n        predictions_test.append(trainer.predict(test_ds).predictions)\n        del trainer\n        gc.collect()\n        \n    test[f\"predictions_{CFG.model_path[i].split('/')[-2]}\"] = np.average(predictions_test, axis=0)\n\n    del tokenizer, test_ds\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T08:39:01.374665Z","iopub.execute_input":"2022-06-20T08:39:01.375028Z","iopub.status.idle":"2022-06-20T08:46:37.920245Z","shell.execute_reply.started":"2022-06-20T08:39:01.374984Z","shell.execute_reply":"2022-06-20T08:46:37.919236Z"},"trusted":true},"execution_count":148,"outputs":[{"name":"stderr","text":"Didn't find file ../input/deberta-large-v1/fold0/added_tokens.json. We won't load it.\nloading file ../input/deberta-large-v1/fold0/vocab.json\nloading file ../input/deberta-large-v1/fold0/merges.txt\nloading file ../input/deberta-large-v1/fold0/tokenizer.json\nloading file None\nloading file ../input/deberta-large-v1/fold0/special_tokens_map.json\nloading file ../input/deberta-large-v1/fold0/tokenizer_config.json\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0ex [00:00, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a20abe63fc044bca8bb610aec06386d2"}},"metadata":{}},{"name":"stderr","text":"loading configuration file ../input/deberta-large-v1/fold0/config.json\nModel config DebertaConfig {\n  \"_name_or_path\": \"../input/deberta-large-v1/fold0\",\n  \"architectures\": [\n    \"DebertaForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"LABEL_0\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"label2id\": {\n    \"LABEL_0\": 0\n  },\n  \"layer_norm_eps\": 1e-07,\n  \"max_position_embeddings\": 512,\n  \"max_relative_positions\": -1,\n  \"model_type\": \"deberta\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 0,\n  \"pooler_dropout\": 0,\n  \"pooler_hidden_act\": \"gelu\",\n  \"pooler_hidden_size\": 1024,\n  \"pos_att_type\": [\n    \"c2p\",\n    \"p2c\"\n  ],\n  \"position_biased_input\": false,\n  \"relative_attention\": true,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.16.2\",\n  \"type_vocab_size\": 0,\n  \"vocab_size\": 50265\n}\n\nloading weights file ../input/deberta-large-v1/fold0/pytorch_model.bin\nAll model checkpoint weights were used when initializing DebertaForSequenceClassification.\n\nAll the weights of DebertaForSequenceClassification were initialized from the model checkpoint at ../input/deberta-large-v1/fold0.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaForSequenceClassification for predictions without further training.\nNo `TrainingArguments` passed, using `output_dir=tmp_trainer`.\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nThe following columns in the test set  don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n***** Running Prediction *****\n  Num examples = 36\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"loading configuration file ../input/deberta-large-v1/fold1/config.json\nModel config DebertaConfig {\n  \"_name_or_path\": \"../input/deberta-large-v1/fold1\",\n  \"architectures\": [\n    \"DebertaForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"LABEL_0\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"label2id\": {\n    \"LABEL_0\": 0\n  },\n  \"layer_norm_eps\": 1e-07,\n  \"max_position_embeddings\": 512,\n  \"max_relative_positions\": -1,\n  \"model_type\": \"deberta\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 0,\n  \"pooler_dropout\": 0,\n  \"pooler_hidden_act\": \"gelu\",\n  \"pooler_hidden_size\": 1024,\n  \"pos_att_type\": [\n    \"c2p\",\n    \"p2c\"\n  ],\n  \"position_biased_input\": false,\n  \"relative_attention\": true,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.16.2\",\n  \"type_vocab_size\": 0,\n  \"vocab_size\": 50265\n}\n\nloading weights file ../input/deberta-large-v1/fold1/pytorch_model.bin\nAll model checkpoint weights were used when initializing DebertaForSequenceClassification.\n\nAll the weights of DebertaForSequenceClassification were initialized from the model checkpoint at ../input/deberta-large-v1/fold1.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaForSequenceClassification for predictions without further training.\nNo `TrainingArguments` passed, using `output_dir=tmp_trainer`.\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nThe following columns in the test set  don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n***** Running Prediction *****\n  Num examples = 36\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"loading configuration file ../input/deberta-large-v1/fold2/config.json\nModel config DebertaConfig {\n  \"_name_or_path\": \"../input/deberta-large-v1/fold2\",\n  \"architectures\": [\n    \"DebertaForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"LABEL_0\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"label2id\": {\n    \"LABEL_0\": 0\n  },\n  \"layer_norm_eps\": 1e-07,\n  \"max_position_embeddings\": 512,\n  \"max_relative_positions\": -1,\n  \"model_type\": \"deberta\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 0,\n  \"pooler_dropout\": 0,\n  \"pooler_hidden_act\": \"gelu\",\n  \"pooler_hidden_size\": 1024,\n  \"pos_att_type\": [\n    \"c2p\",\n    \"p2c\"\n  ],\n  \"position_biased_input\": false,\n  \"relative_attention\": true,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.16.2\",\n  \"type_vocab_size\": 0,\n  \"vocab_size\": 50265\n}\n\nloading weights file ../input/deberta-large-v1/fold2/pytorch_model.bin\nAll model checkpoint weights were used when initializing DebertaForSequenceClassification.\n\nAll the weights of DebertaForSequenceClassification were initialized from the model checkpoint at ../input/deberta-large-v1/fold2.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaForSequenceClassification for predictions without further training.\nNo `TrainingArguments` passed, using `output_dir=tmp_trainer`.\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nThe following columns in the test set  don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n***** Running Prediction *****\n  Num examples = 36\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"loading configuration file ../input/deberta-large-v1/fold3/config.json\nModel config DebertaConfig {\n  \"_name_or_path\": \"../input/deberta-large-v1/fold3\",\n  \"architectures\": [\n    \"DebertaForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"LABEL_0\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"label2id\": {\n    \"LABEL_0\": 0\n  },\n  \"layer_norm_eps\": 1e-07,\n  \"max_position_embeddings\": 512,\n  \"max_relative_positions\": -1,\n  \"model_type\": \"deberta\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 0,\n  \"pooler_dropout\": 0,\n  \"pooler_hidden_act\": \"gelu\",\n  \"pooler_hidden_size\": 1024,\n  \"pos_att_type\": [\n    \"c2p\",\n    \"p2c\"\n  ],\n  \"position_biased_input\": false,\n  \"relative_attention\": true,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.16.2\",\n  \"type_vocab_size\": 0,\n  \"vocab_size\": 50265\n}\n\nloading weights file ../input/deberta-large-v1/fold3/pytorch_model.bin\nAll model checkpoint weights were used when initializing DebertaForSequenceClassification.\n\nAll the weights of DebertaForSequenceClassification were initialized from the model checkpoint at ../input/deberta-large-v1/fold3.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaForSequenceClassification for predictions without further training.\nNo `TrainingArguments` passed, using `output_dir=tmp_trainer`.\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nThe following columns in the test set  don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n***** Running Prediction *****\n  Num examples = 36\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"loading configuration file ../input/deberta-large-v1/fold4/config.json\nModel config DebertaConfig {\n  \"_name_or_path\": \"../input/deberta-large-v1/fold4\",\n  \"architectures\": [\n    \"DebertaForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"LABEL_0\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"label2id\": {\n    \"LABEL_0\": 0\n  },\n  \"layer_norm_eps\": 1e-07,\n  \"max_position_embeddings\": 512,\n  \"max_relative_positions\": -1,\n  \"model_type\": \"deberta\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 0,\n  \"pooler_dropout\": 0,\n  \"pooler_hidden_act\": \"gelu\",\n  \"pooler_hidden_size\": 1024,\n  \"pos_att_type\": [\n    \"c2p\",\n    \"p2c\"\n  ],\n  \"position_biased_input\": false,\n  \"relative_attention\": true,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.16.2\",\n  \"type_vocab_size\": 0,\n  \"vocab_size\": 50265\n}\n\nloading weights file ../input/deberta-large-v1/fold4/pytorch_model.bin\nAll model checkpoint weights were used when initializing DebertaForSequenceClassification.\n\nAll the weights of DebertaForSequenceClassification were initialized from the model checkpoint at ../input/deberta-large-v1/fold4.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaForSequenceClassification for predictions without further training.\nNo `TrainingArguments` passed, using `output_dir=tmp_trainer`.\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nThe following columns in the test set  don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n***** Running Prediction *****\n  Num examples = 36\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Didn't find file ../input/deberta-v3-5folds/fold0/tokenizer.json. We won't load it.\nloading file ../input/deberta-v3-5folds/fold0/spm.model\nloading file ../input/deberta-v3-5folds/fold0/added_tokens.json\nloading file ../input/deberta-v3-5folds/fold0/special_tokens_map.json\nloading file ../input/deberta-v3-5folds/fold0/tokenizer_config.json\nloading file None\nAdding [MASK] to the vocabulary\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0ex [00:00, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07bb094cebea42dcad7d91b56991f15e"}},"metadata":{}},{"name":"stderr","text":"loading configuration file ../input/deberta-v3-5folds/fold0/config.json\nModel config DebertaV2Config {\n  \"_name_or_path\": \"../input/deberta-v3-5folds/fold0\",\n  \"architectures\": [\n    \"DebertaV2ForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"LABEL_0\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"label2id\": {\n    \"LABEL_0\": 0\n  },\n  \"layer_norm_eps\": 1e-07,\n  \"max_position_embeddings\": 512,\n  \"max_relative_positions\": -1,\n  \"model_type\": \"deberta-v2\",\n  \"norm_rel_ebd\": \"layer_norm\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 0,\n  \"pooler_dropout\": 0,\n  \"pooler_hidden_act\": \"gelu\",\n  \"pooler_hidden_size\": 1024,\n  \"pos_att_type\": [\n    \"p2c\",\n    \"c2p\"\n  ],\n  \"position_biased_input\": false,\n  \"position_buckets\": 256,\n  \"relative_attention\": true,\n  \"share_att_key\": true,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.16.2\",\n  \"type_vocab_size\": 0,\n  \"vocab_size\": 128100\n}\n\nloading weights file ../input/deberta-v3-5folds/fold0/pytorch_model.bin\nAll model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n\nAll the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at ../input/deberta-v3-5folds/fold0.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\nNo `TrainingArguments` passed, using `output_dir=tmp_trainer`.\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nThe following columns in the test set  don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n***** Running Prediction *****\n  Num examples = 36\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"loading configuration file ../input/deberta-v3-5folds/fold1/config.json\nModel config DebertaV2Config {\n  \"_name_or_path\": \"../input/deberta-v3-5folds/fold1\",\n  \"architectures\": [\n    \"DebertaV2ForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"LABEL_0\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"label2id\": {\n    \"LABEL_0\": 0\n  },\n  \"layer_norm_eps\": 1e-07,\n  \"max_position_embeddings\": 512,\n  \"max_relative_positions\": -1,\n  \"model_type\": \"deberta-v2\",\n  \"norm_rel_ebd\": \"layer_norm\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 0,\n  \"pooler_dropout\": 0,\n  \"pooler_hidden_act\": \"gelu\",\n  \"pooler_hidden_size\": 1024,\n  \"pos_att_type\": [\n    \"p2c\",\n    \"c2p\"\n  ],\n  \"position_biased_input\": false,\n  \"position_buckets\": 256,\n  \"relative_attention\": true,\n  \"share_att_key\": true,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.16.2\",\n  \"type_vocab_size\": 0,\n  \"vocab_size\": 128100\n}\n\nloading weights file ../input/deberta-v3-5folds/fold1/pytorch_model.bin\nAll model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n\nAll the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at ../input/deberta-v3-5folds/fold1.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\nNo `TrainingArguments` passed, using `output_dir=tmp_trainer`.\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nThe following columns in the test set  don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n***** Running Prediction *****\n  Num examples = 36\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"loading configuration file ../input/deberta-v3-5folds/fold2/config.json\nModel config DebertaV2Config {\n  \"_name_or_path\": \"../input/deberta-v3-5folds/fold2\",\n  \"architectures\": [\n    \"DebertaV2ForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"LABEL_0\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"label2id\": {\n    \"LABEL_0\": 0\n  },\n  \"layer_norm_eps\": 1e-07,\n  \"max_position_embeddings\": 512,\n  \"max_relative_positions\": -1,\n  \"model_type\": \"deberta-v2\",\n  \"norm_rel_ebd\": \"layer_norm\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 0,\n  \"pooler_dropout\": 0,\n  \"pooler_hidden_act\": \"gelu\",\n  \"pooler_hidden_size\": 1024,\n  \"pos_att_type\": [\n    \"p2c\",\n    \"c2p\"\n  ],\n  \"position_biased_input\": false,\n  \"position_buckets\": 256,\n  \"relative_attention\": true,\n  \"share_att_key\": true,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.16.2\",\n  \"type_vocab_size\": 0,\n  \"vocab_size\": 128100\n}\n\nloading weights file ../input/deberta-v3-5folds/fold2/pytorch_model.bin\nAll model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n\nAll the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at ../input/deberta-v3-5folds/fold2.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\nNo `TrainingArguments` passed, using `output_dir=tmp_trainer`.\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nThe following columns in the test set  don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n***** Running Prediction *****\n  Num examples = 36\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"loading configuration file ../input/deberta-v3-5folds/fold3/config.json\nModel config DebertaV2Config {\n  \"_name_or_path\": \"../input/deberta-v3-5folds/fold3\",\n  \"architectures\": [\n    \"DebertaV2ForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"LABEL_0\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"label2id\": {\n    \"LABEL_0\": 0\n  },\n  \"layer_norm_eps\": 1e-07,\n  \"max_position_embeddings\": 512,\n  \"max_relative_positions\": -1,\n  \"model_type\": \"deberta-v2\",\n  \"norm_rel_ebd\": \"layer_norm\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 0,\n  \"pooler_dropout\": 0,\n  \"pooler_hidden_act\": \"gelu\",\n  \"pooler_hidden_size\": 1024,\n  \"pos_att_type\": [\n    \"p2c\",\n    \"c2p\"\n  ],\n  \"position_biased_input\": false,\n  \"position_buckets\": 256,\n  \"relative_attention\": true,\n  \"share_att_key\": true,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.16.2\",\n  \"type_vocab_size\": 0,\n  \"vocab_size\": 128100\n}\n\nloading weights file ../input/deberta-v3-5folds/fold3/pytorch_model.bin\nAll model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n\nAll the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at ../input/deberta-v3-5folds/fold3.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\nNo `TrainingArguments` passed, using `output_dir=tmp_trainer`.\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nThe following columns in the test set  don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n***** Running Prediction *****\n  Num examples = 36\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"loading configuration file ../input/deberta-v3-5folds/fold4/config.json\nModel config DebertaV2Config {\n  \"_name_or_path\": \"../input/deberta-v3-5folds/fold4\",\n  \"architectures\": [\n    \"DebertaV2ForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"LABEL_0\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"label2id\": {\n    \"LABEL_0\": 0\n  },\n  \"layer_norm_eps\": 1e-07,\n  \"max_position_embeddings\": 512,\n  \"max_relative_positions\": -1,\n  \"model_type\": \"deberta-v2\",\n  \"norm_rel_ebd\": \"layer_norm\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 0,\n  \"pooler_dropout\": 0,\n  \"pooler_hidden_act\": \"gelu\",\n  \"pooler_hidden_size\": 1024,\n  \"pos_att_type\": [\n    \"p2c\",\n    \"c2p\"\n  ],\n  \"position_biased_input\": false,\n  \"position_buckets\": 256,\n  \"relative_attention\": true,\n  \"share_att_key\": true,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.16.2\",\n  \"type_vocab_size\": 0,\n  \"vocab_size\": 128100\n}\n\nloading weights file ../input/deberta-v3-5folds/fold4/pytorch_model.bin\nAll model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n\nAll the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at ../input/deberta-v3-5folds/fold4.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\nNo `TrainingArguments` passed, using `output_dir=tmp_trainer`.\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nThe following columns in the test set  don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n***** Running Prediction *****\n  Num examples = 36\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Didn't find file ../input/xlm-roberta-large-5folds/fold0/added_tokens.json. We won't load it.\nloading file ../input/xlm-roberta-large-5folds/fold0/sentencepiece.bpe.model\nloading file ../input/xlm-roberta-large-5folds/fold0/tokenizer.json\nloading file None\nloading file ../input/xlm-roberta-large-5folds/fold0/special_tokens_map.json\nloading file ../input/xlm-roberta-large-5folds/fold0/tokenizer_config.json\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0ex [00:00, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"671b448f69204b5b9a302985a56491fb"}},"metadata":{}},{"name":"stderr","text":"loading configuration file ../input/xlm-roberta-large-5folds/fold0/config.json\nModel config XLMRobertaConfig {\n  \"_name_or_path\": \"../input/xlm-roberta-large-5folds/fold0\",\n  \"architectures\": [\n    \"XLMRobertaForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"LABEL_0\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"label2id\": {\n    \"LABEL_0\": 0\n  },\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"xlm-roberta\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"output_past\": true,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"problem_type\": \"regression\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.16.2\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 250002\n}\n\nloading weights file ../input/xlm-roberta-large-5folds/fold0/pytorch_model.bin\nAll model checkpoint weights were used when initializing XLMRobertaForSequenceClassification.\n\nAll the weights of XLMRobertaForSequenceClassification were initialized from the model checkpoint at ../input/xlm-roberta-large-5folds/fold0.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaForSequenceClassification for predictions without further training.\nNo `TrainingArguments` passed, using `output_dir=tmp_trainer`.\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nThe following columns in the test set  don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n***** Running Prediction *****\n  Num examples = 36\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"loading configuration file ../input/xlm-roberta-large-5folds/fold1/config.json\nModel config XLMRobertaConfig {\n  \"_name_or_path\": \"../input/xlm-roberta-large-5folds/fold1\",\n  \"architectures\": [\n    \"XLMRobertaForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"LABEL_0\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"label2id\": {\n    \"LABEL_0\": 0\n  },\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"xlm-roberta\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"output_past\": true,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"problem_type\": \"regression\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.16.2\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 250002\n}\n\nloading weights file ../input/xlm-roberta-large-5folds/fold1/pytorch_model.bin\nAll model checkpoint weights were used when initializing XLMRobertaForSequenceClassification.\n\nAll the weights of XLMRobertaForSequenceClassification were initialized from the model checkpoint at ../input/xlm-roberta-large-5folds/fold1.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaForSequenceClassification for predictions without further training.\nNo `TrainingArguments` passed, using `output_dir=tmp_trainer`.\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nThe following columns in the test set  don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n***** Running Prediction *****\n  Num examples = 36\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"loading configuration file ../input/xlm-roberta-large-5folds/fold2/config.json\nModel config XLMRobertaConfig {\n  \"_name_or_path\": \"../input/xlm-roberta-large-5folds/fold2\",\n  \"architectures\": [\n    \"XLMRobertaForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"LABEL_0\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"label2id\": {\n    \"LABEL_0\": 0\n  },\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"xlm-roberta\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"output_past\": true,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"problem_type\": \"regression\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.16.2\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 250002\n}\n\nloading weights file ../input/xlm-roberta-large-5folds/fold2/pytorch_model.bin\nAll model checkpoint weights were used when initializing XLMRobertaForSequenceClassification.\n\nAll the weights of XLMRobertaForSequenceClassification were initialized from the model checkpoint at ../input/xlm-roberta-large-5folds/fold2.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaForSequenceClassification for predictions without further training.\nNo `TrainingArguments` passed, using `output_dir=tmp_trainer`.\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nThe following columns in the test set  don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n***** Running Prediction *****\n  Num examples = 36\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"loading configuration file ../input/xlm-roberta-large-5folds/fold3/config.json\nModel config XLMRobertaConfig {\n  \"_name_or_path\": \"../input/xlm-roberta-large-5folds/fold3\",\n  \"architectures\": [\n    \"XLMRobertaForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"LABEL_0\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"label2id\": {\n    \"LABEL_0\": 0\n  },\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"xlm-roberta\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"output_past\": true,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"problem_type\": \"regression\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.16.2\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 250002\n}\n\nloading weights file ../input/xlm-roberta-large-5folds/fold3/pytorch_model.bin\nAll model checkpoint weights were used when initializing XLMRobertaForSequenceClassification.\n\nAll the weights of XLMRobertaForSequenceClassification were initialized from the model checkpoint at ../input/xlm-roberta-large-5folds/fold3.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaForSequenceClassification for predictions without further training.\nNo `TrainingArguments` passed, using `output_dir=tmp_trainer`.\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nThe following columns in the test set  don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n***** Running Prediction *****\n  Num examples = 36\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"loading configuration file ../input/xlm-roberta-large-5folds/fold4/config.json\nModel config XLMRobertaConfig {\n  \"_name_or_path\": \"../input/xlm-roberta-large-5folds/fold4\",\n  \"architectures\": [\n    \"XLMRobertaForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"LABEL_0\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"label2id\": {\n    \"LABEL_0\": 0\n  },\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"xlm-roberta\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"output_past\": true,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"problem_type\": \"regression\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.16.2\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 250002\n}\n\nloading weights file ../input/xlm-roberta-large-5folds/fold4/pytorch_model.bin\nAll model checkpoint weights were used when initializing XLMRobertaForSequenceClassification.\n\nAll the weights of XLMRobertaForSequenceClassification were initialized from the model checkpoint at ../input/xlm-roberta-large-5folds/fold4.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaForSequenceClassification for predictions without further training.\nNo `TrainingArguments` passed, using `output_dir=tmp_trainer`.\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nThe following columns in the test set  don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n***** Running Prediction *****\n  Num examples = 36\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Didn't find file ../input/electra-upppm/electra_upppm/fold0/added_tokens.json. We won't load it.\nloading file ../input/electra-upppm/electra_upppm/fold0/vocab.txt\nloading file ../input/electra-upppm/electra_upppm/fold0/tokenizer.json\nloading file None\nloading file ../input/electra-upppm/electra_upppm/fold0/special_tokens_map.json\nloading file ../input/electra-upppm/electra_upppm/fold0/tokenizer_config.json\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0ex [00:00, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5e925c88ed1469b9aecde0f33e4eca5"}},"metadata":{}},{"name":"stderr","text":"loading configuration file ../input/electra-upppm/electra_upppm/fold0/config.json\nModel config ElectraConfig {\n  \"_name_or_path\": \"../input/electra-upppm/electra_upppm/fold0\",\n  \"architectures\": [\n    \"ElectraForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"embedding_size\": 1024,\n  \"finetuning_task\": \"mnli\",\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"LABEL_0\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"label2id\": {\n    \"LABEL_0\": 0\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"electra\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"problem_type\": \"regression\",\n  \"summary_activation\": \"gelu\",\n  \"summary_last_dropout\": 0.1,\n  \"summary_type\": \"first\",\n  \"summary_use_proj\": true,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.16.2\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\nloading weights file ../input/electra-upppm/electra_upppm/fold0/pytorch_model.bin\nAll model checkpoint weights were used when initializing ElectraForSequenceClassification.\n\nAll the weights of ElectraForSequenceClassification were initialized from the model checkpoint at ../input/electra-upppm/electra_upppm/fold0.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraForSequenceClassification for predictions without further training.\nNo `TrainingArguments` passed, using `output_dir=tmp_trainer`.\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nThe following columns in the test set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n***** Running Prediction *****\n  Num examples = 36\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"loading configuration file ../input/electra-upppm/electra_upppm/fold1/config.json\nModel config ElectraConfig {\n  \"_name_or_path\": \"../input/electra-upppm/electra_upppm/fold1\",\n  \"architectures\": [\n    \"ElectraForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"embedding_size\": 1024,\n  \"finetuning_task\": \"mnli\",\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"LABEL_0\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"label2id\": {\n    \"LABEL_0\": 0\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"electra\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"problem_type\": \"regression\",\n  \"summary_activation\": \"gelu\",\n  \"summary_last_dropout\": 0.1,\n  \"summary_type\": \"first\",\n  \"summary_use_proj\": true,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.16.2\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\nloading weights file ../input/electra-upppm/electra_upppm/fold1/pytorch_model.bin\nAll model checkpoint weights were used when initializing ElectraForSequenceClassification.\n\nAll the weights of ElectraForSequenceClassification were initialized from the model checkpoint at ../input/electra-upppm/electra_upppm/fold1.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraForSequenceClassification for predictions without further training.\nNo `TrainingArguments` passed, using `output_dir=tmp_trainer`.\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nThe following columns in the test set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n***** Running Prediction *****\n  Num examples = 36\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"loading configuration file ../input/electra-upppm/electra_upppm/fold2/config.json\nModel config ElectraConfig {\n  \"_name_or_path\": \"../input/electra-upppm/electra_upppm/fold2\",\n  \"architectures\": [\n    \"ElectraForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"embedding_size\": 1024,\n  \"finetuning_task\": \"mnli\",\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"LABEL_0\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"label2id\": {\n    \"LABEL_0\": 0\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"electra\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"problem_type\": \"regression\",\n  \"summary_activation\": \"gelu\",\n  \"summary_last_dropout\": 0.1,\n  \"summary_type\": \"first\",\n  \"summary_use_proj\": true,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.16.2\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\nloading weights file ../input/electra-upppm/electra_upppm/fold2/pytorch_model.bin\nAll model checkpoint weights were used when initializing ElectraForSequenceClassification.\n\nAll the weights of ElectraForSequenceClassification were initialized from the model checkpoint at ../input/electra-upppm/electra_upppm/fold2.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraForSequenceClassification for predictions without further training.\nNo `TrainingArguments` passed, using `output_dir=tmp_trainer`.\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nThe following columns in the test set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n***** Running Prediction *****\n  Num examples = 36\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"loading configuration file ../input/electra-upppm/electra_upppm/fold3/config.json\nModel config ElectraConfig {\n  \"_name_or_path\": \"../input/electra-upppm/electra_upppm/fold3\",\n  \"architectures\": [\n    \"ElectraForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"embedding_size\": 1024,\n  \"finetuning_task\": \"mnli\",\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"LABEL_0\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"label2id\": {\n    \"LABEL_0\": 0\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"electra\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"problem_type\": \"regression\",\n  \"summary_activation\": \"gelu\",\n  \"summary_last_dropout\": 0.1,\n  \"summary_type\": \"first\",\n  \"summary_use_proj\": true,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.16.2\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\nloading weights file ../input/electra-upppm/electra_upppm/fold3/pytorch_model.bin\nAll model checkpoint weights were used when initializing ElectraForSequenceClassification.\n\nAll the weights of ElectraForSequenceClassification were initialized from the model checkpoint at ../input/electra-upppm/electra_upppm/fold3.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraForSequenceClassification for predictions without further training.\nNo `TrainingArguments` passed, using `output_dir=tmp_trainer`.\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nThe following columns in the test set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n***** Running Prediction *****\n  Num examples = 36\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"loading configuration file ../input/electra-upppm/electra_upppm/fold4/config.json\nModel config ElectraConfig {\n  \"_name_or_path\": \"../input/electra-upppm/electra_upppm/fold4\",\n  \"architectures\": [\n    \"ElectraForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"embedding_size\": 1024,\n  \"finetuning_task\": \"mnli\",\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"LABEL_0\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"label2id\": {\n    \"LABEL_0\": 0\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"electra\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"problem_type\": \"regression\",\n  \"summary_activation\": \"gelu\",\n  \"summary_last_dropout\": 0.1,\n  \"summary_type\": \"first\",\n  \"summary_use_proj\": true,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.16.2\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\nloading weights file ../input/electra-upppm/electra_upppm/fold4/pytorch_model.bin\nAll model checkpoint weights were used when initializing ElectraForSequenceClassification.\n\nAll the weights of ElectraForSequenceClassification were initialized from the model checkpoint at ../input/electra-upppm/electra_upppm/fold4.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraForSequenceClassification for predictions without further training.\nNo `TrainingArguments` passed, using `output_dir=tmp_trainer`.\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nThe following columns in the test set  don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n***** Running Prediction *****\n  Num examples = 36\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Didn't find file ../input/bert4patents-upppm/bert4patents_upppm/fold0/added_tokens.json. We won't load it.\nloading file ../input/bert4patents-upppm/bert4patents_upppm/fold0/vocab.txt\nloading file ../input/bert4patents-upppm/bert4patents_upppm/fold0/tokenizer.json\nloading file None\nloading file ../input/bert4patents-upppm/bert4patents_upppm/fold0/special_tokens_map.json\nloading file ../input/bert4patents-upppm/bert4patents_upppm/fold0/tokenizer_config.json\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0ex [00:00, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb830e73fb2c41b0a2f381053120d606"}},"metadata":{}},{"name":"stderr","text":"loading configuration file ../input/bert4patents-upppm/bert4patents_upppm/fold0/config.json\nModel config BertConfig {\n  \"_name_or_path\": \"../input/bert4patents-upppm/bert4patents_upppm/fold0\",\n  \"architectures\": [\n    \"BertForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"LABEL_0\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"label2id\": {\n    \"LABEL_0\": 0\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"problem_type\": \"regression\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.16.2\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 39859\n}\n\nloading weights file ../input/bert4patents-upppm/bert4patents_upppm/fold0/pytorch_model.bin\nAll model checkpoint weights were used when initializing BertForSequenceClassification.\n\nAll the weights of BertForSequenceClassification were initialized from the model checkpoint at ../input/bert4patents-upppm/bert4patents_upppm/fold0.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\nNo `TrainingArguments` passed, using `output_dir=tmp_trainer`.\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nThe following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n***** Running Prediction *****\n  Num examples = 36\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"loading configuration file ../input/bert4patents-upppm/bert4patents_upppm/fold1/config.json\nModel config BertConfig {\n  \"_name_or_path\": \"../input/bert4patents-upppm/bert4patents_upppm/fold1\",\n  \"architectures\": [\n    \"BertForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"LABEL_0\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"label2id\": {\n    \"LABEL_0\": 0\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"problem_type\": \"regression\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.16.2\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 39859\n}\n\nloading weights file ../input/bert4patents-upppm/bert4patents_upppm/fold1/pytorch_model.bin\nAll model checkpoint weights were used when initializing BertForSequenceClassification.\n\nAll the weights of BertForSequenceClassification were initialized from the model checkpoint at ../input/bert4patents-upppm/bert4patents_upppm/fold1.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\nNo `TrainingArguments` passed, using `output_dir=tmp_trainer`.\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nThe following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n***** Running Prediction *****\n  Num examples = 36\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"loading configuration file ../input/bert4patents-upppm/bert4patents_upppm/fold2/config.json\nModel config BertConfig {\n  \"_name_or_path\": \"../input/bert4patents-upppm/bert4patents_upppm/fold2\",\n  \"architectures\": [\n    \"BertForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"LABEL_0\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"label2id\": {\n    \"LABEL_0\": 0\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"problem_type\": \"regression\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.16.2\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 39859\n}\n\nloading weights file ../input/bert4patents-upppm/bert4patents_upppm/fold2/pytorch_model.bin\nAll model checkpoint weights were used when initializing BertForSequenceClassification.\n\nAll the weights of BertForSequenceClassification were initialized from the model checkpoint at ../input/bert4patents-upppm/bert4patents_upppm/fold2.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\nNo `TrainingArguments` passed, using `output_dir=tmp_trainer`.\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nThe following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n***** Running Prediction *****\n  Num examples = 36\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"loading configuration file ../input/bert4patents-upppm/bert4patents_upppm/fold3/config.json\nModel config BertConfig {\n  \"_name_or_path\": \"../input/bert4patents-upppm/bert4patents_upppm/fold3\",\n  \"architectures\": [\n    \"BertForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"LABEL_0\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"label2id\": {\n    \"LABEL_0\": 0\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"problem_type\": \"regression\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.16.2\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 39859\n}\n\nloading weights file ../input/bert4patents-upppm/bert4patents_upppm/fold3/pytorch_model.bin\nAll model checkpoint weights were used when initializing BertForSequenceClassification.\n\nAll the weights of BertForSequenceClassification were initialized from the model checkpoint at ../input/bert4patents-upppm/bert4patents_upppm/fold3.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\nNo `TrainingArguments` passed, using `output_dir=tmp_trainer`.\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nThe following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n***** Running Prediction *****\n  Num examples = 36\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:00]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"loading configuration file ../input/bert4patents-upppm/bert4patents_upppm/fold4/config.json\nModel config BertConfig {\n  \"_name_or_path\": \"../input/bert4patents-upppm/bert4patents_upppm/fold4\",\n  \"architectures\": [\n    \"BertForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"id2label\": {\n    \"0\": \"LABEL_0\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"label2id\": {\n    \"LABEL_0\": 0\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"problem_type\": \"regression\",\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.16.2\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 39859\n}\n\nloading weights file ../input/bert4patents-upppm/bert4patents_upppm/fold4/pytorch_model.bin\nAll model checkpoint weights were used when initializing BertForSequenceClassification.\n\nAll the weights of BertForSequenceClassification were initialized from the model checkpoint at ../input/bert4patents-upppm/bert4patents_upppm/fold4.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\nNo `TrainingArguments` passed, using `output_dir=tmp_trainer`.\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nThe following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__.\n***** Running Prediction *****\n  Num examples = 36\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:00]\n    </div>\n    "},"metadata":{}}]},{"cell_type":"code","source":"def process_valid(unit):\n        return {\n        **tokenizer(unit['text'])\n    }\n    \nfor i in range (CFG.model_num):   \n    tokenizer = AutoTokenizer.from_pretrained(f'{CFG.model_path[i]}fold0')\n    valid_ds = datasets.Dataset.from_pandas(train[['text']])\n    valid_ds = valid_ds.map(process_valid)\n\n    predictions_valid = []\n    for fold in range(CFG.num_fold):        \n        trainer = Trainer(\n                AutoModelForSequenceClassification.from_pretrained(f'{CFG.model_path[i]}fold{fold}', \n                                                                   num_labels=1),\n                tokenizer=tokenizer,\n            )\n        \n        predictions_valid.append(trainer.predict(valid_ds).predictions)\n        del trainer\n        gc.collect()\n\n    train[f\"predictions_{CFG.model_path[i].split('/')[-2]}\"] = np.average(predictions_valid, axis=0)\n\n    del tokenizer, valid_ds\n    gc.collect()","metadata":{"_uuid":"f7e15874-fc82-4243-9a91-34cb24ab04bc","_cell_guid":"aa4a21af-9cd7-4051-be66-6f9837acf680","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T08:35:49.186762Z","iopub.status.idle":"2022-06-20T08:35:49.187589Z","shell.execute_reply.started":"2022-06-20T08:35:49.187280Z","shell.execute_reply":"2022-06-20T08:35:49.187311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train.drop(columns=['id', 'anchor', 'target', 'context', 'score', 'general_context', 'context_text',\n       'section', 'classes', 'dataset', 'anchor_parsed', 'target_parsed', 'anchor_nlp', 'target_nlp', 'text']).astype('float32')\ny = train['score']","metadata":{"_uuid":"c6e4839b-efc5-4086-a590-2f7b7b65e8de","_cell_guid":"46bdead9-8e05-4907-bc48-78c2be20cb9a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T08:14:48.244655Z","iopub.execute_input":"2022-06-20T08:14:48.245000Z","iopub.status.idle":"2022-06-20T08:14:48.257466Z","shell.execute_reply.started":"2022-06-20T08:14:48.244966Z","shell.execute_reply":"2022-06-20T08:14:48.255992Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"execution":{"iopub.status.busy":"2022-06-20T08:14:57.663445Z","iopub.execute_input":"2022-06-20T08:14:57.664113Z","iopub.status.idle":"2022-06-20T08:14:57.717299Z","shell.execute_reply.started":"2022-06-20T08:14:57.664078Z","shell.execute_reply":"2022-06-20T08:14:57.716113Z"},"trusted":true},"execution_count":125,"outputs":[{"execution_count":125,"output_type":"execute_result","data":{"text/plain":"       Chemistry and Metallurgy  Electricity  Fixed Constructions  \\\n0                           0.0          0.0                  0.0   \n1                           0.0          0.0                  0.0   \n2                           0.0          0.0                  0.0   \n3                           0.0          0.0                  0.0   \n4                           0.0          0.0                  0.0   \n...                         ...          ...                  ...   \n36468                       0.0          0.0                  0.0   \n36469                       0.0          0.0                  0.0   \n36470                       0.0          0.0                  0.0   \n36471                       0.0          0.0                  0.0   \n36472                       0.0          0.0                  0.0   \n\n       Human Necessities  Mechanical Engineering  Operations and Transport  \\\n0                    1.0                     0.0                       0.0   \n1                    1.0                     0.0                       0.0   \n2                    1.0                     0.0                       0.0   \n3                    1.0                     0.0                       0.0   \n4                    1.0                     0.0                       0.0   \n...                  ...                     ...                       ...   \n36468                0.0                     0.0                       1.0   \n36469                0.0                     0.0                       1.0   \n36470                0.0                     0.0                       1.0   \n36471                0.0                     0.0                       1.0   \n36472                0.0                     0.0                       1.0   \n\n       Physics  Textiles  anchor_len  target_len  ...  anchor_ADV  target_ADV  \\\n0          0.0       0.0         1.0         3.0  ...         0.0         0.0   \n1          0.0       0.0         1.0         3.0  ...         0.0         0.0   \n2          0.0       0.0         1.0         2.0  ...         0.0         0.0   \n3          0.0       0.0         1.0         2.0  ...         0.0         0.0   \n4          0.0       0.0         1.0         2.0  ...         0.0         0.0   \n...        ...       ...         ...         ...  ...         ...         ...   \n36468      0.0       0.0         2.0         2.0  ...         0.0         0.0   \n36469      0.0       0.0         2.0         2.0  ...         0.0         0.0   \n36470      0.0       0.0         2.0         2.0  ...         0.0         0.0   \n36471      0.0       0.0         2.0         2.0  ...         0.0         0.0   \n36472      0.0       0.0         2.0         2.0  ...         0.0         0.0   \n\n       anchor_in_target  target_in_anchor  anchor_target_cos_sim  \\\n0                   1.0               0.0                 0.8592   \n1                   0.0               0.0                 0.5321   \n2                   0.0               0.0                 0.2249   \n3                   0.0               0.0                 0.3318   \n4                   0.0               0.0                 0.1598   \n...                 ...               ...                    ...   \n36468               0.0               0.0                 0.8630   \n36469               0.0               0.0                 0.5774   \n36470               0.0               0.0                 0.5931   \n36471               0.0               0.0                 0.7081   \n36472               0.0               0.0                 0.5174   \n\n       predictions_deberta-large-v1  predictions_deberta-v3-5folds  \\\n0                               NaN                         0.3832   \n1                               NaN                         0.6793   \n2                               NaN                         0.2856   \n3                               NaN                         0.3693   \n4                               NaN                         0.2200   \n...                             ...                            ...   \n36468                           NaN                         1.0064   \n36469                           NaN                         0.4542   \n36470                           NaN                         0.5050   \n36471                           NaN                         0.7584   \n36472                           NaN                         0.4892   \n\n       predictions_xlm-roberta-large-5folds  predictions_electra_upppm  \\\n0                                    0.4439                        NaN   \n1                                    0.5331                        NaN   \n2                                    0.2182                        NaN   \n3                                    0.3482                        NaN   \n4                                    0.1735                        NaN   \n...                                     ...                        ...   \n36468                                0.3953                        NaN   \n36469                                0.2566                        NaN   \n36470                                0.2829                        NaN   \n36471                                0.3618                        NaN   \n36472                                0.2858                        NaN   \n\n       predictions_bert4patents_upppm  \n0                                 NaN  \n1                                 NaN  \n2                                 NaN  \n3                                 NaN  \n4                                 NaN  \n...                               ...  \n36468                             NaN  \n36469                             NaN  \n36470                             NaN  \n36471                             NaN  \n36472                             NaN  \n\n[36473 rows x 30 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Chemistry and Metallurgy</th>\n      <th>Electricity</th>\n      <th>Fixed Constructions</th>\n      <th>Human Necessities</th>\n      <th>Mechanical Engineering</th>\n      <th>Operations and Transport</th>\n      <th>Physics</th>\n      <th>Textiles</th>\n      <th>anchor_len</th>\n      <th>target_len</th>\n      <th>...</th>\n      <th>anchor_ADV</th>\n      <th>target_ADV</th>\n      <th>anchor_in_target</th>\n      <th>target_in_anchor</th>\n      <th>anchor_target_cos_sim</th>\n      <th>predictions_deberta-large-v1</th>\n      <th>predictions_deberta-v3-5folds</th>\n      <th>predictions_xlm-roberta-large-5folds</th>\n      <th>predictions_electra_upppm</th>\n      <th>predictions_bert4patents_upppm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.8592</td>\n      <td>NaN</td>\n      <td>0.3832</td>\n      <td>0.4439</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.5321</td>\n      <td>NaN</td>\n      <td>0.6793</td>\n      <td>0.5331</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.2249</td>\n      <td>NaN</td>\n      <td>0.2856</td>\n      <td>0.2182</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.3318</td>\n      <td>NaN</td>\n      <td>0.3693</td>\n      <td>0.3482</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.1598</td>\n      <td>NaN</td>\n      <td>0.2200</td>\n      <td>0.1735</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>36468</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.8630</td>\n      <td>NaN</td>\n      <td>1.0064</td>\n      <td>0.3953</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>36469</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.5774</td>\n      <td>NaN</td>\n      <td>0.4542</td>\n      <td>0.2566</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>36470</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.5931</td>\n      <td>NaN</td>\n      <td>0.5050</td>\n      <td>0.2829</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>36471</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.7081</td>\n      <td>NaN</td>\n      <td>0.7584</td>\n      <td>0.3618</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>36472</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.5174</td>\n      <td>NaN</td>\n      <td>0.4892</td>\n      <td>0.2858</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>36473 rows × 30 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def slice_by_corr(X, r_min=0):\n    # Create correlation matrix\n    corr_matrix = X.corr().abs()\n\n    # Select upper triangle of correlation matrix\n    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n\n    # Find features with correlation greater than r_min\n    return X[[column for column in upper.columns if any(upper[column] > r_min)]]\n\ndef variance_inflation_factor(X, exog_idx):\n    clf = LinearRegression(fit_intercept=True)\n    sub_X = np.delete(np.nan_to_num(X), exog_idx, axis=1)\n    sub_y = X[:, exog_idx][np.newaxis].T\n    sub_clf = clf.fit(sub_X, sub_y)\n    return 1 / (1 - r2_score(sub_y, sub_clf.predict(sub_X)))\n\nclass ReduceVIF(BaseEstimator, TransformerMixin):\n\n    def __init__(self, thresh=10.0, nthreads=4, r_min=0, obs=250):\n        self.thresh = thresh\n        self.nthreads = nthreads\n        self.r_min = r_min\n        self.obs = obs\n        \n    def fit(self, X):\n        self.X = X\n        return self\n\n    def transform(self, X):\n        return ReduceVIF.calculate_vif(X, self.thresh, \n                                       self.nthreads, \n                                       self.r_min, \n                                       self.obs)\n\n    @staticmethod\n    def calculate_vif(X, thresh=10.0, nthreads=16, r_min=0, obs=250):        \n        dropped = True\n        vif_cols = []\n        X_vif_candidates = slice_by_corr(X, r_min)\n        X_vif_candidates = X_vif_candidates.sample(n=obs)\n        while dropped:\n            variables = X_vif_candidates.columns\n            dropped = False\n            with Parallel(n_jobs=nthreads, backend='threading') as parallel:\n                vif = parallel(\n                    delayed(variance_inflation_factor)(\n                        np.asarray(X_vif_candidates[variables].values),\n                        X_vif_candidates.columns.get_loc(var)) for var in \n                    X_vif_candidates.columns)\n            max_vif = max(vif)\n            if max_vif > thresh:\n                maxloc = vif.index(max_vif)\n                print(f'Dropping {X_vif_candidates.columns[maxloc]} with vif={max_vif}')\n                vif_cols.append(X_vif_candidates.columns.tolist()[maxloc])\n                X_vif_candidates = X_vif_candidates.drop(\n                    [X_vif_candidates.columns.tolist()[maxloc]], axis=1)\n                dropped = True\n        \n        if len(vif_cols) > 0:\n            return X.drop(columns=vif_cols), vif_cols\n        else:\n            return X, vif_cols\n\n    \ndef preprocess_x_y(X, nodrop_columns=[],\n                   var_thr=0.98, remove_multi=True,\n                   standardize=True, standardizer='mm',\n                   std_dev=3, vif_thr=5, missingness_thr=0.50,\n                   zero_thr=0.99, nthreads=4):\n    from colorama import Fore, Style\n\n    # Replace all near-zero with zeros\n    # Drop excessively sparse columns with >zero_thr zeros\n    if zero_thr > 0:\n        X = X.apply(lambda x: np.where(np.abs(x) < 0.000001, 0, x))\n        X_tmp = X.T.loc[(X == 0).sum() < (float(zero_thr)) * X.shape[0]].T\n\n        if len(nodrop_columns) > 0:\n            X = pd.concat([X_tmp, X[[i for i in X.columns if i in\n                                     nodrop_columns and i not in\n                                     X_tmp.columns]]], axis=1)\n        else:\n            X = X_tmp\n        del X_tmp\n\n        if X.empty or len(X.columns) < 5:\n            print(f\"\\n\\n{Fore.RED}Empty feature-space (Zero Columns): \"\n                  f\"{X}{Style.RESET_ALL}\\n\\n\")\n            return X\n\n    # Remove columns with excessive missing values\n    X = X.dropna(thresh=len(X) * (1 - missingness_thr), axis=1)\n    if X.empty:\n        print(f\"\\n\\n{Fore.RED}Empty feature-space (missingness): \"\n              f\"{X}{Style.RESET_ALL}\\n\\n\")\n        return X\n\n    # Apply a simple imputer (note that this assumes extreme cases of\n    # missingness have already been addressed). The SimpleImputer is better\n    # for smaller datasets, whereas the IterativeImputer performs best on\n    # larger sets.\n\n    # from sklearn.experimental import enable_iterative_imputer\n    # from sklearn.impute import IterativeImputer\n    # imp = IterativeImputer(random_state=0, sample_posterior=True)\n    # X = pd.DataFrame(imp.fit_transform(X, y), columns=X.columns)\n    imp1 = SimpleImputer()\n    X = pd.DataFrame(imp1.fit_transform(X.astype('float32')),\n                     columns=X.columns)\n\n    # Standardize X\n    if standardize is True:\n        if standardizer == 'ss':\n            scaler = StandardScaler()\n        else:\n            scaler = MinMaxScaler()\n        X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n\n    # Remove low-variance columns\n    sel = VarianceThreshold(threshold=(var_thr*(1-var_thr)))\n    sel.fit(X)\n    if len(nodrop_columns) > 0:\n        good_var_cols = X.columns[np.concatenate(\n            [sel.get_support(indices=True), np.array([X.columns.get_loc(c)\n                                                      for c in\n                                                      nodrop_columns if\n                                                      c in X])])]\n    else:\n        good_var_cols = X.columns[sel.get_support(indices=True)]\n    low_var_cols = [i for i in X.columns if i not in list(good_var_cols)]\n    if len(low_var_cols) > 0:\n        print(f\"Dropping {low_var_cols} for low variance...\")\n    X = X[good_var_cols]\n\n    if X.empty:\n        print(f\"\\n\\n{Fore.RED}Empty feature-space (low-variance): \"\n              f\"{X}{Style.RESET_ALL}\\n\\n\")\n        return X\n        \n    # Remove multicollinear columns\n    if remove_multi is True:\n        try:\n            rvif = ReduceVIF(thresh=vif_thr, nthreads=nthreads)\n            X = rvif.fit_transform(X)[0]\n            if X.empty or len(X.columns) < 5:\n                print(f\"\\n\\n{Fore.RED}Empty feature-space \"\n                      f\"(multicollinearity): \"\n                      f\"{X}{Style.RESET_ALL}\\n\\n\")\n                return X\n        except:\n            print(f\"\\n\\n{Fore.RED}Empty feature-space (multicollinearity): \"\n                  f\"{X}{Style.RESET_ALL}\\n\\n\")\n            return X\n\n    print(f\"\\nX: {X}\\n\")\n    print(f\"Features: {list(X.columns)}\\n\")\n    return X\n\n\nclass Razors(object):\n    \"\"\"\n    Razors is a callable refit option for `GridSearchCV` whose aim is to\n    balance model complexity and cross-validated score in the spirit of the\n    \"one standard error\" rule of Breiman et al. (1984), which showed that\n    the tuning hyperparameter associated with the best performing model may be\n    prone to overfit. To help mitigate this risk, we can instead instruct\n    gridsearch to refit the highest performing 'parsimonious' model, as defined\n    using simple statistical rules (e.g. standard error (`sigma`),\n    percentile (`eta`), or significance level (`alpha`)) to compare\n    distributions of model performance across folds. Importantly, this\n    strategy assumes that the grid of multiple cross-validated models\n    can be principly ordered from simplest to most complex with respect to some\n    target hyperparameter of interest. To use the razors suite, supply\n    the `simplify` function partial of the `Razors` class as a callable\n    directly to the `refit` argument of `GridSearchCV`.\n\n    Parameters\n    ----------\n    cv_results : dict of numpy(masked) ndarrays\n        See attribute cv_results_ of `GridSearchCV`.\n    scoring : str\n        Refit scoring metric.\n    param : str\n        Parameter whose complexity will be optimized.\n    rule : str\n        Rule for balancing model complexity with performance.\n        Options are 'se', 'percentile', and 'ranksum'. Default is 'se'.\n    sigma : int\n        Number of standard errors tolerance in the case that a standard error\n        threshold is used to filter outlying scores across folds. Required if\n        `rule`=='se'. Default is 1.\n    eta : float\n        Percentile tolerance in the case that a percentile threshold\n        is used to filter outlier scores across folds. Required if\n        `rule`=='percentile'. Default is 0.68.\n    alpha : float\n        An alpha significance level in the case that wilcoxon rank sum\n        hypothesis testing is used to filter outlying scores across folds.\n        Required if `rule`=='ranksum'. Default is 0.05.\n\n    References\n    ----------\n    Breiman, Friedman, Olshen, and Stone. (1984) Classification and Regression\n    Trees. Wadsworth.\n\n    Notes\n    -----\n    Here, 'simplest' is defined by the complexity of the model as influenced by\n    some user-defined target parameter (e.g. number of components, number of\n    estimators, polynomial degree, cost, scale, number hidden units, weight\n    decay, number of nearest neighbors, L1/L2 penalty, etc.).\n\n    The callable API accordingly assumes that the `params` attribute of\n    `cv_results_` 1) contains the indicated hyperparameter (`param`) of\n    interest, and 2) contains a sequence of values (numeric, boolean, or\n    categorical) that are ordered from least to most complex.\n    \"\"\"\n    __slots__ = ('cv_results', 'param', 'param_complexity', 'scoring',\n                 'rule', 'greater_is_better',\n                 '_scoring_funcs', '_scoring_dict',\n                 '_n_folds', '_splits', '_score_grid',\n                 '_cv_means', '_sigma', '_eta', '_alpha')\n\n    def __init__(\n            self,\n            cv_results_,\n            param,\n            scoring,\n            rule,\n            sigma=1,\n            eta=0.95,\n            alpha=0.01,\n    ):\n        import sklearn.metrics\n\n        self.cv_results = cv_results_\n        self.param = param\n        self.scoring = scoring\n        self.rule = rule\n        self._scoring_funcs = [\n            met\n            for met in sklearn.metrics.__all__\n            if (met.endswith(\"_score\")) or (met.endswith(\"_error\"))\n        ]\n        # Set _score metrics to True and _error metrics to False\n        self._scoring_dict = dict(\n            zip(\n                self._scoring_funcs,\n                [met.endswith(\"_score\") for met in self._scoring_funcs],\n            )\n        )\n        self.greater_is_better = self._check_scorer()\n        self._n_folds = len(list(set([i.split('_')[0] for i in\n                                     list(self.cv_results.keys()) if\n                                     i.startswith('split')])))\n        # Extract subgrid corresponding to the scoring metric of interest\n        self._splits = [i for i in list(self.cv_results.keys()) if\n                        i.endswith(f\"test_{self.scoring}\") and\n                        i.startswith('split')]\n        self._score_grid = np.vstack([self.cv_results[cv] for cv in\n                                      self._splits]).T\n        self._cv_means = np.array(np.nanmean(self._score_grid, axis=1))\n        self._sigma = sigma\n        self._eta = eta\n        self._alpha = alpha\n\n    def _check_scorer(self):\n        \"\"\"\n        Check whether the target refit scorer is negated. If so, adjust\n        greater_is_better accordingly.\n        \"\"\"\n\n        if (\n                self.scoring not in self._scoring_dict.keys()\n                and f\"{self.scoring}_score\" not in self._scoring_dict.keys()\n        ):\n            if self.scoring.startswith(\"neg_\"):\n                self.greater_is_better = True\n            else:\n                raise NotImplementedError(f\"Scoring metric {self.scoring} not \"\n                                          f\"recognized.\")\n        else:\n            self.greater_is_better = [\n                value for key, value in self._scoring_dict.items() if\n                self.scoring in key][0]\n        return self.greater_is_better\n\n    def _best_low_complexity(self):\n        \"\"\"\n        Balance model complexity with cross-validated score.\n\n        Return\n        ------\n        int\n            Index of a model that has the lowest complexity but its test score\n            is the highest on average across folds as compared to other models\n            that are equally likely to occur.\n        \"\"\"\n\n        # Check parameter(s) whose complexity we seek to restrict\n        if not any(self.param in x for x in\n                   self.cv_results[\"params\"][0].keys()):\n            raise KeyError(f\"Parameter {self.param} not found in cv grid.\")\n        else:\n            hyperparam = [\n                i for i in self.cv_results[\"params\"][0].keys() if\n                i.endswith(self.param)][0]\n\n        # Select low complexity threshold based on specified evaluation rule\n        if self.rule == \"se\":\n            if not self._sigma:\n                raise ValueError(\n                    \"For `se` rule, the tolerance \"\n                    \"(i.e. `_sigma`) parameter cannot be null.\"\n                )\n            l_cutoff, h_cutoff = self.call_standard_error()\n        elif self.rule == \"percentile\":\n            if not self._eta:\n                raise ValueError(\n                    \"For `percentile` rule, the tolerance \"\n                    \"(i.e. `_eta`) parameter cannot be null.\"\n                )\n            l_cutoff, h_cutoff = self.call_percentile()\n        elif self.rule == \"ranksum\":\n            if not self._alpha:\n                raise ValueError(\n                    \"For `ranksum` rule, the alpha-level \"\n                    \"(i.e. `_alpha`) parameter cannot be null.\"\n                )\n            l_cutoff, h_cutoff = self.call_rank_sum_test()\n        else:\n            raise NotImplementedError(f\"{self.rule} is not a valid \"\n                                      f\"rule of RazorCV.\")\n\n        self.cv_results[f\"param_{hyperparam}\"].mask = np.where(\n            (self._cv_means >= float(l_cutoff)) &\n            (self._cv_means <= float(h_cutoff)),\n            True, False)\n\n        if np.sum(self.cv_results[f\"param_{hyperparam}\"].mask) == 0:\n            print(f\"\\nLow: {l_cutoff}\")\n            print(f\"High: {h_cutoff}\")\n            print(f\"{self._cv_means}\")\n            print(f\"hyperparam: {hyperparam}\\n\")\n            raise ValueError(\"No valid grid columns remain within the \"\n                             \"boundaries of the specified razor\")\n\n        highest_surviving_rank = np.nanmin(\n            self.cv_results[f\"rank_test_{self.scoring}\"][\n                self.cv_results[f\"param_{hyperparam}\"].mask])\n\n        # print(f\"Highest surviving rank: {highest_surviving_rank}\\n\")\n\n        return np.flatnonzero(np.isin(\n            self.cv_results[f\"rank_test_{self.scoring}\"],\n            highest_surviving_rank))[0]\n\n    def call_standard_error(self):\n        \"\"\"\n        Returns the simplest model whose performance is within `sigma`\n        standard errors of the average highest performing model.\n        \"\"\"\n\n        # Estimate the standard error across folds for each column of the grid\n        cv_se = np.array(np.nanstd(self._score_grid, axis=1) /\n                         np.sqrt(self._n_folds))\n\n        # Determine confidence interval\n        if self.greater_is_better:\n            best_score_idx = np.nanargmax(self._cv_means)\n            h_cutoff = self._cv_means[best_score_idx] + cv_se[best_score_idx]\n            l_cutoff = self._cv_means[best_score_idx] - cv_se[best_score_idx]\n        else:\n            best_score_idx = np.nanargmin(self._cv_means)\n            h_cutoff = self._cv_means[best_score_idx] - cv_se[best_score_idx]\n            l_cutoff = self._cv_means[best_score_idx] + cv_se[best_score_idx]\n\n        return l_cutoff, h_cutoff\n\n    def call_rank_sum_test(self):\n        \"\"\"\n        Returns the simplest model whose paired performance across folds is\n        insignificantly different from the average highest performing,\n        at a predefined `alpha` level of significance.\n        \"\"\"\n\n        from scipy.stats import wilcoxon\n        import itertools\n\n        if self.greater_is_better:\n            best_score_idx = np.nanargmax(self._cv_means)\n        else:\n            best_score_idx = np.nanargmin(self._cv_means)\n\n        # Perform signed Wilcoxon rank sum test for each pair combination of\n        # columns against the best average score column\n        tests = [pair for pair in list(itertools.combinations(range(\n            self._score_grid.shape[0]), 2)) if best_score_idx in pair]\n\n        p_dict = {}\n        for i, test in enumerate(tests):\n            p_dict[i] = wilcoxon(self._score_grid[test[0], :],\n                                 self._score_grid[test[1], :])[1]\n\n        # Sort and prune away significant tests\n        p_dict = {k: v for k, v in sorted(p_dict.items(),\n                                          key=lambda item: item[1]) if\n                  v > self._alpha}\n\n        # Flatten list of tuples, remove best score index, and take the\n        # lowest and highest remaining bounds\n        tests = [j for j in list(set(list(sum([tests[i] for i in\n                                               list(p_dict.keys())],\n                                              ())))) if j != best_score_idx]\n        if self.greater_is_better:\n            h_cutoff = self._cv_means[\n                np.nanargmin(self.cv_results[\n                                 f\"rank_test_{self.scoring}\"][tests])]\n            l_cutoff = self._cv_means[\n                np.nanargmax(self.cv_results[\n                                 f\"rank_test_{self.scoring}\"][tests])]\n        else:\n            h_cutoff = self._cv_means[\n                np.nanargmax(self.cv_results[\n                                 f\"rank_test_{self.scoring}\"][tests])]\n            l_cutoff = self._cv_means[\n                np.nanargmin(self.cv_results[\n                                 f\"rank_test_{self.scoring}\"][tests])]\n\n        return l_cutoff, h_cutoff\n\n\n    def call_percentile(self):\n        \"\"\"\n        Returns the simplest model whose performance is within the `eta`\n        percentile of the average highest performing model.\n        \"\"\"\n\n        # Estimate the indicated percentile, and its inverse, across folds for\n        # each column of the grid\n        perc_cutoff = np.nanpercentile(self._score_grid,\n                                       [100 * self._eta,\n                                        100 - 100 * self._eta], axis=1)\n\n        # Determine bounds of the percentile interval\n        if self.greater_is_better:\n            best_score_idx = np.nanargmax(self._cv_means)\n            h_cutoff = perc_cutoff[0, best_score_idx]\n            l_cutoff = perc_cutoff[1, best_score_idx]\n        else:\n            best_score_idx = np.nanargmin(self._cv_means)\n            h_cutoff = perc_cutoff[0, best_score_idx]\n            l_cutoff = perc_cutoff[1, best_score_idx]\n\n        return l_cutoff, h_cutoff\n\n    @staticmethod\n    def simplify(param, scoring, rule='se', sigma=1, eta=0.68, alpha=0.01):\n        \"\"\"\n        Callable to be run as `refit` argument of `GridsearchCV`.\n\n        Parameters\n        ----------\n        param : str\n            Parameter with the largest influence on model complexity.\n        scoring : str\n            Refit scoring metric.\n        sigma : int\n            Number of standard errors tolerance in the case that a standard\n            error threshold is used to filter outlying scores across folds.\n            Only applicable if `rule`=='se'. Default is 1.\n        eta : float\n            Acceptable percent tolerance in the case that a percentile\n            threshold is used. Only applicable if `rule`=='percentile'.\n            Default is 0.68.\n        alpha : float\n            Alpha-level to use for signed wilcoxon rank sum testing.\n            Only applicable if `rule`=='ranksum'. Default is 0.01.\n        \"\"\"\n        from functools import partial\n\n        def razor_pass(\n                cv_results_, param, scoring, rule, sigma, alpha, eta\n        ):\n            rcv = Razors(cv_results_, param, scoring, rule=rule,\n                         sigma=sigma, alpha=alpha, eta=eta)\n            return rcv._best_low_complexity()\n\n        return partial(\n            razor_pass,\n            param=param,\n            scoring=scoring,\n            rule=rule,\n            sigma=sigma,\n            alpha=alpha,\n            eta=eta,\n        )\n\ndef divide_df(df_all,train_len):\n    return df_all.loc[:train_len-1], df_all.loc[train_len:].drop('target',axis=1)\n\ndef concat_df(train_data, test_data):\n    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)","metadata":{"_uuid":"07381d69-4197-43f3-9ab8-44ec5d3e32cc","_cell_guid":"cb66bafc-95ec-44f7-871c-b4d825158399","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T08:29:28.787042Z","iopub.execute_input":"2022-06-20T08:29:28.787419Z","iopub.status.idle":"2022-06-20T08:29:28.872654Z","shell.execute_reply.started":"2022-06-20T08:29:28.787384Z","shell.execute_reply":"2022-06-20T08:29:28.871703Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"preprocess = FunctionTransformer(preprocess_x_y)\nX_clean = preprocess.fit_transform(X=X)\nsurviving_features = list(X_clean.columns)","metadata":{"_uuid":"babc5fa2-709b-49bd-9ad2-f9753ac17822","_cell_guid":"2712eda4-f76c-499e-acae-26b8f5b934c8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T08:29:30.405846Z","iopub.execute_input":"2022-06-20T08:29:30.406127Z","iopub.status.idle":"2022-06-20T08:29:30.637707Z","shell.execute_reply.started":"2022-06-20T08:29:30.406096Z","shell.execute_reply":"2022-06-20T08:29:30.636687Z"},"trusted":true},"execution_count":141,"outputs":[{"name":"stdout","text":"Dropping ['target_len', 'target_NOUN', 'target_DET', 'target_ADJ', 'anchor_ADV', 'target_ADV'] for low variance...\n\nX:        Chemistry and Metallurgy  Electricity  Fixed Constructions  \\\n0                           0.0          0.0                  0.0   \n1                           0.0          0.0                  0.0   \n2                           0.0          0.0                  0.0   \n3                           0.0          0.0                  0.0   \n4                           0.0          0.0                  0.0   \n...                         ...          ...                  ...   \n36468                       0.0          0.0                  0.0   \n36469                       0.0          0.0                  0.0   \n36470                       0.0          0.0                  0.0   \n36471                       0.0          0.0                  0.0   \n36472                       0.0          0.0                  0.0   \n\n       Human Necessities  Mechanical Engineering  Operations and Transport  \\\n0                    1.0                     0.0                       0.0   \n1                    1.0                     0.0                       0.0   \n2                    1.0                     0.0                       0.0   \n3                    1.0                     0.0                       0.0   \n4                    1.0                     0.0                       0.0   \n...                  ...                     ...                       ...   \n36468                0.0                     0.0                       1.0   \n36469                0.0                     0.0                       1.0   \n36470                0.0                     0.0                       1.0   \n36471                0.0                     0.0                       1.0   \n36472                0.0                     0.0                       1.0   \n\n       Physics  Textiles  anchor_len  anchor_VERB  target_VERB  anchor_NOUN  \\\n0          0.0       0.0        0.00          0.0       0.0000          0.2   \n1          0.0       0.0        0.00          0.0       0.3333          0.2   \n2          0.0       0.0        0.00          0.0       0.0000          0.2   \n3          0.0       0.0        0.00          0.0       0.3333          0.2   \n4          0.0       0.0        0.00          0.0       0.0000          0.2   \n...        ...       ...         ...          ...          ...          ...   \n36468      0.0       0.0        0.25          0.0       0.0000          0.4   \n36469      0.0       0.0        0.25          0.0       0.0000          0.4   \n36470      0.0       0.0        0.25          0.0       0.0000          0.4   \n36471      0.0       0.0        0.25          0.0       0.0000          0.4   \n36472      0.0       0.0        0.25          0.0       0.0000          0.4   \n\n       anchor_ADJ  anchor_in_target  target_in_anchor  anchor_target_cos_sim  \\\n0             0.0               1.0               0.0                 0.8874   \n1             0.0               0.0               0.0                 0.6258   \n2             0.0               0.0               0.0                 0.3800   \n3             0.0               0.0               0.0                 0.4656   \n4             0.0               0.0               0.0                 0.3280   \n...           ...               ...               ...                    ...   \n36468         0.0               0.0               0.0                 0.8904   \n36469         0.0               0.0               0.0                 0.6620   \n36470         0.0               0.0               0.0                 0.6745   \n36471         0.0               0.0               0.0                 0.7665   \n36472         0.0               0.0               0.0                 0.6140   \n\n       predictions_deberta-v3-5folds  predictions_xlm-roberta-large-5folds  \n0                             0.3834                                0.4468  \n1                             0.6648                                0.5365  \n2                             0.2908                                0.2199  \n3                             0.3702                                0.3506  \n4                             0.2285                                0.1749  \n...                              ...                                   ...  \n36468                         0.9755                                0.3980  \n36469                         0.4509                                0.2585  \n36470                         0.4991                                0.2849  \n36471                         0.7399                                0.3643  \n36472                         0.4841                                0.2878  \n\n[36473 rows x 18 columns]\n\nFeatures: ['Chemistry and Metallurgy', 'Electricity', 'Fixed Constructions', 'Human Necessities', 'Mechanical Engineering', 'Operations and Transport', 'Physics', 'Textiles', 'anchor_len', 'anchor_VERB', 'target_VERB', 'anchor_NOUN', 'anchor_ADJ', 'anchor_in_target', 'target_in_anchor', 'anchor_target_cos_sim', 'predictions_deberta-v3-5folds', 'predictions_xlm-roberta-large-5folds']\n\n","output_type":"stream"}]},{"cell_type":"code","source":"seed=42\nX_train, X_test, y_train, y_test = train_test_split(X_clean, y, random_state=seed)\n\nX_train = X_train.reset_index(drop=True)\ny_train = pd.DataFrame(y_train).reset_index(drop=True)\n\nX_train = X_train.head(10000)\ny_train = y_train.head(10000)\n\nX_test = X_test.reset_index(drop=True)\ny_test = pd.DataFrame(y_test).reset_index(drop=True)\n\nX_test = X_test.head(2000)\ny_test = y_test.head(2000)","metadata":{"_uuid":"2013efce-e219-44ea-9b4f-3fcaf00e7a1a","_cell_guid":"caa0b740-b39a-4181-b506-39e5829c1997","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T08:16:36.378584Z","iopub.execute_input":"2022-06-20T08:16:36.378862Z","iopub.status.idle":"2022-06-20T08:16:36.399696Z","shell.execute_reply.started":"2022-06-20T08:16:36.378830Z","shell.execute_reply":"2022-06-20T08:16:36.398542Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"models = [\n            'rf'\n         ]\n\nestimators = [\n        RandomForestRegressor(random_state=42, min_samples_split=3)\n]","metadata":{"_uuid":"c795674c-3eba-46df-9ba0-107ffcc738fc","_cell_guid":"1cae2f7f-40b3-42cc-9d3c-2b5b2dca76bd","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T08:20:07.296874Z","iopub.execute_input":"2022-06-20T08:20:07.297292Z","iopub.status.idle":"2022-06-20T08:20:07.302633Z","shell.execute_reply.started":"2022-06-20T08:20:07.297245Z","shell.execute_reply":"2022-06-20T08:20:07.301288Z"},"trusted":true},"execution_count":132,"outputs":[]},{"cell_type":"code","source":"params={models[0]: {\n                    'max_depth': [3, 5, 7],\n                    'n_estimators': [125, 150, 200, 250, 300],\n                    'min_samples_leaf': [3, 5, 7]\n                   }\n       }","metadata":{"_uuid":"4c5a010d-7329-46a0-b904-4af8032697d6","_cell_guid":"3cb8358e-126b-4b91-ae6f-ba4d70386c2a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T08:30:48.775643Z","iopub.execute_input":"2022-06-20T08:30:48.775948Z","iopub.status.idle":"2022-06-20T08:30:48.784307Z","shell.execute_reply.started":"2022-06-20T08:30:48.775917Z","shell.execute_reply":"2022-06-20T08:30:48.780721Z"},"trusted":true},"execution_count":142,"outputs":[]},{"cell_type":"code","source":"model_factory = {}\n\ninner_scoring = \"neg_mean_absolute_error\"\n\nfor name, estimator in zip(models, estimators):\n    print(name)\n    model_factory[name] = {}\n    \n    pipe = Pipeline([\n        (name, TransformedTargetRegressor(regressor=estimator, transformer=MinMaxScaler()))\n    ])\n    model_params = {}\n    for hyperparam in params[name].keys():\n        model_params[f\"{name}__regressor__{hyperparam}\"] = params[name][hyperparam]\n    pipe_grid_cv = GridSearchCV(pipe, model_params, scoring=[inner_scoring], \n                       refit=Razors.simplify(param=f'{name}__regressor__n_estimators', \n                                             scoring=inner_scoring, rule=\"se\", sigma=1), \n                       cv=KFold(n_splits=5, shuffle=True, random_state=seed), n_jobs=-1)\n    pipe_grid_cv.fit(X_train, y_train.values.ravel())\n    model_factory[name]['oos_score'] = cross_val_score(pipe_grid_cv, X_test, y_test.values.ravel(), \n                                                       scoring='r2', \n                                                       cv=KFold(n_splits=5, shuffle=True, \n                                                                random_state=seed + 1))\n    model_factory[name]['best_params'] = pipe_grid_cv.best_params_\n    model_factory[name]['best_estimator'] = pipe_grid_cv.best_estimator_\n\nleaderboard = {}\nfor mod in model_factory.keys():\n    leaderboard[mod] = np.mean(model_factory[mod]['oos_score'])\n\nbest_estimator_name = max(leaderboard, key=leaderboard.get)\n\nbest_estimator = model_factory[best_estimator_name]['best_estimator']\n\nmodel_factory","metadata":{"_uuid":"8036d58b-7c10-49bf-a571-6a0567094cff","_cell_guid":"47c28da5-8a5f-4096-a8f2-38710f345686","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T08:30:54.471793Z","iopub.execute_input":"2022-06-20T08:30:54.472097Z","iopub.status.idle":"2022-06-20T08:35:49.182381Z","shell.execute_reply.started":"2022-06-20T08:30:54.472064Z","shell.execute_reply":"2022-06-20T08:35:49.180417Z"},"trusted":true},"execution_count":143,"outputs":[{"name":"stdout","text":"rf\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_34/861897713.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                              scoring=inner_scoring, rule=\"se\", sigma=1), \n\u001b[1;32m     18\u001b[0m                        cv=KFold(n_splits=5, shuffle=True, random_state=seed), n_jobs=-1)\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mpipe_grid_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     model_factory[name]['oos_score'] = cross_val_score(pipe_grid_cv, X_test, y_test.values.ravel(), \n\u001b[1;32m     21\u001b[0m                                                        \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"model_factory[name]['best_params']","metadata":{"_uuid":"97d22c7f-b8a9-4e0f-8184-635733fd552c","_cell_guid":"424275f0-4842-4f8c-9144-623804168b6a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T08:35:49.184083Z","iopub.status.idle":"2022-06-20T08:35:49.185048Z","shell.execute_reply.started":"2022-06-20T08:35:49.184746Z","shell.execute_reply":"2022-06-20T08:35:49.184778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outer_best = KFold(n_splits=5, shuffle=True, random_state=seed)\n\nbest_estimator.fit(X_clean, y)\n\nscores = cross_val_score(best_estimator, X_clean, y, scoring='r2', cv=outer_best, n_jobs=-1, error_score='raise')\nscores","metadata":{"_uuid":"b1d45736-646e-4036-98ef-126d90fde156","_cell_guid":"759be8eb-545f-42c1-aa8b-7b465db135e7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T07:33:36.154259Z","iopub.status.idle":"2022-06-20T07:33:36.154883Z","shell.execute_reply.started":"2022-06-20T07:33:36.154553Z","shell.execute_reply":"2022-06-20T07:33:36.154591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_estimator.named_steps['rf'].regressor_.feature_importances_","metadata":{"execution":{"iopub.status.busy":"2022-06-20T07:33:36.158559Z","iopub.status.idle":"2022-06-20T07:33:36.159744Z","shell.execute_reply.started":"2022-06-20T07:33:36.159373Z","shell.execute_reply":"2022-06-20T07:33:36.159423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = (\n    f\"/kaggle/working/rf_model.joblib\"\n)\ndump(best_estimator, model_path)","metadata":{"_uuid":"aad5fc5b-78b8-4bd7-b3ca-b4097950aad0","_cell_guid":"b4965bcb-bb94-422b-99b6-4a6f29e5ad94","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T07:33:36.162751Z","iopub.status.idle":"2022-06-20T07:33:36.163448Z","shell.execute_reply.started":"2022-06-20T07:33:36.163030Z","shell.execute_reply":"2022-06-20T07:33:36.163063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('../input/us-patent-phrase-to-phrase-matching/sample_submission.csv')","metadata":{"_uuid":"6d5556c8-1701-499c-a956-3d8b3152f27e","_cell_guid":"26c18b6f-bbd2-44d7-be32-04ab3ddcf43e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T07:33:36.166083Z","iopub.status.idle":"2022-06-20T07:33:36.168547Z","shell.execute_reply.started":"2022-06-20T07:33:36.168171Z","shell.execute_reply":"2022-06-20T07:33:36.168207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler()\ny_pred = best_estimator.predict(pd.DataFrame(scaler.fit_transform(test[surviving_features]), columns=surviving_features))","metadata":{"_uuid":"872795a1-5df7-47e3-b646-8457869d79db","_cell_guid":"5798fccc-7530-4166-a31d-82295021445b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T07:33:36.169849Z","iopub.status.idle":"2022-06-20T07:33:36.170404Z","shell.execute_reply.started":"2022-06-20T07:33:36.170068Z","shell.execute_reply":"2022-06-20T07:33:36.170100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['id'] = test['id']\nsubmission['score'] = y_pred","metadata":{"_uuid":"e87dd27c-b526-4099-80a7-680fd95e7d09","_cell_guid":"9822b0f9-7585-4c97-992d-b0b18cbcc8b0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T07:33:36.172265Z","iopub.status.idle":"2022-06-20T07:33:36.173052Z","shell.execute_reply.started":"2022-06-20T07:33:36.172518Z","shell.execute_reply":"2022-06-20T07:33:36.172741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"_uuid":"804eee29-db36-4b3a-9229-b78f2f05bf59","_cell_guid":"35399c7a-1c57-40db-aeac-4f6b8e9b0ece","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T07:33:36.176006Z","iopub.status.idle":"2022-06-20T07:33:36.177161Z","shell.execute_reply.started":"2022-06-20T07:33:36.176838Z","shell.execute_reply":"2022-06-20T07:33:36.176872Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
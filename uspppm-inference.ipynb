{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f6244f3",
   "metadata": {
    "_cell_guid": "62ad6f3d-b227-4aaf-93bb-ca4860556fd2",
    "_uuid": "a942c950-ef86-481e-9bdd-4fc8ac222320",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-19T18:55:46.061053Z",
     "iopub.status.busy": "2022-06-19T18:55:46.060200Z",
     "iopub.status.idle": "2022-06-19T18:55:58.425690Z",
     "shell.execute_reply": "2022-06-19T18:55:58.424913Z",
     "shell.execute_reply.started": "2022-06-19T18:41:07.403675Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 12.411153,
     "end_time": "2022-06-19T18:55:58.425853",
     "exception": false,
     "start_time": "2022-06-19T18:55:46.014700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import spacy\n",
    "import nltk\n",
    "import itertools\n",
    "import unicodedata\n",
    "import datasets, transformers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from joblib import dump\n",
    "from scipy import stats\n",
    "from itertools import groupby\n",
    "from joblib import parallel_backend\n",
    "from sklearn import linear_model, decomposition\n",
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "from sklearn import metrics\n",
    "from joblib import Parallel, delayed\n",
    "from transformers import TrainingArguments, Trainer, AutoModelForSequenceClassification, AutoTokenizer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, FunctionTransformer, OneHotEncoder, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, IsolationForest\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate, cross_val_score, train_test_split, KFold\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin, clone, RegressorMixin\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.lang.char_classes import CONCAT_QUOTES, LIST_ELLIPSES, LIST_ICONS, ALPHA, ALPHA_LOWER, ALPHA_UPPER\n",
    "from spacy.util import compile_infix_regex\n",
    "# from scispacy.abbreviation import AbbreviationDetector\n",
    "from spacy.pipeline import EntityRecognizer\n",
    "\n",
    "try:\n",
    "    from sklearn.utils._testing import ignore_warnings\n",
    "except:\n",
    "    from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ae09ab6",
   "metadata": {
    "_cell_guid": "5d404e17-1ab3-461b-b39f-71a493cdd0ef",
    "_uuid": "e258ea08-693b-4f1a-a98f-52bb71b64865",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-19T18:55:58.499143Z",
     "iopub.status.busy": "2022-06-19T18:55:58.498290Z",
     "iopub.status.idle": "2022-06-19T18:55:58.500748Z",
     "shell.execute_reply": "2022-06-19T18:55:58.500299Z",
     "shell.execute_reply.started": "2022-06-19T17:17:00.391484Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.036505,
     "end_time": "2022-06-19T18:55:58.500862",
     "exception": false,
     "start_time": "2022-06-19T18:55:58.464357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    input_path = '../input/us-patent-phrase-to-phrase-matching/'\n",
    "    model_path = ['../input/deberta-v3-5folds/',\n",
    "                  '../input/bert-for-patent-5fold/', \n",
    "#                   '../input/deberta-large-v1/',\n",
    "#                   '../input/xlm-roberta-large-5folds/',\n",
    "                 ]\n",
    "    model_num = 2\n",
    "    num_fold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d1d765b",
   "metadata": {
    "_cell_guid": "147479a7-c7c8-472f-bfdd-2c560020546b",
    "_uuid": "561bcb8c-31c6-4e52-b925-97112600781b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-19T18:55:58.564309Z",
     "iopub.status.busy": "2022-06-19T18:55:58.563810Z",
     "iopub.status.idle": "2022-06-19T18:56:03.887254Z",
     "shell.execute_reply": "2022-06-19T18:56:03.886751Z",
     "shell.execute_reply.started": "2022-06-19T17:17:02.895910Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 5.356828,
     "end_time": "2022-06-19T18:56:03.887393",
     "exception": false,
     "start_time": "2022-06-19T18:55:58.530565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "# nlp.add_pipe(\"abbreviation_detector\")\n",
    "re_token_match = spacy.tokenizer._get_regex_pattern(nlp.Defaults.token_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d20347ee",
   "metadata": {
    "_cell_guid": "ba02c35f-90b7-4f80-905b-0391f96f2347",
    "_uuid": "8238d081-b92b-434a-8b85-4329fbcb278f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-19T18:56:03.985811Z",
     "iopub.status.busy": "2022-06-19T18:56:03.984804Z",
     "iopub.status.idle": "2022-06-19T18:56:04.025981Z",
     "shell.execute_reply": "2022-06-19T18:56:04.025497Z",
     "shell.execute_reply.started": "2022-06-19T17:17:06.833719Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.105873,
     "end_time": "2022-06-19T18:56:04.026120",
     "exception": false,
     "start_time": "2022-06-19T18:56:03.920247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "pd.set_option('display.precision', 4)\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "# pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.width', 1000)\n",
    "\n",
    "cm = sns.light_palette('green', as_cmap=True)\n",
    "props_param = \"color:white; font-weight:bold; background-color:green;\"\n",
    "\n",
    "CUSTOM_SEED = 42\n",
    "CUSTOM_BATCH = 24\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Stopwords and infixes\n",
    "ADDITIONAL_STOPWORDS = ['one or more', 'a', 'needn', 'a', 'not', 'able', 'never', 'about', 'neednâ€™t', 'accordance', 'now', 'often', 'above', 'no', 'according', 'of', 'mentioned', 'others', 'after', 'nor', 'all', 'on', 'accordingly', 'otherwise', 'again', 'not', 'also', 'onto', 'across', 'overall', 'against', 'now', 'an', 'or', 'along', 'rather', 'ain', 'o', 'and', 'other', 'already', 'remarkably', 'all', 'of', 'another', 'particularly', 'alternatively', 'significantly', 'am', 'off', 'are', 'preferably', 'always', 'simply', 'an', 'on', 'as', 'preferred', 'among', 'sometimes', 'and', 'once', 'at', 'present', 'and/or', 'specifically', 'any', 'only', 'be', 'provide', 'anything', 'straight', 'are', 'or', 'because', 'provided', 'anywhere', 'forward', 'aren', 'other', 'been', 'provides', 'better', 'substantially', 'arenâ€™t', 'our', 'being', 'relatively', 'disclosure', 'thereafter', 'as', 'ours', 'by', 'respectively', 'due', 'therebetween', 'at', 'ourselves', 'claim', 'said', 'easily', 'therefor', 'be', 'out', 'comprises', 'comprising', 'should', 'easy', 'therefrom', 'because', 'over', 'since', 'e.g', 'therein', 'been', 'own', 'could', 'some', 'either', 'thereinto', 'before', 're', 'described', 'such', 'elsewhere', 'thereon', 'being', 's', 'desired', 'suitable', 'enough', 'therethrough', 'below', 'same', 'do', 'than', 'especially', 'therewith', 'between', 'shan', 'does', 'that', 'essentially', 'together', 'both', 'shanâ€™t', 'each', 'the', 'et', 'al', 'toward', 'but', 'she', 'embodiment', 'their', 'etc', 'towards', 'by', 'sheâ€™s', 'fig', 'then', 'eventually', 'typical', 'can', 'should', 'figs', 'there', 'excellent', 'upon', 'couldn', 'shouldâ€™ve', 'for', 'thereby', 'finally', 'via', 'couldnâ€™t', 'shouldn', 'from', 'therefore', 'furthermore', 'vice', 'versa', 'd', 'shouldnâ€™t', 'further', 'thereof', 'good', 'whatever', 'did', 'so', 'generally', 'thereto', 'hence', 'whereas', 'didn', 'some', 'had', 'these', 'he/she', 'whereat', 'didnâ€™t', 'such', 'has', 'they', 'him/her', 'wherever', 'do', 't', 'have', 'this', 'his/her', 'whether', 'does', 'than', 'having', 'those', 'ie', 'whose', 'doesn', 'that', 'herein', 'thus', 'ii', 'within', 'doesnâ€™t', 'thatâ€™ll', 'however', 'to', 'iii', 'without', 'doing', 'the', 'if', 'use', 'instead', 'yet', 'don', 'their', 'in', 'various', 'later', 'donâ€™t', 'theirs', 'into', 'was', 'like', 'down', 'them', 'invention', 'were', 'little', 'during', 'themselves', 'is', 'what', 'many', 'each', 'there', 'it', 'when', 'may', 'few', 'these', 'its', 'where', 'meanwhile', 'for', 'they', 'means', 'whereby', 'might', 'from', 'this', 'wherein', 'moreover', 'further', 'those', 'which', 'much', 'had', 'through', 'while', 'must', 'hadn', 'to', 'who', 'hadnâ€™t', 'too', 'will', 'has', 'under', 'with', 'hasn', 'until', 'Would', 'hasnâ€™t', 'up', 'have', 've', 'haven', 'very', 'havenâ€™t', 'was', 'having', 'wasn', 'he', 'wasnâ€™t', 'her', 'we', 'here', 'were', 'hers', 'weren', 'herself', 'werenâ€™t', 'him', 'what', 'himself', 'when', 'his', 'where', 'how', 'which', 'i', 'while', 'if', 'who', 'in', 'whom', 'into', 'why', 'is', 'will', 'isn', 'with', 'isnâ€™t', 'won', 'it', 'wonâ€™t', 'itâ€™s', 'wouldn', 'its', 'wouldnâ€™t', 'itself', 'y', 'just', 'you', 'll', 'youâ€™d', 'm', 'youâ€™ll', 'ma', 'youâ€™re', 'me', 'youâ€™ve', 'mightn', 'your', 'mightnâ€™t', 'yours', 'more', 'yourself', 'most', 'yourselves', 'mustn', 'mustnâ€™t', 'my', 'myself']\n",
    "\n",
    "puncts = ['\\u200d','?', '....','..','...','', ',', '.', '\"', ':', ')', '(', '-', '!', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '*', '+', '\\\\',\n",
    "    'â€¢', '~', 'Â£', 'Â·', '_', '{', '}', 'Â©', '^', 'Â®', '`',  '<', 'â†’', 'Â°', 'â‚¬', 'â„¢', 'â€º',  'â™¥', 'â†', 'Ã—', 'Â§', 'â€³', 'â€²', 'Ã‚', 'â–ˆ',\n",
    "    'Â½', 'Ã ', 'â€¦', 'â€œ', 'â˜…', 'â€', 'â€“', 'â—', 'Ã¢', 'â–º', 'âˆ’', 'Â¢', 'Â²', 'Â¬', 'â–‘', 'Â¶', 'â†‘', 'Â±', 'Â¿', 'â–¾', 'â•', 'Â¦', 'â•‘', 'â€•', 'Â¥', 'â–“',\n",
    "    'â€”', 'â€¹', 'â”€', 'â–’', 'ï¼š', 'Â¼', 'âŠ•', 'â–¼', 'â–ª', 'â€ ', 'â– ', 'â€™', 'â–€', 'Â¨', 'â–„', 'â™«', 'â˜†', 'Ã©', 'Â¯', 'â™¦', 'Â¤', 'â–²', 'Ã¨', 'Â¸', 'Â¾',\n",
    "    'Ãƒ', 'â‹…', 'â€˜', 'âˆž', 'âˆ™', 'ï¼‰', 'â†“', 'ã€', 'â”‚', 'ï¼ˆ', 'Â»', 'ï¼Œ', 'â™ª', 'â•©', 'â•š', 'Â³', 'ãƒ»', 'â•¦', 'â•£', 'â•”', 'â•—', 'â–¬', 'â¤', 'Ã¯', 'Ã˜',\n",
    "    'Â¹', 'â‰¤', 'â€¡', 'âˆš', '!','ðŸ…°','ðŸ…±']\n",
    "\n",
    "infixes = (\n",
    "    LIST_ELLIPSES\n",
    "    + LIST_ICONS\n",
    "    + [\n",
    "        r\"(?<=[0-9])[+\\-\\*^](?=[0-9-])\",\n",
    "        r\"(?<=[{al}{q}])\\.(?=[{au}{q}])\".format(\n",
    "            al=ALPHA_LOWER, au=ALPHA_UPPER, q=CONCAT_QUOTES\n",
    "        ),\n",
    "        r\"(?<=[{a}]),(?=[{a}])\".format(a=ALPHA),\n",
    "        # âœ… Commented out regex that splits on hyphens between letters:\n",
    "        # r\"(?<=[{a}])(?:{h})(?=[{a}])\".format(a=ALPHA, h=HYPHENS),\n",
    "        r\"(?<=[{a}0-9])[:<>=/](?=[{a}])\".format(a=ALPHA),\n",
    "        r'''[-~]'''\n",
    "    ]\n",
    ")\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english') + ADDITIONAL_STOPWORDS\n",
    "\n",
    "prefix_re = spacy.util.compile_prefix_regex(nlp.Defaults.prefixes)\n",
    "suffix_re = spacy.util.compile_suffix_regex(nlp.Defaults.suffixes)\n",
    "infix_re = compile_infix_regex(infixes)\n",
    "\n",
    "def customize_tokenizer(nlp):\n",
    "    # Adds support to use `-` as the delimiter for tokenization\n",
    "    return Tokenizer(nlp.vocab, prefix_search=prefix_re.search,\n",
    "                     suffix_search=suffix_re.search,\n",
    "                     infix_finditer=infix_re.finditer,\n",
    "                     token_match=None\n",
    "                    )\n",
    "\n",
    "nlp.tokenizer = customize_tokenizer(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0795aa99",
   "metadata": {
    "_cell_guid": "d97adb40-4f30-487b-aa22-c14a50be0f17",
    "_uuid": "102bd6d4-c302-4fde-995f-decacdbce996",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-19T18:56:04.094306Z",
     "iopub.status.busy": "2022-06-19T18:56:04.093738Z",
     "iopub.status.idle": "2022-06-19T18:56:04.097714Z",
     "shell.execute_reply": "2022-06-19T18:56:04.097195Z",
     "shell.execute_reply.started": "2022-06-19T17:17:08.926499Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.038328,
     "end_time": "2022-06-19T18:56:04.097840",
     "exception": false,
     "start_time": "2022-06-19T18:56:04.059512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "table = {\n",
    "'A': 'Human Necessities',\n",
    "'B': 'Operations and Transport',\n",
    "'C': 'Chemistry and Metallurgy',\n",
    "'D': 'Textiles',\n",
    "'E': 'Fixed Constructions',\n",
    "'F': 'Mechanical Engineering',\n",
    "'G': 'Physics',\n",
    "'H': 'Electricity',\n",
    "'Y': 'Emerging Cross-Sectional Technologies'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd2998ef",
   "metadata": {
    "_cell_guid": "4047b6a7-5604-4be7-ab3c-b02d7ea18512",
    "_uuid": "d75199e1-2d90-4925-8857-fc15aa97eee9",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-19T18:56:04.174410Z",
     "iopub.status.busy": "2022-06-19T18:56:04.169110Z",
     "iopub.status.idle": "2022-06-19T18:56:04.188512Z",
     "shell.execute_reply": "2022-06-19T18:56:04.187981Z",
     "shell.execute_reply.started": "2022-06-19T17:17:11.332290Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.060645,
     "end_time": "2022-06-19T18:56:04.188644",
     "exception": false,
     "start_time": "2022-06-19T18:56:04.127999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_from_list(x, stuff_to_remove) -> list:\n",
    "    for item in stuff_to_remove:\n",
    "        # Making sure to iterate through the entire token\n",
    "        for i,token in enumerate(x):\n",
    "            if item == token:\n",
    "                del x[i]\n",
    "    return x\n",
    "\n",
    "def Remove_Duplicates(text_in):\n",
    "    return re.sub(r\"\\b(\\w+)(?:\\W\\1\\b)+\", r\"\\1\", text_in, flags=re.IGNORECASE)\n",
    "\n",
    "\n",
    "def remove_consecutive_nums(text):\n",
    "    # Remove any chunks of consecutive numbers\n",
    "    number_strings = re.findall(r'\\d+[ \\t]\\d+', text)\n",
    "    ind_num_strings = []\n",
    "    for j in number_strings:\n",
    "        x = [int(i) for i in j.split()]\n",
    "        ind_num_strings.append(x)\n",
    "\n",
    "    flat_num_list = [item for sublist in ind_num_strings for item in sublist]\n",
    "\n",
    "    for i in flat_num_list:\n",
    "        j=re.sub(r'\\d+','',str(i))\n",
    "        text = text.replace(str(i),j)\n",
    "    return text\n",
    "\n",
    "\n",
    "def basic_clean(text_list, infixes, stopwords):\n",
    "    \"\"\"\n",
    "    A simple function to clean up the data. All the words that\n",
    "    are not designated as a stop word is then lemmatized after\n",
    "    encoding and basic regex parsing are performed.\n",
    "    \"\"\"\n",
    "\n",
    "    text_list_clean = []\n",
    "    for text in text_list:\n",
    "        text = re.sub(r'[\\)\\(\\.\\,\\;\\\\\\?\\&\\%\\!\\+\\-]', '', re.sub(r'[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f\\x7f-\\xff\\xad\\x0c6Â§\\\\\\Â£\\Ã‚*_<>\"\"âŽ«â€¢{}Î“~]', ' ', str(' '.join(re.split('\\s*-\\s*', text)))))\n",
    "        if len(text.split(\"  \")) > 1000:\n",
    "            text = \" \".join([\"\".join(w.split(\" \")) if len(w.split(' '))>1 else w for w in text.split(\"  \")])\n",
    "        text_list_clean.append([i for i in remove_from_list(re.sub('\\s+', ' ', re.sub('\\s\\s+', ' ', re.sub('\\s+\\s+', ' ', Remove_Duplicates(re.sub(r\"\\b(?=[mdclxvii])m{0,4}(cm|cd|d?c{0,3})(xc|xl|l?x{0,3})([ii]x|[ii]v|v?[ii]{0,3})\\b\\.?\", '', (unicodedata.normalize('NFKD', re.sub(' +', ' ', re.sub(r\"\\s+\\s+\",\" \", re.sub(r\"\\\\,\",\",\", re.sub(r\" \\,\",\",\", re.sub(r\"\\\\.\",\".\", re.sub(r\" \\.\",\".\", re.sub(r\"\\(\\s+\\)\",\"\", re.sub(r\"\\(\\)\",\"\", re.sub(r\" \\)\",\"\", re.sub(r\"\\( \",\"\", remove_consecutive_nums(re.sub(r\"\\s+\",\" \", re.sub(r\"([A-z])\\- ([A-z])\", r\"\\1\\2\", re.sub(r'\\s', ' ', text)).replace('\\'','').replace('. .', '.').replace('\\'',''))))))))))))).lower())\n",
    "        .encode('ascii', 'ignore')\n",
    "        .decode('utf-8', 'ignore')\n",
    "        .lower())))))).split(), puncts) if not i.isdigit() or i in stopwords])\n",
    "        del text\n",
    "\n",
    "    return '. '.join(x.strip().capitalize() for x in '. '.join(' '.join([word for word in sent]) for sent in text_list_clean).split('.')) + '.'\n",
    "\n",
    "\n",
    "def get_cpc_texts():\n",
    "    \"\"\"\n",
    "    Function taken from Y Nakama's notebook:\n",
    "    https://www.kaggle.com/code/yasufuminakama/pppm-deberta-v3-large-baseline-w-w-b-train\n",
    "    \"\"\"\n",
    "    contexts = []\n",
    "    pattern = '[A-Z]\\d+'\n",
    "    for file_name in os.listdir('cpc-data/CPCSchemeXML202105'):\n",
    "        result = re.findall(pattern, file_name)\n",
    "        if result:\n",
    "            contexts.append(result)\n",
    "    contexts = sorted(set(sum(contexts, [])))\n",
    "    results = {}\n",
    "    for cpc in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'Y']:\n",
    "        with open(f'cpc-data/CPCTitleList202202/cpc-section-{cpc}_20220201.txt') as f:\n",
    "            s = f.read()\n",
    "        pattern = f'{cpc}\\t\\t.+'\n",
    "        result = re.findall(pattern, s)\n",
    "        cpc_result = result[0].lstrip(pattern)\n",
    "        for context in [c for c in contexts if c[0] == cpc]:\n",
    "            pattern = f'{context}\\t\\t.+'\n",
    "            result = re.findall(pattern, s)\n",
    "            results[context] = cpc_result + \". \" + result[0].lstrip(pattern)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8081cc3a",
   "metadata": {
    "_cell_guid": "4ec8f13b-391a-48c7-a86c-c35526506b16",
    "_uuid": "f3ffefe0-201e-4750-b043-c76da4bab192",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-19T18:56:04.263634Z",
     "iopub.status.busy": "2022-06-19T18:56:04.263028Z",
     "iopub.status.idle": "2022-06-19T18:56:04.352745Z",
     "shell.execute_reply": "2022-06-19T18:56:04.352146Z",
     "shell.execute_reply.started": "2022-06-19T17:17:14.470569Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.129234,
     "end_time": "2022-06-19T18:56:04.352972",
     "exception": false,
     "start_time": "2022-06-19T18:56:04.223738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/us-patent-phrase-to-phrase-matching/train.csv')\n",
    "test = pd.read_csv('../input/us-patent-phrase-to-phrase-matching/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59f857fe",
   "metadata": {
    "_cell_guid": "cd06dd39-bba8-4aec-a547-23fe3ec4a32e",
    "_uuid": "c05280f7-90a1-49ce-9868-0f03aaff67b9",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-19T18:56:04.460341Z",
     "iopub.status.busy": "2022-06-19T18:56:04.457412Z",
     "iopub.status.idle": "2022-06-19T18:56:04.733323Z",
     "shell.execute_reply": "2022-06-19T18:56:04.734045Z",
     "shell.execute_reply.started": "2022-06-19T17:17:16.669013Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.346677,
     "end_time": "2022-06-19T18:56:04.734224",
     "exception": false,
     "start_time": "2022-06-19T18:56:04.387547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['general_context'] = train['context'].apply(lambda x: table[x[0].upper()])\n",
    "test['general_context'] = test['context'].apply(lambda x: table[x[0].upper()])\n",
    "\n",
    "train = pd.concat([train, pd.get_dummies(train['general_context'])], axis=1)\n",
    "test = pd.concat([test, pd.get_dummies(test['general_context'])], axis=1)\n",
    "\n",
    "cpc_texts = torch.load(f\"../input/cpc-texts/cpc_texts.pth\")\n",
    "train['context_text'] = train['context'].map(cpc_texts)\n",
    "test['context_text'] = test['context'].map(cpc_texts)\n",
    "\n",
    "train['section'] = train['context'].astype(str).str[0]\n",
    "train['classes'] = train['context'].astype(str).str[1:]\n",
    "test['section'] = test['context'].astype(str).str[0]\n",
    "test['classes'] = test['context'].astype(str).str[1:]\n",
    "\n",
    "train['num_anchor'] = train['anchor'].str.contains('[0-9]', na=False)\n",
    "train['anchor_len'] = train['anchor'].str.split().str.len()\n",
    "train['num_target'] = train['target'].str.contains('[0-9]', na=False)\n",
    "train['target_len'] = train['target'].str.split().str.len()\n",
    "\n",
    "test['num_anchor'] = test['anchor'].str.contains('[0-9]', na=False)\n",
    "test['anchor_len'] = test['anchor'].str.split().str.len()\n",
    "test['num_target'] = test['target'].str.contains('[0-9]', na=False)\n",
    "test['target_len'] = test['target'].str.split().str.len()\n",
    "\n",
    "train['num_anchor_stops'] = test['anchor'].str.count('|'.join(stopwords))\n",
    "test['num_anchor_stops'] = test['anchor'].str.count('|'.join(stopwords))\n",
    "train['num_target_stops'] = test['target'].str.count('|'.join(stopwords))\n",
    "test['num_target_stops'] = test['target'].str.count('|'.join(stopwords))\n",
    "\n",
    "train['dataset'] = 'train'\n",
    "test['dataset'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07f6b4d5",
   "metadata": {
    "_cell_guid": "ad17e21f-04a5-43a8-87f3-91a9694e6806",
    "_uuid": "75838474-5f7f-4ee7-8362-9bc40a853e1b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-19T18:56:04.805533Z",
     "iopub.status.busy": "2022-06-19T18:56:04.804519Z",
     "iopub.status.idle": "2022-06-19T18:56:04.835680Z",
     "shell.execute_reply": "2022-06-19T18:56:04.834819Z",
     "shell.execute_reply.started": "2022-06-19T17:17:21.459582Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.069059,
     "end_time": "2022-06-19T18:56:04.835808",
     "exception": false,
     "start_time": "2022-06-19T18:56:04.766749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.loc[~train.index.duplicated(keep='first')]\n",
    "test = test.loc[~test.index.duplicated(keep='first')]\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "df_all = train.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "490f662d",
   "metadata": {
    "_cell_guid": "a2ded0a7-ecc0-4625-9798-b1af9d525c51",
    "_uuid": "f5aeb6b5-62a0-434d-a5d8-b09d05215ac0",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-19T18:56:04.905721Z",
     "iopub.status.busy": "2022-06-19T18:56:04.903115Z",
     "iopub.status.idle": "2022-06-19T19:01:44.301629Z",
     "shell.execute_reply": "2022-06-19T19:01:44.301113Z",
     "shell.execute_reply.started": "2022-06-19T17:17:22.921877Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 339.435771,
     "end_time": "2022-06-19T19:01:44.301777",
     "exception": false,
     "start_time": "2022-06-19T18:56:04.866006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all['anchor_parsed'] = df_all['anchor'].apply(\n",
    "    lambda text:\n",
    "        \" \".join(\n",
    "            token.lemma_ for token in nlp(text)\n",
    "                if token.lemma_.lower() not in stopwords and token.is_alpha\n",
    "        )\n",
    ")\n",
    "\n",
    "df_all['target_parsed'] = df_all['target'].apply(\n",
    "    lambda text:\n",
    "        \" \".join(\n",
    "            token.lemma_ for token in nlp(text)\n",
    "                if token.lemma_.lower() not in stopwords and token.is_alpha\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94a0ee89",
   "metadata": {
    "_cell_guid": "4fb10eae-003e-4f2e-a769-dc9f85dc81a1",
    "_uuid": "eb33244d-de87-45ba-90b9-541980ce4093",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-19T19:01:44.375642Z",
     "iopub.status.busy": "2022-06-19T19:01:44.374792Z",
     "iopub.status.idle": "2022-06-19T19:07:22.484466Z",
     "shell.execute_reply": "2022-06-19T19:07:22.483920Z",
     "shell.execute_reply.started": "2022-06-19T17:52:43.868362Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 338.152076,
     "end_time": "2022-06-19T19:07:22.484639",
     "exception": false,
     "start_time": "2022-06-19T19:01:44.332563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all['anchor_nlp'] = df_all.anchor.apply(lambda series: nlp(series))\n",
    "df_all['target_nlp'] = df_all.target.apply(lambda series: nlp(series))\n",
    "\n",
    "df_all['anchor_VERB'] = df_all.anchor_nlp.apply(lambda series: len([token for token in series if token.pos_ == 'VERB']))\n",
    "df_all['target_VERB'] = df_all.target_nlp.apply(lambda series: len([token for token in series if token.pos_ == 'VERB']))\n",
    "\n",
    "df_all['anchor_NOUN'] = df_all.anchor_nlp.apply(lambda series: len([token for token in series if token.pos_ == 'NOUN']))\n",
    "df_all['target_NOUN'] = df_all.target_nlp.apply(lambda series: len([token for token in series if token.pos_ == 'NOUN']))\n",
    "\n",
    "df_all['anchor_DET'] = df_all.anchor_nlp.apply(lambda series: len([token for token in series if token.pos_ == 'DET']))\n",
    "df_all['target_DET'] = df_all.target_nlp.apply(lambda series: len([token for token in series if token.pos_ == 'DET']))\n",
    "\n",
    "df_all['anchor_ADJ'] = df_all.anchor_nlp.apply(lambda series: len([token for token in series if token.pos_ == 'ADJ']))\n",
    "df_all['target_ADJ'] = df_all.target_nlp.apply(lambda series: len([token for token in series if token.pos_ == 'ADJ']))\n",
    "\n",
    "df_all['anchor_ADV'] = df_all.anchor_nlp.apply(lambda series: len([token for token in series if token.pos_ == 'ADV']))\n",
    "df_all['target_ADV'] = df_all.target_nlp.apply(lambda series: len([token for token in series if token.pos_ == 'ADV']))\n",
    "\n",
    "df_all['anchor_in_target'] = df_all.apply(lambda x: x[\"anchor_parsed\"] in x[\"target\"], axis=1)\n",
    "df_all['target_in_anchor'] = df_all.apply(lambda x: x[\"target_parsed\"] in x[\"anchor\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22730b4a",
   "metadata": {
    "_cell_guid": "ca883518-7c1f-4112-978b-5a0dac56b352",
    "_uuid": "00148a52-36d5-48d5-8600-875693a2172c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-19T19:07:22.563067Z",
     "iopub.status.busy": "2022-06-19T19:07:22.562132Z",
     "iopub.status.idle": "2022-06-19T19:13:12.945973Z",
     "shell.execute_reply": "2022-06-19T19:13:12.946639Z",
     "shell.execute_reply.started": "2022-06-19T17:59:02.090574Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 350.430782,
     "end_time": "2022-06-19T19:13:12.946888",
     "exception": false,
     "start_time": "2022-06-19T19:07:22.516106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sims = df_all[[\"anchor_parsed\", \"target_parsed\"]]\n",
    "similarityValue = []\n",
    "for i in range(sims.count()[0]):\n",
    "    sentence_1 = nlp(sims.iloc[i][0])\n",
    "    sentence_2 = nlp(sims.iloc[i][1])\n",
    "    similarityValue.append(sentence_1.similarity(sentence_2))\n",
    "\n",
    "df_all['anchor_target_cos_sim'] = similarityValue\n",
    "\n",
    "train = df_all.loc[df_all['dataset'] == 'train']\n",
    "test = df_all.loc[df_all['dataset'] == 'test']\n",
    "\n",
    "train['text'] = train['anchor'] + '[SEP]' + train['target'] + '[SEP]' + train['context_text']\n",
    "test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]' + test['context_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1692a684",
   "metadata": {
    "_cell_guid": "8bcead30-5905-499e-acb9-db98aca2b561",
    "_uuid": "e8d796bc-1c18-4d24-aa17-4023ca03cb20",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-19T19:13:13.054498Z",
     "iopub.status.busy": "2022-06-19T19:13:13.044459Z",
     "iopub.status.idle": "2022-06-19T19:16:25.003019Z",
     "shell.execute_reply": "2022-06-19T19:16:25.001528Z",
     "shell.execute_reply.started": "2022-06-19T18:10:02.808245Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 192.006907,
     "end_time": "2022-06-19T19:16:25.003175",
     "exception": false,
     "start_time": "2022-06-19T19:13:12.996268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1252971e16044bdfbac4c0b7091ae285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the test set  don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text, __index_level_0__, anchor_target_cos_sim.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../input/deberta-v3-5folds/fold1/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"../input/deberta-v3-5folds/fold1\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1024,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file ../input/deberta-v3-5folds/fold1/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at ../input/deberta-v3-5folds/fold1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the test set  don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text, __index_level_0__, anchor_target_cos_sim.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../input/deberta-v3-5folds/fold2/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"../input/deberta-v3-5folds/fold2\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1024,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file ../input/deberta-v3-5folds/fold2/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at ../input/deberta-v3-5folds/fold2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the test set  don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text, __index_level_0__, anchor_target_cos_sim.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../input/deberta-v3-5folds/fold3/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"../input/deberta-v3-5folds/fold3\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1024,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file ../input/deberta-v3-5folds/fold3/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at ../input/deberta-v3-5folds/fold3.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the test set  don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text, __index_level_0__, anchor_target_cos_sim.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../input/deberta-v3-5folds/fold4/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"../input/deberta-v3-5folds/fold4\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1024,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file ../input/deberta-v3-5folds/fold4/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at ../input/deberta-v3-5folds/fold4.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the test set  don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text, __index_level_0__, anchor_target_cos_sim.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file ../input/bert-for-patent-5fold/fold0/added_tokens.json. We won't load it.\n",
      "loading file ../input/bert-for-patent-5fold/fold0/vocab.txt\n",
      "loading file ../input/bert-for-patent-5fold/fold0/tokenizer.json\n",
      "loading file None\n",
      "loading file ../input/bert-for-patent-5fold/fold0/special_tokens_map.json\n",
      "loading file ../input/bert-for-patent-5fold/fold0/tokenizer_config.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c60fe0d4304a62a065470b02a80c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../input/bert-for-patent-5fold/fold0/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"../input/bert-for-patent-5fold/fold0\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 39859\n",
      "}\n",
      "\n",
      "loading weights file ../input/bert-for-patent-5fold/fold0/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../input/bert-for-patent-5fold/fold0.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, anchor_target_cos_sim.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../input/bert-for-patent-5fold/fold1/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"../input/bert-for-patent-5fold/fold1\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 39859\n",
      "}\n",
      "\n",
      "loading weights file ../input/bert-for-patent-5fold/fold1/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../input/bert-for-patent-5fold/fold1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, anchor_target_cos_sim.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../input/bert-for-patent-5fold/fold2/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"../input/bert-for-patent-5fold/fold2\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 39859\n",
      "}\n",
      "\n",
      "loading weights file ../input/bert-for-patent-5fold/fold2/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../input/bert-for-patent-5fold/fold2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, anchor_target_cos_sim.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../input/bert-for-patent-5fold/fold3/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"../input/bert-for-patent-5fold/fold3\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 39859\n",
      "}\n",
      "\n",
      "loading weights file ../input/bert-for-patent-5fold/fold3/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../input/bert-for-patent-5fold/fold3.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, anchor_target_cos_sim.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../input/bert-for-patent-5fold/fold4/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"../input/bert-for-patent-5fold/fold4\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 39859\n",
      "}\n",
      "\n",
      "loading weights file ../input/bert-for-patent-5fold/fold4/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../input/bert-for-patent-5fold/fold4.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, anchor_target_cos_sim.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_test = []\n",
    "\n",
    "def process_test(unit):\n",
    "        return {\n",
    "        **tokenizer(unit['text'])\n",
    "    }\n",
    "    \n",
    "for i in range (CFG.model_num):   \n",
    "    tokenizer = AutoTokenizer.from_pretrained(f'{CFG.model_path[i]}fold0')\n",
    "    test_ds = datasets.Dataset.from_pandas(test.drop(columns=['id', 'anchor', 'target', 'context', 'score', 'general_context',\n",
    "       'Chemistry and Metallurgy', 'Electricity', 'Fixed Constructions',\n",
    "       'Human Necessities', 'Mechanical Engineering',\n",
    "       'Operations and Transport', 'Physics', 'Textiles', 'context_text',\n",
    "       'section', 'classes', 'num_anchor', 'anchor_len', 'num_target',\n",
    "       'target_len', 'dataset', 'anchor_parsed', 'target_parsed', 'num_anchor_stops', 'num_target_stops', 'anchor_in_target', \n",
    "                                                        'target_in_anchor', 'anchor_ADV', 'target_ADV', 'anchor_ADJ', 'target_ADJ', \n",
    "                                                        'anchor_DET', 'target_DET', 'anchor_NOUN', 'target_NOUN', 'anchor_VERB', 'target_VERB', \n",
    "                                                        'anchor_nlp', 'target_nlp']))\n",
    "    test_ds = test_ds.map(process_test)\n",
    "\n",
    "    for fold in range(CFG.num_fold):        \n",
    "        trainer = Trainer(\n",
    "                AutoModelForSequenceClassification.from_pretrained(f'{CFG.model_path[i]}fold{fold}', \n",
    "                                                                   num_labels=1),\n",
    "                tokenizer=tokenizer,\n",
    "            )\n",
    "        \n",
    "        predictions_test.append(trainer.predict(test_ds).predictions)\n",
    "        del trainer\n",
    "        gc.collect()\n",
    "        \n",
    "    del tokenizer, test_ds\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1241902c",
   "metadata": {
    "_cell_guid": "aa4a21af-9cd7-4051-be66-6f9837acf680",
    "_uuid": "f7e15874-fc82-4243-9a91-34cb24ab04bc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-19T19:16:25.181291Z",
     "iopub.status.busy": "2022-06-19T19:16:25.180715Z",
     "iopub.status.idle": "2022-06-19T19:42:20.313065Z",
     "shell.execute_reply": "2022-06-19T19:42:20.312390Z",
     "shell.execute_reply.started": "2022-06-19T18:14:25.814781Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1555.226078,
     "end_time": "2022-06-19T19:42:20.313271",
     "exception": false,
     "start_time": "2022-06-19T19:16:25.087193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file ../input/deberta-v3-5folds/fold0/tokenizer.json. We won't load it.\n",
      "loading file ../input/deberta-v3-5folds/fold0/spm.model\n",
      "loading file ../input/deberta-v3-5folds/fold0/added_tokens.json\n",
      "loading file ../input/deberta-v3-5folds/fold0/special_tokens_map.json\n",
      "loading file ../input/deberta-v3-5folds/fold0/tokenizer_config.json\n",
      "loading file None\n",
      "Adding [MASK] to the vocabulary\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f648d78736584f9a85e71932150dddd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../input/deberta-v3-5folds/fold0/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"../input/deberta-v3-5folds/fold0\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1024,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file ../input/deberta-v3-5folds/fold0/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at ../input/deberta-v3-5folds/fold0.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the test set  don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text, __index_level_0__, anchor_target_cos_sim.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 18236\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2280' max='2280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2280/2280 02:56]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../input/deberta-v3-5folds/fold1/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"../input/deberta-v3-5folds/fold1\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1024,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file ../input/deberta-v3-5folds/fold1/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at ../input/deberta-v3-5folds/fold1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the test set  don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text, __index_level_0__, anchor_target_cos_sim.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 18236\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2280' max='2280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2280/2280 02:57]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../input/deberta-v3-5folds/fold2/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"../input/deberta-v3-5folds/fold2\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1024,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file ../input/deberta-v3-5folds/fold2/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at ../input/deberta-v3-5folds/fold2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the test set  don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text, __index_level_0__, anchor_target_cos_sim.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 18236\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2280' max='2280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2280/2280 02:58]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../input/deberta-v3-5folds/fold3/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"../input/deberta-v3-5folds/fold3\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1024,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file ../input/deberta-v3-5folds/fold3/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at ../input/deberta-v3-5folds/fold3.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the test set  don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text, __index_level_0__, anchor_target_cos_sim.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 18236\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2280' max='2280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2280/2280 02:58]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../input/deberta-v3-5folds/fold4/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"../input/deberta-v3-5folds/fold4\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1024,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file ../input/deberta-v3-5folds/fold4/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at ../input/deberta-v3-5folds/fold4.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the test set  don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: text, __index_level_0__, anchor_target_cos_sim.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 18236\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2280' max='2280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2280/2280 02:58]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file ../input/bert-for-patent-5fold/fold0/added_tokens.json. We won't load it.\n",
      "loading file ../input/bert-for-patent-5fold/fold0/vocab.txt\n",
      "loading file ../input/bert-for-patent-5fold/fold0/tokenizer.json\n",
      "loading file None\n",
      "loading file ../input/bert-for-patent-5fold/fold0/special_tokens_map.json\n",
      "loading file ../input/bert-for-patent-5fold/fold0/tokenizer_config.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa3f3e1fe08a445f82cbe0205108b97a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../input/bert-for-patent-5fold/fold0/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"../input/bert-for-patent-5fold/fold0\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 39859\n",
      "}\n",
      "\n",
      "loading weights file ../input/bert-for-patent-5fold/fold0/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../input/bert-for-patent-5fold/fold0.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, anchor_target_cos_sim.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 18236\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2280' max='2280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2280/2280 01:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../input/bert-for-patent-5fold/fold1/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"../input/bert-for-patent-5fold/fold1\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 39859\n",
      "}\n",
      "\n",
      "loading weights file ../input/bert-for-patent-5fold/fold1/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../input/bert-for-patent-5fold/fold1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, anchor_target_cos_sim.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 18236\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2280' max='2280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2280/2280 01:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../input/bert-for-patent-5fold/fold2/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"../input/bert-for-patent-5fold/fold2\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 39859\n",
      "}\n",
      "\n",
      "loading weights file ../input/bert-for-patent-5fold/fold2/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../input/bert-for-patent-5fold/fold2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, anchor_target_cos_sim.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 18236\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2280' max='2280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2280/2280 01:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../input/bert-for-patent-5fold/fold3/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"../input/bert-for-patent-5fold/fold3\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 39859\n",
      "}\n",
      "\n",
      "loading weights file ../input/bert-for-patent-5fold/fold3/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../input/bert-for-patent-5fold/fold3.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, anchor_target_cos_sim.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 18236\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2280' max='2280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2280/2280 01:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../input/bert-for-patent-5fold/fold4/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"../input/bert-for-patent-5fold/fold4\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 39859\n",
      "}\n",
      "\n",
      "loading weights file ../input/bert-for-patent-5fold/fold4/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../input/bert-for-patent-5fold/fold4.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__, anchor_target_cos_sim.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 18236\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2280' max='2280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2280/2280 01:32]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_valid = []\n",
    "\n",
    "def process_valid(unit):\n",
    "    return {\n",
    "    **tokenizer(unit['text']),\n",
    "    'label': unit['score']\n",
    "}\n",
    "\n",
    "valid = train.sample(frac=0.5, replace=False, random_state=42)\n",
    "\n",
    "for i in range (CFG.model_num):   \n",
    "    tokenizer = AutoTokenizer.from_pretrained(f'{CFG.model_path[i]}fold0')\n",
    "    valid_ds = datasets.Dataset.from_pandas(valid.drop(columns=['id', 'anchor', 'target', 'context', 'score', 'general_context',\n",
    "       'Chemistry and Metallurgy', 'Electricity', 'Fixed Constructions',\n",
    "       'Human Necessities', 'Mechanical Engineering',\n",
    "       'Operations and Transport', 'Physics', 'Textiles', 'context_text',\n",
    "       'section', 'classes', 'num_anchor', 'anchor_len', 'num_target',\n",
    "       'target_len', 'dataset', 'anchor_parsed', 'target_parsed', 'num_anchor_stops', 'num_target_stops', 'anchor_in_target', \n",
    "                                                        'target_in_anchor', 'anchor_ADV', 'target_ADV', 'anchor_ADJ', 'target_ADJ', \n",
    "                                                        'anchor_DET', 'target_DET', 'anchor_NOUN', 'target_NOUN', 'anchor_VERB', 'target_VERB', \n",
    "                                                        'anchor_nlp', 'target_nlp']))\n",
    "    valid_ds = valid_ds.map(process_test)\n",
    "\n",
    "    for fold in range(CFG.num_fold):\n",
    "        trainer = Trainer(\n",
    "                AutoModelForSequenceClassification.from_pretrained(f'{CFG.model_path[i]}fold{fold}',\n",
    "                                                                   num_labels=1),\n",
    "                tokenizer=tokenizer,\n",
    "            )\n",
    "        \n",
    "        predictions_valid.append(trainer.predict(valid_ds).predictions)\n",
    "        del trainer\n",
    "        gc.collect()\n",
    "        \n",
    "    del tokenizer, valid_ds\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3be3984",
   "metadata": {
    "_cell_guid": "c28a86c6-0bc5-4283-98e4-8a85472dafba",
    "_uuid": "0dfb43f5-dd41-4d0e-bebc-f5675c671eb1",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-19T19:42:20.755383Z",
     "iopub.status.busy": "2022-06-19T19:42:20.754273Z",
     "iopub.status.idle": "2022-06-19T19:42:20.764391Z",
     "shell.execute_reply": "2022-06-19T19:42:20.765041Z",
     "shell.execute_reply.started": "2022-06-19T18:40:14.264555Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.242289,
     "end_time": "2022-06-19T19:42:20.765254",
     "exception": false,
     "start_time": "2022-06-19T19:42:20.522965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test['predictions_deberta_v3'] = np.average(predictions_test[0:5], axis=0)\n",
    "test['predictions_bert_4_patents'] = np.average(predictions_test[6:10], axis=0)\n",
    "\n",
    "valid['predictions_deberta_v3'] = np.average(predictions_valid[0:5], axis=0)\n",
    "valid['predictions_bert_4_patents'] = np.average(predictions_valid[6:10], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6a6d6b3",
   "metadata": {
    "_cell_guid": "46bdead9-8e05-4907-bc48-78c2be20cb9a",
    "_uuid": "c6e4839b-efc5-4086-a590-2f7b7b65e8de",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-19T19:42:21.241835Z",
     "iopub.status.busy": "2022-06-19T19:42:21.240749Z",
     "iopub.status.idle": "2022-06-19T19:42:21.248037Z",
     "shell.execute_reply": "2022-06-19T19:42:21.248776Z",
     "shell.execute_reply.started": "2022-06-19T18:40:16.555716Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.26732,
     "end_time": "2022-06-19T19:42:21.248972",
     "exception": false,
     "start_time": "2022-06-19T19:42:20.981652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = valid[['Chemistry and Metallurgy', 'Electricity', 'Fixed Constructions',\n",
    "           'Human Necessities', 'Mechanical Engineering',\n",
    "           'Operations and Transport', 'Physics', 'Textiles', 'num_anchor', 'anchor_len', 'num_target',\n",
    "           'target_len', 'predictions_deberta_v3', 'predictions_bert_4_patents', 'anchor_target_cos_sim', \n",
    "           'num_anchor_stops', 'num_target_stops', 'anchor_in_target', 'target_in_anchor', 'anchor_ADV', \n",
    "           'target_ADV', 'anchor_ADJ', 'target_ADJ', 'anchor_DET', 'target_DET', 'anchor_NOUN', 'target_NOUN', \n",
    "           'anchor_VERB', 'target_VERB', 'anchor_in_target', 'target_in_anchor']]\n",
    "y = valid['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ff368a9",
   "metadata": {
    "_cell_guid": "cb66bafc-95ec-44f7-871c-b4d825158399",
    "_uuid": "07381d69-4197-43f3-9ab8-44ec5d3e32cc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-19T19:42:21.772845Z",
     "iopub.status.busy": "2022-06-19T19:42:21.769711Z",
     "iopub.status.idle": "2022-06-19T19:42:21.854419Z",
     "shell.execute_reply": "2022-06-19T19:42:21.855005Z",
     "shell.execute_reply.started": "2022-06-19T18:41:59.639079Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.350136,
     "end_time": "2022-06-19T19:42:21.855158",
     "exception": false,
     "start_time": "2022-06-19T19:42:21.505022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def slice_by_corr(X, r_min=0):\n",
    "    # Create correlation matrix\n",
    "    corr_matrix = X.corr().abs()\n",
    "\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "    # Find features with correlation greater than r_min\n",
    "    return X[[column for column in upper.columns if any(upper[column] > r_min)]]\n",
    "\n",
    "def variance_inflation_factor(X, exog_idx):\n",
    "    clf = LinearRegression(fit_intercept=True)\n",
    "    sub_X = np.delete(np.nan_to_num(X), exog_idx, axis=1)\n",
    "    sub_y = X[:, exog_idx][np.newaxis].T\n",
    "    sub_clf = clf.fit(sub_X, sub_y)\n",
    "    return 1 / (1 - r2_score(sub_y, sub_clf.predict(sub_X)))\n",
    "\n",
    "class ReduceVIF(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, thresh=10.0, nthreads=4, r_min=0, obs=250):\n",
    "        self.thresh = thresh\n",
    "        self.nthreads = nthreads\n",
    "        self.r_min = r_min\n",
    "        self.obs = obs\n",
    "        \n",
    "    def fit(self, X):\n",
    "        self.X = X\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return ReduceVIF.calculate_vif(X, self.thresh, \n",
    "                                       self.nthreads, \n",
    "                                       self.r_min, \n",
    "                                       self.obs)\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_vif(X, thresh=10.0, nthreads=16, r_min=0, obs=250):        \n",
    "        dropped = True\n",
    "        vif_cols = []\n",
    "        X_vif_candidates = slice_by_corr(X, r_min)\n",
    "        X_vif_candidates = X_vif_candidates.sample(n=obs)\n",
    "        while dropped:\n",
    "            variables = X_vif_candidates.columns\n",
    "            dropped = False\n",
    "            with Parallel(n_jobs=nthreads, backend='threading') as parallel:\n",
    "                vif = parallel(\n",
    "                    delayed(variance_inflation_factor)(\n",
    "                        np.asarray(X_vif_candidates[variables].values),\n",
    "                        X_vif_candidates.columns.get_loc(var)) for var in \n",
    "                    X_vif_candidates.columns)\n",
    "            max_vif = max(vif)\n",
    "            if max_vif > thresh:\n",
    "                maxloc = vif.index(max_vif)\n",
    "                print(f'Dropping {X_vif_candidates.columns[maxloc]} with vif={max_vif}')\n",
    "                vif_cols.append(X_vif_candidates.columns.tolist()[maxloc])\n",
    "                X_vif_candidates = X_vif_candidates.drop(\n",
    "                    [X_vif_candidates.columns.tolist()[maxloc]], axis=1)\n",
    "                dropped = True\n",
    "        \n",
    "        if len(vif_cols) > 0:\n",
    "            return X.drop(columns=vif_cols), vif_cols\n",
    "        else:\n",
    "            return X, vif_cols\n",
    "\n",
    "    \n",
    "def preprocess_x_y(X, nodrop_columns=[],\n",
    "                   var_thr=0.85, remove_multi=True,\n",
    "                   standardize=True,\n",
    "                   std_dev=3, vif_thr=5, missingness_thr=0.50,\n",
    "                   zero_thr=0.50, nthreads=4):\n",
    "    from colorama import Fore, Style\n",
    "\n",
    "    # Replace all near-zero with zeros\n",
    "    # Drop excessively sparse columns with >zero_thr zeros\n",
    "    if zero_thr > 0:\n",
    "        X = X.apply(lambda x: np.where(np.abs(x) < 0.000001, 0, x))\n",
    "        X_tmp = X.T.loc[(X == 0).sum() < (float(zero_thr)) * X.shape[0]].T\n",
    "\n",
    "        if len(nodrop_columns) > 0:\n",
    "            X = pd.concat([X_tmp, X[[i for i in X.columns if i in\n",
    "                                     nodrop_columns and i not in\n",
    "                                     X_tmp.columns]]], axis=1)\n",
    "        else:\n",
    "            X = X_tmp\n",
    "        del X_tmp\n",
    "\n",
    "        if X.empty or len(X.columns) < 5:\n",
    "            print(f\"\\n\\n{Fore.RED}Empty feature-space (Zero Columns): \"\n",
    "                  f\"{X}{Style.RESET_ALL}\\n\\n\")\n",
    "            return X\n",
    "\n",
    "    # Remove columns with excessive missing values\n",
    "    X = X.dropna(thresh=len(X) * (1 - missingness_thr), axis=1)\n",
    "    if X.empty:\n",
    "        print(f\"\\n\\n{Fore.RED}Empty feature-space (missingness): \"\n",
    "              f\"{X}{Style.RESET_ALL}\\n\\n\")\n",
    "        return X\n",
    "\n",
    "    # Apply a simple imputer (note that this assumes extreme cases of\n",
    "    # missingness have already been addressed). The SimpleImputer is better\n",
    "    # for smaller datasets, whereas the IterativeImputer performs best on\n",
    "    # larger sets.\n",
    "\n",
    "    # from sklearn.experimental import enable_iterative_imputer\n",
    "    # from sklearn.impute import IterativeImputer\n",
    "    # imp = IterativeImputer(random_state=0, sample_posterior=True)\n",
    "    # X = pd.DataFrame(imp.fit_transform(X, y), columns=X.columns)\n",
    "    imp1 = SimpleImputer()\n",
    "    X = pd.DataFrame(imp1.fit_transform(X.astype('float32')),\n",
    "                     columns=X.columns)\n",
    "\n",
    "    # Standardize X\n",
    "    if standardize is True:\n",
    "        scaler = StandardScaler()\n",
    "        X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "    # Remove low-variance columns\n",
    "    sel = VarianceThreshold(threshold=var_thr)\n",
    "    sel.fit(X)\n",
    "    if len(nodrop_columns) > 0:\n",
    "        good_var_cols = X.columns[np.concatenate(\n",
    "            [sel.get_support(indices=True), np.array([X.columns.get_loc(c)\n",
    "                                                      for c in\n",
    "                                                      nodrop_columns if\n",
    "                                                      c in X])])]\n",
    "    else:\n",
    "        good_var_cols = X.columns[sel.get_support(indices=True)]\n",
    "    low_var_cols = [i for i in X.columns if i not in list(good_var_cols)]\n",
    "    if len(low_var_cols) > 0:\n",
    "        print(f\"Dropping {low_var_cols} for low variance...\")\n",
    "    X = X[good_var_cols]\n",
    "\n",
    "    if X.empty:\n",
    "        print(f\"\\n\\n{Fore.RED}Empty feature-space (low-variance): \"\n",
    "              f\"{X}{Style.RESET_ALL}\\n\\n\")\n",
    "        return X\n",
    "\n",
    "    # Remove multicollinear columns\n",
    "    if remove_multi is True:\n",
    "        try:\n",
    "            rvif = ReduceVIF(thresh=vif_thr, nthreads=nthreads)\n",
    "            X = rvif.fit_transform(X)[0]\n",
    "            if X.empty or len(X.columns) < 5:\n",
    "                print(f\"\\n\\n{Fore.RED}Empty feature-space \"\n",
    "                      f\"(multicollinearity): \"\n",
    "                      f\"{X}{Style.RESET_ALL}\\n\\n\")\n",
    "                return X\n",
    "        except:\n",
    "            print(f\"\\n\\n{Fore.RED}Empty feature-space (multicollinearity): \"\n",
    "                  f\"{X}{Style.RESET_ALL}\\n\\n\")\n",
    "            return X\n",
    "\n",
    "    print(f\"\\nX: {X}\\n\")\n",
    "    print(f\"Features: {list(X.columns)}\\n\")\n",
    "    return X\n",
    "\n",
    "\n",
    "class Razors(object):\n",
    "    \"\"\"\n",
    "    Razors is a callable refit option for `GridSearchCV` whose aim is to\n",
    "    balance model complexity and cross-validated score in the spirit of the\n",
    "    \"one standard error\" rule of Breiman et al. (1984), which showed that\n",
    "    the tuning hyperparameter associated with the best performing model may be\n",
    "    prone to overfit. To help mitigate this risk, we can instead instruct\n",
    "    gridsearch to refit the highest performing 'parsimonious' model, as defined\n",
    "    using simple statistical rules (e.g. standard error (`sigma`),\n",
    "    percentile (`eta`), or significance level (`alpha`)) to compare\n",
    "    distributions of model performance across folds. Importantly, this\n",
    "    strategy assumes that the grid of multiple cross-validated models\n",
    "    can be principly ordered from simplest to most complex with respect to some\n",
    "    target hyperparameter of interest. To use the razors suite, supply\n",
    "    the `simplify` function partial of the `Razors` class as a callable\n",
    "    directly to the `refit` argument of `GridSearchCV`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cv_results : dict of numpy(masked) ndarrays\n",
    "        See attribute cv_results_ of `GridSearchCV`.\n",
    "    scoring : str\n",
    "        Refit scoring metric.\n",
    "    param : str\n",
    "        Parameter whose complexity will be optimized.\n",
    "    rule : str\n",
    "        Rule for balancing model complexity with performance.\n",
    "        Options are 'se', 'percentile', and 'ranksum'. Default is 'se'.\n",
    "    sigma : int\n",
    "        Number of standard errors tolerance in the case that a standard error\n",
    "        threshold is used to filter outlying scores across folds. Required if\n",
    "        `rule`=='se'. Default is 1.\n",
    "    eta : float\n",
    "        Percentile tolerance in the case that a percentile threshold\n",
    "        is used to filter outlier scores across folds. Required if\n",
    "        `rule`=='percentile'. Default is 0.68.\n",
    "    alpha : float\n",
    "        An alpha significance level in the case that wilcoxon rank sum\n",
    "        hypothesis testing is used to filter outlying scores across folds.\n",
    "        Required if `rule`=='ranksum'. Default is 0.05.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Breiman, Friedman, Olshen, and Stone. (1984) Classification and Regression\n",
    "    Trees. Wadsworth.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Here, 'simplest' is defined by the complexity of the model as influenced by\n",
    "    some user-defined target parameter (e.g. number of components, number of\n",
    "    estimators, polynomial degree, cost, scale, number hidden units, weight\n",
    "    decay, number of nearest neighbors, L1/L2 penalty, etc.).\n",
    "\n",
    "    The callable API accordingly assumes that the `params` attribute of\n",
    "    `cv_results_` 1) contains the indicated hyperparameter (`param`) of\n",
    "    interest, and 2) contains a sequence of values (numeric, boolean, or\n",
    "    categorical) that are ordered from least to most complex.\n",
    "    \"\"\"\n",
    "    __slots__ = ('cv_results', 'param', 'param_complexity', 'scoring',\n",
    "                 'rule', 'greater_is_better',\n",
    "                 '_scoring_funcs', '_scoring_dict',\n",
    "                 '_n_folds', '_splits', '_score_grid',\n",
    "                 '_cv_means', '_sigma', '_eta', '_alpha')\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            cv_results_,\n",
    "            param,\n",
    "            scoring,\n",
    "            rule,\n",
    "            sigma=1,\n",
    "            eta=0.95,\n",
    "            alpha=0.01,\n",
    "    ):\n",
    "        import sklearn.metrics\n",
    "\n",
    "        self.cv_results = cv_results_\n",
    "        self.param = param\n",
    "        self.scoring = scoring\n",
    "        self.rule = rule\n",
    "        self._scoring_funcs = [\n",
    "            met\n",
    "            for met in sklearn.metrics.__all__\n",
    "            if (met.endswith(\"_score\")) or (met.endswith(\"_error\"))\n",
    "        ]\n",
    "        # Set _score metrics to True and _error metrics to False\n",
    "        self._scoring_dict = dict(\n",
    "            zip(\n",
    "                self._scoring_funcs,\n",
    "                [met.endswith(\"_score\") for met in self._scoring_funcs],\n",
    "            )\n",
    "        )\n",
    "        self.greater_is_better = self._check_scorer()\n",
    "        self._n_folds = len(list(set([i.split('_')[0] for i in\n",
    "                                     list(self.cv_results.keys()) if\n",
    "                                     i.startswith('split')])))\n",
    "        # Extract subgrid corresponding to the scoring metric of interest\n",
    "        self._splits = [i for i in list(self.cv_results.keys()) if\n",
    "                        i.endswith(f\"test_{self.scoring}\") and\n",
    "                        i.startswith('split')]\n",
    "        self._score_grid = np.vstack([self.cv_results[cv] for cv in\n",
    "                                      self._splits]).T\n",
    "        self._cv_means = np.array(np.nanmean(self._score_grid, axis=1))\n",
    "        self._sigma = sigma\n",
    "        self._eta = eta\n",
    "        self._alpha = alpha\n",
    "\n",
    "    def _check_scorer(self):\n",
    "        \"\"\"\n",
    "        Check whether the target refit scorer is negated. If so, adjust\n",
    "        greater_is_better accordingly.\n",
    "        \"\"\"\n",
    "\n",
    "        if (\n",
    "                self.scoring not in self._scoring_dict.keys()\n",
    "                and f\"{self.scoring}_score\" not in self._scoring_dict.keys()\n",
    "        ):\n",
    "            if self.scoring.startswith(\"neg_\"):\n",
    "                self.greater_is_better = True\n",
    "            else:\n",
    "                raise NotImplementedError(f\"Scoring metric {self.scoring} not \"\n",
    "                                          f\"recognized.\")\n",
    "        else:\n",
    "            self.greater_is_better = [\n",
    "                value for key, value in self._scoring_dict.items() if\n",
    "                self.scoring in key][0]\n",
    "        return self.greater_is_better\n",
    "\n",
    "    def _best_low_complexity(self):\n",
    "        \"\"\"\n",
    "        Balance model complexity with cross-validated score.\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        int\n",
    "            Index of a model that has the lowest complexity but its test score\n",
    "            is the highest on average across folds as compared to other models\n",
    "            that are equally likely to occur.\n",
    "        \"\"\"\n",
    "\n",
    "        # Check parameter(s) whose complexity we seek to restrict\n",
    "        if not any(self.param in x for x in\n",
    "                   self.cv_results[\"params\"][0].keys()):\n",
    "            raise KeyError(f\"Parameter {self.param} not found in cv grid.\")\n",
    "        else:\n",
    "            hyperparam = [\n",
    "                i for i in self.cv_results[\"params\"][0].keys() if\n",
    "                i.endswith(self.param)][0]\n",
    "\n",
    "        # Select low complexity threshold based on specified evaluation rule\n",
    "        if self.rule == \"se\":\n",
    "            if not self._sigma:\n",
    "                raise ValueError(\n",
    "                    \"For `se` rule, the tolerance \"\n",
    "                    \"(i.e. `_sigma`) parameter cannot be null.\"\n",
    "                )\n",
    "            l_cutoff, h_cutoff = self.call_standard_error()\n",
    "        elif self.rule == \"percentile\":\n",
    "            if not self._eta:\n",
    "                raise ValueError(\n",
    "                    \"For `percentile` rule, the tolerance \"\n",
    "                    \"(i.e. `_eta`) parameter cannot be null.\"\n",
    "                )\n",
    "            l_cutoff, h_cutoff = self.call_percentile()\n",
    "        elif self.rule == \"ranksum\":\n",
    "            if not self._alpha:\n",
    "                raise ValueError(\n",
    "                    \"For `ranksum` rule, the alpha-level \"\n",
    "                    \"(i.e. `_alpha`) parameter cannot be null.\"\n",
    "                )\n",
    "            l_cutoff, h_cutoff = self.call_rank_sum_test()\n",
    "        else:\n",
    "            raise NotImplementedError(f\"{self.rule} is not a valid \"\n",
    "                                      f\"rule of RazorCV.\")\n",
    "\n",
    "        self.cv_results[f\"param_{hyperparam}\"].mask = np.where(\n",
    "            (self._cv_means >= float(l_cutoff)) &\n",
    "            (self._cv_means <= float(h_cutoff)),\n",
    "            True, False)\n",
    "\n",
    "        if np.sum(self.cv_results[f\"param_{hyperparam}\"].mask) == 0:\n",
    "            print(f\"\\nLow: {l_cutoff}\")\n",
    "            print(f\"High: {h_cutoff}\")\n",
    "            print(f\"{self._cv_means}\")\n",
    "            print(f\"hyperparam: {hyperparam}\\n\")\n",
    "            raise ValueError(\"No valid grid columns remain within the \"\n",
    "                             \"boundaries of the specified razor\")\n",
    "\n",
    "        highest_surviving_rank = np.nanmin(\n",
    "            self.cv_results[f\"rank_test_{self.scoring}\"][\n",
    "                self.cv_results[f\"param_{hyperparam}\"].mask])\n",
    "\n",
    "        # print(f\"Highest surviving rank: {highest_surviving_rank}\\n\")\n",
    "\n",
    "        return np.flatnonzero(np.isin(\n",
    "            self.cv_results[f\"rank_test_{self.scoring}\"],\n",
    "            highest_surviving_rank))[0]\n",
    "\n",
    "    def call_standard_error(self):\n",
    "        \"\"\"\n",
    "        Returns the simplest model whose performance is within `sigma`\n",
    "        standard errors of the average highest performing model.\n",
    "        \"\"\"\n",
    "\n",
    "        # Estimate the standard error across folds for each column of the grid\n",
    "        cv_se = np.array(np.nanstd(self._score_grid, axis=1) /\n",
    "                         np.sqrt(self._n_folds))\n",
    "\n",
    "        # Determine confidence interval\n",
    "        if self.greater_is_better:\n",
    "            best_score_idx = np.nanargmax(self._cv_means)\n",
    "            h_cutoff = self._cv_means[best_score_idx] + cv_se[best_score_idx]\n",
    "            l_cutoff = self._cv_means[best_score_idx] - cv_se[best_score_idx]\n",
    "        else:\n",
    "            best_score_idx = np.nanargmin(self._cv_means)\n",
    "            h_cutoff = self._cv_means[best_score_idx] - cv_se[best_score_idx]\n",
    "            l_cutoff = self._cv_means[best_score_idx] + cv_se[best_score_idx]\n",
    "\n",
    "        return l_cutoff, h_cutoff\n",
    "\n",
    "    def call_rank_sum_test(self):\n",
    "        \"\"\"\n",
    "        Returns the simplest model whose paired performance across folds is\n",
    "        insignificantly different from the average highest performing,\n",
    "        at a predefined `alpha` level of significance.\n",
    "        \"\"\"\n",
    "\n",
    "        from scipy.stats import wilcoxon\n",
    "        import itertools\n",
    "\n",
    "        if self.greater_is_better:\n",
    "            best_score_idx = np.nanargmax(self._cv_means)\n",
    "        else:\n",
    "            best_score_idx = np.nanargmin(self._cv_means)\n",
    "\n",
    "        # Perform signed Wilcoxon rank sum test for each pair combination of\n",
    "        # columns against the best average score column\n",
    "        tests = [pair for pair in list(itertools.combinations(range(\n",
    "            self._score_grid.shape[0]), 2)) if best_score_idx in pair]\n",
    "\n",
    "        p_dict = {}\n",
    "        for i, test in enumerate(tests):\n",
    "            p_dict[i] = wilcoxon(self._score_grid[test[0], :],\n",
    "                                 self._score_grid[test[1], :])[1]\n",
    "\n",
    "        # Sort and prune away significant tests\n",
    "        p_dict = {k: v for k, v in sorted(p_dict.items(),\n",
    "                                          key=lambda item: item[1]) if\n",
    "                  v > self._alpha}\n",
    "\n",
    "        # Flatten list of tuples, remove best score index, and take the\n",
    "        # lowest and highest remaining bounds\n",
    "        tests = [j for j in list(set(list(sum([tests[i] for i in\n",
    "                                               list(p_dict.keys())],\n",
    "                                              ())))) if j != best_score_idx]\n",
    "        if self.greater_is_better:\n",
    "            h_cutoff = self._cv_means[\n",
    "                np.nanargmin(self.cv_results[\n",
    "                                 f\"rank_test_{self.scoring}\"][tests])]\n",
    "            l_cutoff = self._cv_means[\n",
    "                np.nanargmax(self.cv_results[\n",
    "                                 f\"rank_test_{self.scoring}\"][tests])]\n",
    "        else:\n",
    "            h_cutoff = self._cv_means[\n",
    "                np.nanargmax(self.cv_results[\n",
    "                                 f\"rank_test_{self.scoring}\"][tests])]\n",
    "            l_cutoff = self._cv_means[\n",
    "                np.nanargmin(self.cv_results[\n",
    "                                 f\"rank_test_{self.scoring}\"][tests])]\n",
    "\n",
    "        return l_cutoff, h_cutoff\n",
    "\n",
    "\n",
    "    def call_percentile(self):\n",
    "        \"\"\"\n",
    "        Returns the simplest model whose performance is within the `eta`\n",
    "        percentile of the average highest performing model.\n",
    "        \"\"\"\n",
    "\n",
    "        # Estimate the indicated percentile, and its inverse, across folds for\n",
    "        # each column of the grid\n",
    "        perc_cutoff = np.nanpercentile(self._score_grid,\n",
    "                                       [100 * self._eta,\n",
    "                                        100 - 100 * self._eta], axis=1)\n",
    "\n",
    "        # Determine bounds of the percentile interval\n",
    "        if self.greater_is_better:\n",
    "            best_score_idx = np.nanargmax(self._cv_means)\n",
    "            h_cutoff = perc_cutoff[0, best_score_idx]\n",
    "            l_cutoff = perc_cutoff[1, best_score_idx]\n",
    "        else:\n",
    "            best_score_idx = np.nanargmin(self._cv_means)\n",
    "            h_cutoff = perc_cutoff[0, best_score_idx]\n",
    "            l_cutoff = perc_cutoff[1, best_score_idx]\n",
    "\n",
    "        return l_cutoff, h_cutoff\n",
    "\n",
    "    @staticmethod\n",
    "    def simplify(param, scoring, rule='se', sigma=1, eta=0.68, alpha=0.01):\n",
    "        \"\"\"\n",
    "        Callable to be run as `refit` argument of `GridsearchCV`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        param : str\n",
    "            Parameter with the largest influence on model complexity.\n",
    "        scoring : str\n",
    "            Refit scoring metric.\n",
    "        sigma : int\n",
    "            Number of standard errors tolerance in the case that a standard\n",
    "            error threshold is used to filter outlying scores across folds.\n",
    "            Only applicable if `rule`=='se'. Default is 1.\n",
    "        eta : float\n",
    "            Acceptable percent tolerance in the case that a percentile\n",
    "            threshold is used. Only applicable if `rule`=='percentile'.\n",
    "            Default is 0.68.\n",
    "        alpha : float\n",
    "            Alpha-level to use for signed wilcoxon rank sum testing.\n",
    "            Only applicable if `rule`=='ranksum'. Default is 0.01.\n",
    "        \"\"\"\n",
    "        from functools import partial\n",
    "\n",
    "        def razor_pass(\n",
    "                cv_results_, param, scoring, rule, sigma, alpha, eta\n",
    "        ):\n",
    "            rcv = Razors(cv_results_, param, scoring, rule=rule,\n",
    "                         sigma=sigma, alpha=alpha, eta=eta)\n",
    "            return rcv._best_low_complexity()\n",
    "\n",
    "        return partial(\n",
    "            razor_pass,\n",
    "            param=param,\n",
    "            scoring=scoring,\n",
    "            rule=rule,\n",
    "            sigma=sigma,\n",
    "            alpha=alpha,\n",
    "            eta=eta,\n",
    "        )\n",
    "\n",
    "def divide_df(df_all,train_len):\n",
    "    return df_all.loc[:train_len-1], df_all.loc[train_len:].drop('target',axis=1)\n",
    "\n",
    "def concat_df(train_data, test_data):\n",
    "    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6a6a457",
   "metadata": {
    "_cell_guid": "2712eda4-f76c-499e-acae-26b8f5b934c8",
    "_uuid": "babc5fa2-709b-49bd-9ad2-f9753ac17822",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-19T19:42:22.168943Z",
     "iopub.status.busy": "2022-06-19T19:42:22.168305Z",
     "iopub.status.idle": "2022-06-19T19:42:22.477476Z",
     "shell.execute_reply": "2022-06-19T19:42:22.478076Z",
     "shell.execute_reply.started": "2022-06-19T18:42:02.412455Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.465677,
     "end_time": "2022-06-19T19:42:22.478248",
     "exception": false,
     "start_time": "2022-06-19T19:42:22.012571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X:        anchor_len  target_len  predictions_deberta_v3  \\\n",
      "0         -0.2723     -0.2034                 -0.7996   \n",
      "1         -0.2723     -0.2034                 -0.0764   \n",
      "2         -0.2723     -1.3663                 -0.2171   \n",
      "3         -0.2723     -1.3663                  0.4930   \n",
      "4          2.8545     -0.2034                  0.5417   \n",
      "...           ...         ...                     ...   \n",
      "18231      1.2911     -0.2034                 -0.0423   \n",
      "18232     -0.2723     -0.2034                 -1.5529   \n",
      "18233     -0.2723     -1.3663                 -0.7300   \n",
      "18234     -0.2723      0.9594                  0.6799   \n",
      "18235     -0.2723     -0.2034                 -1.3531   \n",
      "\n",
      "       predictions_bert_4_patents  anchor_target_cos_sim  anchor_NOUN  \\\n",
      "0                          0.2977                -0.1698      -0.5177   \n",
      "1                          0.3904                -0.2008      -0.5177   \n",
      "2                          0.2550                -0.7716      -0.5177   \n",
      "3                         -0.0172                 0.7113       0.8385   \n",
      "4                          0.1642                 0.8772       0.8385   \n",
      "...                           ...                    ...          ...   \n",
      "18231                      1.4828                 0.4824       2.1946   \n",
      "18232                     -0.2750                 0.5705       0.8385   \n",
      "18233                     -1.0398                -1.0940      -0.5177   \n",
      "18234                      1.8219                 1.2028       0.8385   \n",
      "18235                     -0.6948                -1.5265       0.8385   \n",
      "\n",
      "       target_NOUN  \n",
      "0           0.7525  \n",
      "1          -0.5396  \n",
      "2          -0.5396  \n",
      "3          -0.5396  \n",
      "4          -0.5396  \n",
      "...            ...  \n",
      "18231       0.7525  \n",
      "18232       0.7525  \n",
      "18233      -0.5396  \n",
      "18234       0.7525  \n",
      "18235      -0.5396  \n",
      "\n",
      "[18236 rows x 7 columns]\n",
      "\n",
      "Features: ['anchor_len', 'target_len', 'predictions_deberta_v3', 'predictions_bert_4_patents', 'anchor_target_cos_sim', 'anchor_NOUN', 'target_NOUN']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocess = FunctionTransformer(preprocess_x_y)\n",
    "X_clean = preprocess.fit_transform(X=X)\n",
    "surviving_features = list(X_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80e8b212",
   "metadata": {
    "_cell_guid": "caa0b740-b39a-4181-b506-39e5829c1997",
    "_uuid": "2013efce-e219-44ea-9b4f-3fcaf00e7a1a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-19T19:42:23.003889Z",
     "iopub.status.busy": "2022-06-19T19:42:23.002455Z",
     "iopub.status.idle": "2022-06-19T19:42:23.013329Z",
     "shell.execute_reply": "2022-06-19T19:42:23.012784Z",
     "shell.execute_reply.started": "2022-06-19T18:42:26.721090Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.27061,
     "end_time": "2022-06-19T19:42:23.013504",
     "exception": false,
     "start_time": "2022-06-19T19:42:22.742894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed=42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_clean, y, random_state=seed)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = pd.DataFrame(y_train).reset_index(drop=True)\n",
    "\n",
    "X_train = X_train.head(10000)\n",
    "y_train = y_train.head(10000)\n",
    "\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_test = pd.DataFrame(y_test).reset_index(drop=True)\n",
    "\n",
    "X_test = X_test.head(2000)\n",
    "y_test = y_test.head(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "386af065",
   "metadata": {
    "_cell_guid": "1cae2f7f-40b3-42cc-9d3c-2b5b2dca76bd",
    "_uuid": "c795674c-3eba-46df-9ba0-107ffcc738fc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-19T19:42:23.346425Z",
     "iopub.status.busy": "2022-06-19T19:42:23.344673Z",
     "iopub.status.idle": "2022-06-19T19:42:23.347034Z",
     "shell.execute_reply": "2022-06-19T19:42:23.347588Z",
     "shell.execute_reply.started": "2022-06-19T18:42:41.803382Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.156267,
     "end_time": "2022-06-19T19:42:23.347751",
     "exception": false,
     "start_time": "2022-06-19T19:42:23.191484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "            'rf'\n",
    "         ]\n",
    "\n",
    "estimators = [\n",
    "        RandomForestRegressor(random_state=42, min_samples_leaf=7, min_samples_split=3)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b310628d",
   "metadata": {
    "_cell_guid": "3cb8358e-126b-4b91-ae6f-ba4d70386c2a",
    "_uuid": "4c5a010d-7329-46a0-b904-4af8032697d6",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-19T19:42:23.647286Z",
     "iopub.status.busy": "2022-06-19T19:42:23.645557Z",
     "iopub.status.idle": "2022-06-19T19:42:23.647980Z",
     "shell.execute_reply": "2022-06-19T19:42:23.648493Z",
     "shell.execute_reply.started": "2022-06-19T18:49:59.971382Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.153555,
     "end_time": "2022-06-19T19:42:23.648665",
     "exception": false,
     "start_time": "2022-06-19T19:42:23.495110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params={models[0]: {'max_depth': [3, 4, 5],\n",
    "                    'n_estimators': [50, 60, 70],\n",
    "       }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8acc9d48",
   "metadata": {
    "_cell_guid": "47c28da5-8a5f-4096-a8f2-38710f345686",
    "_uuid": "8036d58b-7c10-49bf-a571-6a0567094cff",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-19T19:42:24.026992Z",
     "iopub.status.busy": "2022-06-19T19:42:24.022767Z",
     "iopub.status.idle": "2022-06-19T19:43:11.071432Z",
     "shell.execute_reply": "2022-06-19T19:43:11.071972Z",
     "shell.execute_reply.started": "2022-06-19T18:50:01.839439Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 47.203931,
     "end_time": "2022-06-19T19:43:11.072127",
     "exception": false,
     "start_time": "2022-06-19T19:42:23.868196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rf': {'oos_score': array([0.91208248, 0.91473054, 0.93139849, 0.92554432, 0.91192949]),\n",
       "  'best_params': {'rf__regressor__max_depth': 4,\n",
       "   'rf__regressor__n_estimators': 60},\n",
       "  'best_estimator': Pipeline(steps=[('rf',\n",
       "                   TransformedTargetRegressor(regressor=RandomForestRegressor(max_depth=4,\n",
       "                                                                              min_samples_leaf=7,\n",
       "                                                                              min_samples_split=3,\n",
       "                                                                              n_estimators=60,\n",
       "                                                                              random_state=42),\n",
       "                                              transformer=MinMaxScaler()))])}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_factory = {}\n",
    "\n",
    "inner_scoring = \"neg_mean_absolute_error\"\n",
    "\n",
    "for name, estimator in zip(models, estimators):\n",
    "    print(name)\n",
    "    model_factory[name] = {}\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "        (name, TransformedTargetRegressor(regressor=estimator, transformer=MinMaxScaler()))\n",
    "    ])\n",
    "    model_params = {}\n",
    "    for hyperparam in params[name].keys():\n",
    "        model_params[f\"{name}__regressor__{hyperparam}\"] = params[name][hyperparam]\n",
    "    pipe_grid_cv = GridSearchCV(pipe, model_params, scoring=[inner_scoring], \n",
    "                       refit=Razors.simplify(param=f'{name}__regressor__n_estimators', \n",
    "                                             scoring=inner_scoring, rule=\"se\", sigma=1), \n",
    "                       cv=KFold(n_splits=5, shuffle=True, random_state=seed), n_jobs=-1)\n",
    "    pipe_grid_cv.fit(X_train, y_train.values.ravel())\n",
    "    model_factory[name]['oos_score'] = cross_val_score(pipe_grid_cv, X_test, y_test.values.ravel(), \n",
    "                                                       scoring='r2', \n",
    "                                                       cv=KFold(n_splits=5, shuffle=True, \n",
    "                                                                random_state=seed + 1))\n",
    "    model_factory[name]['best_params'] = pipe_grid_cv.best_params_\n",
    "    model_factory[name]['best_estimator'] = pipe_grid_cv.best_estimator_\n",
    "\n",
    "leaderboard = {}\n",
    "for mod in model_factory.keys():\n",
    "    leaderboard[mod] = np.mean(model_factory[mod]['oos_score'])\n",
    "\n",
    "best_estimator_name = max(leaderboard, key=leaderboard.get)\n",
    "\n",
    "best_estimator = model_factory[best_estimator_name]['best_estimator']\n",
    "\n",
    "model_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f49ef83",
   "metadata": {
    "_cell_guid": "424275f0-4842-4f8c-9144-623804168b6a",
    "_uuid": "97d22c7f-b8a9-4e0f-8184-635733fd552c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-19T19:43:11.352693Z",
     "iopub.status.busy": "2022-06-19T19:43:11.351884Z",
     "iopub.status.idle": "2022-06-19T19:43:11.354793Z",
     "shell.execute_reply": "2022-06-19T19:43:11.355222Z",
     "shell.execute_reply.started": "2022-06-19T18:51:40.635113Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.145146,
     "end_time": "2022-06-19T19:43:11.355367",
     "exception": false,
     "start_time": "2022-06-19T19:43:11.210221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rf__regressor__max_depth': 4, 'rf__regressor__n_estimators': 60}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_factory[name]['best_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "badf02d4",
   "metadata": {
    "_cell_guid": "759be8eb-545f-42c1-aa8b-7b465db135e7",
    "_uuid": "b1d45736-646e-4036-98ef-126d90fde156",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-19T19:43:11.627942Z",
     "iopub.status.busy": "2022-06-19T19:43:11.627108Z",
     "iopub.status.idle": "2022-06-19T19:43:16.017538Z",
     "shell.execute_reply": "2022-06-19T19:43:16.017937Z",
     "shell.execute_reply.started": "2022-06-19T18:51:43.197669Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 4.528989,
     "end_time": "2022-06-19T19:43:16.018089",
     "exception": false,
     "start_time": "2022-06-19T19:43:11.489100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92587911, 0.93063741, 0.93061506, 0.92976181, 0.92367142])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outer_best = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "best_estimator.fit(X_clean, y)\n",
    "\n",
    "scores = cross_val_score(best_estimator, X_clean, y, scoring='r2', cv=outer_best, n_jobs=-1, error_score='raise')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22cf490d",
   "metadata": {
    "_cell_guid": "b4965bcb-bb94-422b-99b6-4a6f29e5ad94",
    "_uuid": "aad5fc5b-78b8-4bd7-b3ca-b4097950aad0",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-19T19:43:16.298905Z",
     "iopub.status.busy": "2022-06-19T19:43:16.297982Z",
     "iopub.status.idle": "2022-06-19T19:43:16.326417Z",
     "shell.execute_reply": "2022-06-19T19:43:16.326903Z",
     "shell.execute_reply.started": "2022-06-19T18:52:31.191757Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.173077,
     "end_time": "2022-06-19T19:43:16.327052",
     "exception": false,
     "start_time": "2022-06-19T19:43:16.153975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/kaggle/working/rf_model.joblib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = (\n",
    "    f\"/kaggle/working/rf_model.joblib\"\n",
    ")\n",
    "dump(best_estimator, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91f42b4a",
   "metadata": {
    "_cell_guid": "26c18b6f-bbd2-44d7-be32-04ab3ddcf43e",
    "_uuid": "6d5556c8-1701-499c-a956-3d8b3152f27e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-19T19:43:16.619077Z",
     "iopub.status.busy": "2022-06-19T19:43:16.618250Z",
     "iopub.status.idle": "2022-06-19T19:43:16.626608Z",
     "shell.execute_reply": "2022-06-19T19:43:16.626110Z",
     "shell.execute_reply.started": "2022-06-19T18:52:33.860896Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.149391,
     "end_time": "2022-06-19T19:43:16.626734",
     "exception": false,
     "start_time": "2022-06-19T19:43:16.477343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/us-patent-phrase-to-phrase-matching/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "167dba16",
   "metadata": {
    "_cell_guid": "5798fccc-7530-4166-a31d-82295021445b",
    "_uuid": "872795a1-5df7-47e3-b646-8457869d79db",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-19T19:43:16.904377Z",
     "iopub.status.busy": "2022-06-19T19:43:16.903492Z",
     "iopub.status.idle": "2022-06-19T19:43:16.916948Z",
     "shell.execute_reply": "2022-06-19T19:43:16.916420Z",
     "shell.execute_reply.started": "2022-06-19T18:53:21.743714Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.155761,
     "end_time": "2022-06-19T19:43:16.917085",
     "exception": false,
     "start_time": "2022-06-19T19:43:16.761324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "y_pred = best_estimator.predict(pd.DataFrame(scaler.fit_transform(test[surviving_features]), columns=surviving_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8bedd726",
   "metadata": {
    "_cell_guid": "9822b0f9-7585-4c97-992d-b0b18cbcc8b0",
    "_uuid": "e87dd27c-b526-4099-80a7-680fd95e7d09",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-19T19:43:17.188591Z",
     "iopub.status.busy": "2022-06-19T19:43:17.187632Z",
     "iopub.status.idle": "2022-06-19T19:43:17.189546Z",
     "shell.execute_reply": "2022-06-19T19:43:17.190048Z",
     "shell.execute_reply.started": "2022-06-19T18:53:40.474086Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.140291,
     "end_time": "2022-06-19T19:43:17.190181",
     "exception": false,
     "start_time": "2022-06-19T19:43:17.049890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission['id'] = test['id']\n",
    "submission['score'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef06dc2c",
   "metadata": {
    "_cell_guid": "35399c7a-1c57-40db-aeac-4f6b8e9b0ece",
    "_uuid": "804eee29-db36-4b3a-9229-b78f2f05bf59",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-06-19T19:43:17.478542Z",
     "iopub.status.busy": "2022-06-19T19:43:17.475379Z",
     "iopub.status.idle": "2022-06-19T19:43:17.480117Z",
     "shell.execute_reply": "2022-06-19T19:43:17.479374Z",
     "shell.execute_reply.started": "2022-06-19T18:53:43.382686Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.156957,
     "end_time": "2022-06-19T19:43:17.480285",
     "exception": false,
     "start_time": "2022-06-19T19:43:17.323328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2863.522366,
   "end_time": "2022-06-19T19:43:21.610421",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-19T18:55:38.088055",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0439e0d50e944f5682788e7ecd2c7f15": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "06cd33ddd5514f4da8127bb4ebfbfedc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b7e2c689aa3a460baec5bed9244ad3ba",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7db601af3e4142fbae90a785422bd6fb",
       "value": 1.0
      }
     },
     "0bad629e6a7345228087420bbc74532e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1021235a62bb4e9a8899157f632949e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "1252971e16044bdfbac4c0b7091ae285": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a4e0c31aae4b472f84f2a74036ca1ca0",
        "IPY_MODEL_06cd33ddd5514f4da8127bb4ebfbfedc",
        "IPY_MODEL_a7d976171a514ab6b5565a7d2433bba7"
       ],
       "layout": "IPY_MODEL_72899eb285554f3aacd81b9203f1247e"
      }
     },
     "16c60fe0d4304a62a065470b02a80c99": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a69db6b376104c5c86fcb73d0d02a756",
        "IPY_MODEL_c05e47f06cb34110b765b40860ad5121",
        "IPY_MODEL_1bbdac82beec4d9fb3b7e45a0c5fac74"
       ],
       "layout": "IPY_MODEL_961766eef6a14123a4a6ec641bb93e4b"
      }
     },
     "1bbdac82beec4d9fb3b7e45a0c5fac74": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6cde85c2f4aa4bdc95c99e087f5b5125",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_ffe26040c49a4184a0f6443dac347663",
       "value": " 36/? [00:00&lt;00:00, 811.05ex/s]"
      }
     },
     "1bdfce6fe26a4cf1880d5b1edefd51f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1e59e02ac8c64d38aac4abba53237da8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "29baea198a6b4326bab8da007cc51205": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "30231cfd99254b9295993e0a931d7514": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3f01371212f942efba781bbb33ef51d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9cd6caddf38546e896308ccdc48a3eae",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_4090dfad9a60497c9131cdfbfa4b6490",
       "value": ""
      }
     },
     "4090dfad9a60497c9131cdfbfa4b6490": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4c699b531b4d424c9cb43d03cced09b2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "55a6624cf4ef43b9a471674188b65278": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "62f8e184b1e244c89dff8bddeb0c5df6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ebee2b064e924e9891c7019d8e67c3e2",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_d78c90c8f6c4429799de990fcb24068a",
       "value": " 18236/? [00:09&lt;00:00, 1851.90ex/s]"
      }
     },
     "6cde85c2f4aa4bdc95c99e087f5b5125": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "72899eb285554f3aacd81b9203f1247e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7db601af3e4142fbae90a785422bd6fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "90908b03314d48f4b114ef9ee159316c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "961766eef6a14123a4a6ec641bb93e4b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "961bdc6a28f347f3b80e15d06754d243": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "97401ef8206d4b7ba4edb1ce431408cc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9978d995fa694bf88e969a0536b49720": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4c699b531b4d424c9cb43d03cced09b2",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_db4bb2cd73c1429a931b9d3159490884",
       "value": " 18236/? [00:05&lt;00:00, 3390.16ex/s]"
      }
     },
     "99d7d1b3f8104f9e9ef7cdc800cbcb13": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b2bc1957a8944338bf3f50e851c6a3fc",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_b6edc8d52e2c4d33a08773bea275fd4e",
       "value": ""
      }
     },
     "9cd6caddf38546e896308ccdc48a3eae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a4e0c31aae4b472f84f2a74036ca1ca0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_30231cfd99254b9295993e0a931d7514",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_961bdc6a28f347f3b80e15d06754d243",
       "value": ""
      }
     },
     "a69db6b376104c5c86fcb73d0d02a756": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0439e0d50e944f5682788e7ecd2c7f15",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_1bdfce6fe26a4cf1880d5b1edefd51f9",
       "value": ""
      }
     },
     "a7d976171a514ab6b5565a7d2433bba7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_90908b03314d48f4b114ef9ee159316c",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_1e59e02ac8c64d38aac4abba53237da8",
       "value": " 36/? [00:00&lt;00:00, 760.97ex/s]"
      }
     },
     "aa3f3e1fe08a445f82cbe0205108b97a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3f01371212f942efba781bbb33ef51d7",
        "IPY_MODEL_b9c2b8ca197848f6b6d9136d07b030a3",
        "IPY_MODEL_9978d995fa694bf88e969a0536b49720"
       ],
       "layout": "IPY_MODEL_55a6624cf4ef43b9a471674188b65278"
      }
     },
     "b2bc1957a8944338bf3f50e851c6a3fc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b6edc8d52e2c4d33a08773bea275fd4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b7a91d0554aa4e27be64cb8259d7312e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1021235a62bb4e9a8899157f632949e3",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0bad629e6a7345228087420bbc74532e",
       "value": 1.0
      }
     },
     "b7e2c689aa3a460baec5bed9244ad3ba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "b9c2b8ca197848f6b6d9136d07b030a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dcc782b756174c268e78d64beb11cc9b",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_bdb140bdae4f4d12ac76296f9f6e3b95",
       "value": 1.0
      }
     },
     "bdb140bdae4f4d12ac76296f9f6e3b95": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c05e47f06cb34110b765b40860ad5121": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dfac56bcd9264cd5a3f20566becf2bd7",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_29baea198a6b4326bab8da007cc51205",
       "value": 1.0
      }
     },
     "d78c90c8f6c4429799de990fcb24068a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "db4bb2cd73c1429a931b9d3159490884": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "dcc782b756174c268e78d64beb11cc9b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "dfac56bcd9264cd5a3f20566becf2bd7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "ebee2b064e924e9891c7019d8e67c3e2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f648d78736584f9a85e71932150dddd6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_99d7d1b3f8104f9e9ef7cdc800cbcb13",
        "IPY_MODEL_b7a91d0554aa4e27be64cb8259d7312e",
        "IPY_MODEL_62f8e184b1e244c89dff8bddeb0c5df6"
       ],
       "layout": "IPY_MODEL_97401ef8206d4b7ba4edb1ce431408cc"
      }
     },
     "ffe26040c49a4184a0f6443dac347663": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc\nimport glob\nimport spacy\nimport nltk\nimport random\nimport itertools\nimport torch\nimport unicodedata\nimport datasets, transformers\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom yellowbrick.model_selection import FeatureImportances\nfrom nltk.corpus import stopwords, wordnet\nfrom joblib import dump\nimport scipy as sp\nfrom scipy import stats\nfrom itertools import groupby\nfrom joblib import parallel_backend\nfrom sklearn import linear_model, decomposition\nfrom collections import OrderedDict\nfrom operator import itemgetter\nfrom sklearn import metrics\nfrom joblib import Parallel, delayed\nfrom transformers import TrainingArguments, Trainer, AutoModelForSequenceClassification, AutoTokenizer\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, FunctionTransformer, OneHotEncoder, LabelEncoder\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.compose import TransformedTargetRegressor\nfrom sklearn.ensemble import RandomForestRegressor, IsolationForest\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.model_selection import GridSearchCV, cross_validate, cross_val_score, train_test_split, KFold\nfrom sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin, clone, RegressorMixin\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import r2_score\nfrom spacy.tokenizer import Tokenizer\nfrom typing import List\nfrom spacy.lang import char_classes\nfrom spacy.symbols import ORTH\nfrom spacy.tokenizer import Tokenizer\nfrom spacy.util import compile_prefix_regex, compile_infix_regex, compile_suffix_regex\nfrom spacy.language import Language\nfrom spacy.lang.char_classes import CONCAT_QUOTES, LIST_ELLIPSES, LIST_ICONS, ALPHA, ALPHA_LOWER, ALPHA_UPPER\n# from scispacy.abbreviation import AbbreviationDetector\nfrom spacy.pipeline import EntityRecognizer\n\ntry:\n    from sklearn.utils._testing import ignore_warnings\nexcept:\n    from sklearn.utils.testing import ignore_warnings\nfrom sklearn.exceptions import ConvergenceWarning\n\n%env TOKENIZERS_PARALLELISM=true\n\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"_uuid":"a942c950-ef86-481e-9bdd-4fc8ac222320","_cell_guid":"62ad6f3d-b227-4aaf-93bb-ca4860556fd2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T22:50:24.360928Z","iopub.execute_input":"2022-06-20T22:50:24.361187Z","iopub.status.idle":"2022-06-20T22:50:30.778808Z","shell.execute_reply.started":"2022-06-20T22:50:24.361158Z","shell.execute_reply":"2022-06-20T22:50:30.777939Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"env: TOKENIZERS_PARALLELISM=true\n","output_type":"stream"}]},{"cell_type":"code","source":"INPUT_DIR = '../input/us-patent-phrase-to-phrase-matching/'\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T22:50:30.780228Z","iopub.execute_input":"2022-06-20T22:50:30.780898Z","iopub.status.idle":"2022-06-20T22:50:30.786466Z","shell.execute_reply.started":"2022-06-20T22:50:30.780859Z","shell.execute_reply":"2022-06-20T22:50:30.785717Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"nlp = spacy.load('en_core_web_lg')\n# nlp.add_pipe(\"abbreviation_detector\")\nre_token_match = spacy.tokenizer._get_regex_pattern(nlp.Defaults.token_match)","metadata":{"_uuid":"561bcb8c-31c6-4e52-b925-97112600781b","_cell_guid":"147479a7-c7c8-472f-bfdd-2c560020546b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T22:51:11.265008Z","iopub.execute_input":"2022-06-20T22:51:11.265445Z","iopub.status.idle":"2022-06-20T22:51:13.255112Z","shell.execute_reply.started":"2022-06-20T22:51:11.265406Z","shell.execute_reply":"2022-06-20T22:51:13.254438Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.simplefilter('ignore')\n\npd.set_option('display.precision', 4)\n# pd.set_option('display.max_rows', 500)\n# pd.set_option('display.max_columns', 500)\n# pd.set_option('display.width', 1000)\n\ncm = sns.light_palette('green', as_cmap=True)\nprops_param = \"color:white; font-weight:bold; background-color:green;\"\n\nCUSTOM_SEED = 42\nCUSTOM_BATCH = 24\n\n# Stopwords and infixes\nADDITIONAL_STOPWORDS = ['one or more', 'a', 'needn', 'a', 'not', 'able', 'never', 'about', 'neednâ€™t', 'accordance', 'now', 'often', 'above', 'no', 'according', 'of', 'mentioned', 'others', 'after', 'nor', 'all', 'on', 'accordingly', 'otherwise', 'again', 'not', 'also', 'onto', 'across', 'overall', 'against', 'now', 'an', 'or', 'along', 'rather', 'ain', 'o', 'and', 'other', 'already', 'remarkably', 'all', 'of', 'another', 'particularly', 'alternatively', 'significantly', 'am', 'off', 'are', 'preferably', 'always', 'simply', 'an', 'on', 'as', 'preferred', 'among', 'sometimes', 'and', 'once', 'at', 'present', 'and/or', 'specifically', 'any', 'only', 'be', 'provide', 'anything', 'straight', 'are', 'or', 'because', 'provided', 'anywhere', 'forward', 'aren', 'other', 'been', 'provides', 'better', 'substantially', 'arenâ€™t', 'our', 'being', 'relatively', 'disclosure', 'thereafter', 'as', 'ours', 'by', 'respectively', 'due', 'therebetween', 'at', 'ourselves', 'claim', 'said', 'easily', 'therefor', 'be', 'out', 'comprises', 'comprising', 'should', 'easy', 'therefrom', 'because', 'over', 'since', 'e.g', 'therein', 'been', 'own', 'could', 'some', 'either', 'thereinto', 'before', 're', 'described', 'such', 'elsewhere', 'thereon', 'being', 's', 'desired', 'suitable', 'enough', 'therethrough', 'below', 'same', 'do', 'than', 'especially', 'therewith', 'between', 'shan', 'does', 'that', 'essentially', 'together', 'both', 'shanâ€™t', 'each', 'the', 'et', 'al', 'toward', 'but', 'she', 'embodiment', 'their', 'etc', 'towards', 'by', 'sheâ€™s', 'fig', 'then', 'eventually', 'typical', 'can', 'should', 'figs', 'there', 'excellent', 'upon', 'couldn', 'shouldâ€™ve', 'for', 'thereby', 'finally', 'via', 'couldnâ€™t', 'shouldn', 'from', 'therefore', 'furthermore', 'vice', 'versa', 'd', 'shouldnâ€™t', 'further', 'thereof', 'good', 'whatever', 'did', 'so', 'generally', 'thereto', 'hence', 'whereas', 'didn', 'some', 'had', 'these', 'he/she', 'whereat', 'didnâ€™t', 'such', 'has', 'they', 'him/her', 'wherever', 'do', 't', 'have', 'this', 'his/her', 'whether', 'does', 'than', 'having', 'those', 'ie', 'whose', 'doesn', 'that', 'herein', 'thus', 'ii', 'within', 'doesnâ€™t', 'thatâ€™ll', 'however', 'to', 'iii', 'without', 'doing', 'the', 'if', 'use', 'instead', 'yet', 'don', 'their', 'in', 'various', 'later', 'donâ€™t', 'theirs', 'into', 'was', 'like', 'down', 'them', 'invention', 'were', 'little', 'during', 'themselves', 'is', 'what', 'many', 'each', 'there', 'it', 'when', 'may', 'few', 'these', 'its', 'where', 'meanwhile', 'for', 'they', 'means', 'whereby', 'might', 'from', 'this', 'wherein', 'moreover', 'further', 'those', 'which', 'much', 'had', 'through', 'while', 'must', 'hadn', 'to', 'who', 'hadnâ€™t', 'too', 'will', 'has', 'under', 'with', 'hasn', 'until', 'Would', 'hasnâ€™t', 'up', 'have', 've', 'haven', 'very', 'havenâ€™t', 'was', 'having', 'wasn', 'he', 'wasnâ€™t', 'her', 'we', 'here', 'were', 'hers', 'weren', 'herself', 'werenâ€™t', 'him', 'what', 'himself', 'when', 'his', 'where', 'how', 'which', 'i', 'while', 'if', 'who', 'in', 'whom', 'into', 'why', 'is', 'will', 'isn', 'with', 'isnâ€™t', 'won', 'it', 'wonâ€™t', 'itâ€™s', 'wouldn', 'its', 'wouldnâ€™t', 'itself', 'y', 'just', 'you', 'll', 'youâ€™d', 'm', 'youâ€™ll', 'ma', 'youâ€™re', 'me', 'youâ€™ve', 'mightn', 'your', 'mightnâ€™t', 'yours', 'more', 'yourself', 'most', 'yourselves', 'mustn', 'mustnâ€™t', 'my', 'myself']\n\npuncts = ['\\u200d','?', '....','..','...','', ',', '.', '\"', ':', ')', '(', '-', '!', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '*', '+', '\\\\',\n    'â€¢', '~', 'Â£', 'Â·', '_', '{', '}', 'Â©', '^', 'Â®', '`',  '<', 'â†’', 'Â°', 'â‚¬', 'â„¢', 'â€º',  'â™¥', 'â†', 'Ã—', 'Â§', 'â€³', 'â€²', 'Ã‚', 'â–ˆ',\n    'Â½', 'Ã ', 'â€¦', 'â€œ', 'â˜…', 'â€', 'â€“', 'â—', 'Ã¢', 'â–º', 'âˆ’', 'Â¢', 'Â²', 'Â¬', 'â–‘', 'Â¶', 'â†‘', 'Â±', 'Â¿', 'â–¾', 'â•', 'Â¦', 'â•‘', 'â€•', 'Â¥', 'â–“',\n    'â€”', 'â€¹', 'â”€', 'â–’', 'ï¼š', 'Â¼', 'âŠ•', 'â–¼', 'â–ª', 'â€ ', 'â– ', 'â€™', 'â–€', 'Â¨', 'â–„', 'â™«', 'â˜†', 'Ã©', 'Â¯', 'â™¦', 'Â¤', 'â–²', 'Ã¨', 'Â¸', 'Â¾',\n    'Ãƒ', 'â‹…', 'â€˜', 'âˆž', 'âˆ™', 'ï¼‰', 'â†“', 'ã€', 'â”‚', 'ï¼ˆ', 'Â»', 'ï¼Œ', 'â™ª', 'â•©', 'â•š', 'Â³', 'ãƒ»', 'â•¦', 'â•£', 'â•”', 'â•—', 'â–¬', 'â¤', 'Ã¯', 'Ã˜',\n    'Â¹', 'â‰¤', 'â€¡', 'âˆš', '!','ðŸ…°','ðŸ…±']\n\nABBREVIATIONS: List[str] = [\n    \"sec.\",\n    \"secs.\",\n    \"Sec.\",\n    \"Secs.\",\n    \"fig.\",\n    \"figs.\",\n    \"Fig.\",\n    \"Figs.\",\n    \"eq.\",\n    \"eqs.\",\n    \"Eq.\",\n    \"Eqs.\",\n    \"no.\",\n    \"nos.\",\n    \"No.\",\n    \"Nos.\",\n    \"al.\",\n    \"gen.\",\n    \"sp.\",\n    \"nov.\",\n]\n\nstopwords = nltk.corpus.stopwords.words('english') + ADDITIONAL_STOPWORDS\n\ndef combined_rule_prefixes() -> List[str]:\n    \"\"\"Helper function that returns the prefix pattern for the tokenizer.\n    It is a helper function to accomodate spacy tests that only test\n    prefixes.\n    \"\"\"\n    # add lookahead assertions for brackets (may not work properly for unbalanced brackets)\n    prefix_punct = char_classes.PUNCT.replace(\"|\", \" \")\n    prefix_punct = prefix_punct.replace(r\"\\(\", r\"\\((?![^\\(\\s]+\\)\\S+)\")\n    prefix_punct = prefix_punct.replace(r\"\\[\", r\"\\[(?![^\\[\\s]+\\]\\S+)\")\n    prefix_punct = prefix_punct.replace(r\"\\{\", r\"\\{(?![^\\{\\s]+\\}\\S+)\")\n\n    prefixes = (\n        [\"Â§\", \"%\", \"=\", r\"\\+\"]\n        + char_classes.split_chars(prefix_punct)\n        + char_classes.LIST_ELLIPSES\n        + char_classes.LIST_QUOTES\n        + char_classes.LIST_CURRENCY\n        + char_classes.LIST_ICONS\n    )\n    return prefixes\n\ndef customize_tokenizer(nlp: Language) -> Tokenizer:\n    \"\"\"Creates a custom tokenizer on top of spaCy's default tokenizer. The\n    intended use of this function is to replace the tokenizer in a spaCy\n    pipeline like so:\n         nlp = spacy.load(\"some_spacy_model\")\n         nlp.tokenizer = combined_rule_tokenizer(nlp)\n    @param nlp: a loaded spaCy model\n    \"\"\"\n    # remove the first hyphen to prevent tokenization of the normal hyphen\n    hyphens = char_classes.HYPHENS.replace(\"-|\", \"\", 1)\n\n    infixes = (\n        char_classes.LIST_ELLIPSES\n        + char_classes.LIST_ICONS\n        + [\n            r\"Ã—\",  # added this special x character to tokenize it separately\n            r\"(?<=[0-9])[+\\-\\*^](?=[0-9-])\",\n            r\"(?<=[{al}])\\.(?=[{au}])\".format(\n                al=char_classes.ALPHA_LOWER, au=char_classes.ALPHA_UPPER\n            ),\n            r\"(?<=[{a}]),(?=[{a}])\".format(a=char_classes.ALPHA),\n            r'(?<=[{a}])[?\";:=,.]*(?:{h})(?=[{a}])'.format(\n                a=char_classes.ALPHA, h=hyphens\n            ),\n            # removed / to prevent tokenization of /\n            r'(?<=[{a}\"])[:<>=](?=[{a}])'.format(a=char_classes.ALPHA),\n        ]\n    )\n\n    prefixes = combined_rule_prefixes()\n\n    # add the last apostrophe\n    quotes = char_classes.LIST_QUOTES.copy() + [\"â€™\"]\n\n    # add lookbehind assertions for brackets (may not work properly for unbalanced brackets)\n    suffix_punct = char_classes.PUNCT.replace(\"|\", \" \")\n    # These lookbehinds are commented out because they are variable width lookbehinds, and as of spacy 2.1,\n    # spacy uses the re package instead of the regex package. The re package does not support variable width\n    # lookbehinds. Hacking spacy internals to allow us to use the regex package is doable, but would require\n    # creating our own instance of the language class, with our own Tokenizer class, with the from_bytes method\n    # using the regex package instead of the re package\n    # suffix_punct = suffix_punct.replace(r\"\\)\", r\"(?<!\\S+\\([^\\)\\s]+)\\)\")\n    # suffix_punct = suffix_punct.replace(r\"\\]\", r\"(?<!\\S+\\[[^\\]\\s]+)\\]\")\n    # suffix_punct = suffix_punct.replace(r\"\\}\", r\"(?<!\\S+\\{[^\\}\\s]+)\\}\")\n\n    suffixes = (\n        char_classes.split_chars(suffix_punct)\n        + char_classes.LIST_ELLIPSES\n        + quotes\n        + char_classes.LIST_ICONS\n        + [\"'s\", \"'S\", \"â€™s\", \"â€™S\", \"â€™s\", \"â€™S\"]\n        + [\n            r\"(?<=[0-9])\\+\",\n            r\"(?<=Â°[FfCcKk])\\.\",\n            r\"(?<=[0-9])(?:{})\".format(char_classes.CURRENCY),\n            # this is another place where we used a variable width lookbehind\n            # so now things like 'H3g' will be tokenized as ['H3', 'g']\n            # previously the lookbehind was (^[0-9]+)\n            r\"(?<=[0-9])(?:{u})\".format(u=char_classes.UNITS),\n            r\"(?<=[0-9{}{}(?:{})])\\.\".format(\n                char_classes.ALPHA_LOWER, r\"%Â²\\-\\)\\]\\+\", \"|\".join(quotes)\n            ),\n            # add |\\d to split off the period of a sentence that ends with 1D.\n            r\"(?<=[{a}|\\d][{a}])\\.\".format(a=char_classes.ALPHA_UPPER),\n        ]\n    )\n\n    infix_re = compile_infix_regex(infixes)\n    prefix_re = compile_prefix_regex(prefixes)\n    suffix_re = compile_suffix_regex(suffixes)\n\n    # Update exclusions to include these abbreviations so the period is not split off\n    exclusions = {\n        abbreviation: [{ORTH: abbreviation}] for abbreviation in ABBREVIATIONS\n    }\n    tokenizer_exceptions = nlp.Defaults.tokenizer_exceptions.copy()\n    tokenizer_exceptions.update(exclusions)\n\n    tokenizer = Tokenizer(\n        nlp.vocab,\n        tokenizer_exceptions,\n        prefix_search=prefix_re.search,\n        suffix_search=suffix_re.search,\n        infix_finditer=infix_re.finditer,\n        token_match=nlp.tokenizer.token_match,  # type: ignore\n    )\n    return tokenizer\n\nnlp.tokenizer = customize_tokenizer(nlp)","metadata":{"_uuid":"8238d081-b92b-434a-8b85-4329fbcb278f","_cell_guid":"ba02c35f-90b7-4f80-905b-0391f96f2347","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T22:52:23.007666Z","iopub.execute_input":"2022-06-20T22:52:23.007921Z","iopub.status.idle":"2022-06-20T22:52:23.264745Z","shell.execute_reply.started":"2022-06-20T22:52:23.007892Z","shell.execute_reply":"2022-06-20T22:52:23.263981Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"table = {\n'A': 'Human Necessities',\n'B': 'Operations and Transport',\n'C': 'Chemistry and Metallurgy',\n'D': 'Textiles',\n'E': 'Fixed Constructions',\n'F': 'Mechanical Engineering',\n'G': 'Physics',\n'H': 'Electricity',\n'Y': 'Emerging Cross-Sectional Technologies'\n}","metadata":{"_uuid":"102bd6d4-c302-4fde-995f-decacdbce996","_cell_guid":"d97adb40-4f30-487b-aa22-c14a50be0f17","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T22:38:50.541563Z","iopub.status.idle":"2022-06-20T22:38:50.542177Z","shell.execute_reply.started":"2022-06-20T22:38:50.541938Z","shell.execute_reply":"2022-06-20T22:38:50.541961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_from_list(x, stuff_to_remove) -> list:\n    for item in stuff_to_remove:\n        # Making sure to iterate through the entire token\n        for i,token in enumerate(x):\n            if item == token:\n                del x[i]\n    return x\n\ndef Remove_Duplicates(text_in):\n    return re.sub(r\"\\b(\\w+)(?:\\W\\1\\b)+\", r\"\\1\", text_in, flags=re.IGNORECASE)\n\n\ndef remove_consecutive_nums(text):\n    # Remove any chunks of consecutive numbers\n    number_strings = re.findall(r'\\d+[ \\t]\\d+', text)\n    ind_num_strings = []\n    for j in number_strings:\n        x = [int(i) for i in j.split()]\n        ind_num_strings.append(x)\n\n    flat_num_list = [item for sublist in ind_num_strings for item in sublist]\n\n    for i in flat_num_list:\n        j=re.sub(r'\\d+','',str(i))\n        text = text.replace(str(i),j)\n    return text\n\n\ndef basic_clean(text_list, infixes, stopwords):\n    \"\"\"\n    A simple function to clean up the data. All the words that\n    are not designated as a stop word is then lemmatized after\n    encoding and basic regex parsing are performed.\n    \"\"\"\n\n    text_list_clean = []\n    for text in text_list:\n        text = re.sub(r'[\\)\\(\\.\\,\\;\\\\\\?\\&\\%\\!\\+\\-]', '', re.sub(r'[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f\\x7f-\\xff\\xad\\x0c6Â§\\\\\\Â£\\Ã‚*_<>\"\"âŽ«â€¢{}Î“~]', ' ', str(' '.join(re.split('\\s*-\\s*', text)))))\n        if len(text.split(\"  \")) > 1000:\n            text = \" \".join([\"\".join(w.split(\" \")) if len(w.split(' '))>1 else w for w in text.split(\"  \")])\n        text_list_clean.append([i for i in remove_from_list(re.sub('\\s+', ' ', re.sub('\\s\\s+', ' ', re.sub('\\s+\\s+', ' ', Remove_Duplicates(re.sub(r\"\\b(?=[mdclxvii])m{0,4}(cm|cd|d?c{0,3})(xc|xl|l?x{0,3})([ii]x|[ii]v|v?[ii]{0,3})\\b\\.?\", '', (unicodedata.normalize('NFKD', re.sub(' +', ' ', re.sub(r\"\\s+\\s+\",\" \", re.sub(r\"\\\\,\",\",\", re.sub(r\" \\,\",\",\", re.sub(r\"\\\\.\",\".\", re.sub(r\" \\.\",\".\", re.sub(r\"\\(\\s+\\)\",\"\", re.sub(r\"\\(\\)\",\"\", re.sub(r\" \\)\",\"\", re.sub(r\"\\( \",\"\", remove_consecutive_nums(re.sub(r\"\\s+\",\" \", re.sub(r\"([A-z])\\- ([A-z])\", r\"\\1\\2\", re.sub(r'\\s', ' ', text)).replace('\\'','').replace('. .', '.').replace('\\'',''))))))))))))).lower())\n        .encode('ascii', 'ignore')\n        .decode('utf-8', 'ignore')\n        .lower())))))).split(), puncts) if not i.isdigit() or i in stopwords])\n        del text\n\n    return '. '.join(x.strip().capitalize() for x in '. '.join(' '.join([word for word in sent]) for sent in text_list_clean).split('.')) + '.'\n\n\ndef get_cpc_texts():\n    \"\"\"\n    Function taken from Y Nakama's notebook:\n    https://www.kaggle.com/code/yasufuminakama/pppm-deberta-v3-large-baseline-w-w-b-train\n    \"\"\"\n    contexts = []\n    pattern = '[A-Z]\\d+'\n    for file_name in os.listdir('cpc-data/CPCSchemeXML202105'):\n        result = re.findall(pattern, file_name)\n        if result:\n            contexts.append(result)\n    contexts = sorted(set(sum(contexts, [])))\n    results = {}\n    for cpc in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'Y']:\n        with open(f'cpc-data/CPCTitleList202202/cpc-section-{cpc}_20220201.txt') as f:\n            s = f.read()\n        pattern = f'{cpc}\\t\\t.+'\n        result = re.findall(pattern, s)\n        cpc_result = result[0].lstrip(pattern)\n        for context in [c for c in contexts if c[0] == cpc]:\n            pattern = f'{context}\\t\\t.+'\n            result = re.findall(pattern, s)\n            results[context] = cpc_result + \". \" + result[0].lstrip(pattern)\n    return results","metadata":{"_uuid":"d75199e1-2d90-4925-8857-fc15aa97eee9","_cell_guid":"4047b6a7-5604-4be7-ab3c-b02d7ea18512","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T22:38:50.543470Z","iopub.status.idle":"2022-06-20T22:38:50.544095Z","shell.execute_reply.started":"2022-06-20T22:38:50.543854Z","shell.execute_reply":"2022-06-20T22:38:50.543880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/us-patent-phrase-to-phrase-matching/train.csv')\ntest = pd.read_csv('../input/us-patent-phrase-to-phrase-matching/test.csv')","metadata":{"_uuid":"f3ffefe0-201e-4750-b043-c76da4bab192","_cell_guid":"4ec8f13b-391a-48c7-a86c-c35526506b16","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T22:38:50.545303Z","iopub.status.idle":"2022-06-20T22:38:50.545902Z","shell.execute_reply.started":"2022-06-20T22:38:50.545673Z","shell.execute_reply":"2022-06-20T22:38:50.545696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['general_context'] = train['context'].apply(lambda x: table[x[0].upper()])\ntest['general_context'] = test['context'].apply(lambda x: table[x[0].upper()])\n\ntrain = pd.concat([train, pd.get_dummies(train['general_context'])], axis=1)\ntest = pd.concat([test, pd.get_dummies(test['general_context'])], axis=1)\n\ncpc_texts = torch.load(f\"../input/cpc-texts/cpc_texts.pth\")\ntrain['context_text'] = train['context'].map(cpc_texts)\ntest['context_text'] = test['context'].map(cpc_texts)\n\ntrain['section'] = train['context'].astype(str).str[0]\ntrain['classes'] = train['context'].astype(str).str[1:]\ntest['section'] = test['context'].astype(str).str[0]\ntest['classes'] = test['context'].astype(str).str[1:]\n\ntrain['anchor_len'] = train['anchor'].str.split().str.len()\ntrain['target_len'] = train['target'].str.split().str.len()\n\ntest['anchor_len'] = test['anchor'].str.split().str.len()\ntest['target_len'] = test['target'].str.split().str.len()\n\ntrain['len_diff'] = np.abs(train['target_len'] - train['anchor_len'])\ntest['len_diff'] = np.abs(test['target_len'] - test['anchor_len'])\n\ntrain['num_anchor_stops'] = test['anchor'].str.count('|'.join(stopwords))\ntest['num_anchor_stops'] = test['anchor'].str.count('|'.join(stopwords))\ntrain['num_target_stops'] = test['target'].str.count('|'.join(stopwords))\ntest['num_target_stops'] = test['target'].str.count('|'.join(stopwords))\n\ntrain['dataset'] = 'train'\ntest['dataset'] = 'test'","metadata":{"_uuid":"c05280f7-90a1-49ce-9868-0f03aaff67b9","_cell_guid":"cd06dd39-bba8-4aec-a547-23fe3ec4a32e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T22:38:50.547093Z","iopub.status.idle":"2022-06-20T22:38:50.547722Z","shell.execute_reply.started":"2022-06-20T22:38:50.547492Z","shell.execute_reply":"2022-06-20T22:38:50.547516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.loc[~train.index.duplicated(keep='first')]\ntest = test.loc[~test.index.duplicated(keep='first')]\ntrain = train.reset_index(drop=True)\ntest = test.reset_index(drop=True)\ndf_all = train.append(test)","metadata":{"_uuid":"75838474-5f7f-4ee7-8362-9bc40a853e1b","_cell_guid":"ad17e21f-04a5-43a8-87f3-91a9694e6806","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T22:38:50.548876Z","iopub.status.idle":"2022-06-20T22:38:50.549502Z","shell.execute_reply.started":"2022-06-20T22:38:50.549256Z","shell.execute_reply":"2022-06-20T22:38:50.549295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_all['anchor_parsed'] = df_all['anchor'].apply(\n    lambda text:\n        \" \".join(\n            token.lemma_ for token in nlp(text)\n                if token.lemma_.lower() not in stopwords and token.is_alpha\n        )\n)\n\ndf_all['target_parsed'] = df_all['target'].apply(\n    lambda text:\n        \" \".join(\n            token.lemma_ for token in nlp(text)\n                if token.lemma_.lower() not in stopwords and token.is_alpha\n        )\n)","metadata":{"_uuid":"f5aeb6b5-62a0-434d-a5d8-b09d05215ac0","_cell_guid":"a2ded0a7-ecc0-4625-9798-b1af9d525c51","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T22:38:50.550660Z","iopub.status.idle":"2022-06-20T22:38:50.551292Z","shell.execute_reply.started":"2022-06-20T22:38:50.551034Z","shell.execute_reply":"2022-06-20T22:38:50.551068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_all['anchor_nlp'] = df_all.anchor.apply(lambda series: nlp(series))\ndf_all['target_nlp'] = df_all.target.apply(lambda series: nlp(series))\n\ndf_all['anchor_VERB'] = df_all.anchor_nlp.apply(lambda series: len([token for token in series if token.pos_ == 'VERB']))\ndf_all['target_VERB'] = df_all.target_nlp.apply(lambda series: len([token for token in series if token.pos_ == 'VERB']))\n\ndf_all['anchor_NOUN'] = df_all.anchor_nlp.apply(lambda series: len([token for token in series if token.pos_ == 'NOUN']))\ndf_all['target_NOUN'] = df_all.target_nlp.apply(lambda series: len([token for token in series if token.pos_ == 'NOUN']))\n\ndf_all['anchor_DET'] = df_all.anchor_nlp.apply(lambda series: len([token for token in series if token.pos_ == 'DET']))\ndf_all['target_DET'] = df_all.target_nlp.apply(lambda series: len([token for token in series if token.pos_ == 'DET']))\n\ndf_all['anchor_ADJ'] = df_all.anchor_nlp.apply(lambda series: len([token for token in series if token.pos_ == 'ADJ']))\ndf_all['target_ADJ'] = df_all.target_nlp.apply(lambda series: len([token for token in series if token.pos_ == 'ADJ']))\n\ndf_all['anchor_in_target'] = df_all.apply(lambda x: x[\"anchor_parsed\"] in x[\"target\"], axis=1)\ndf_all['target_in_anchor'] = df_all.apply(lambda x: x[\"target_parsed\"] in x[\"anchor\"], axis=1)","metadata":{"_uuid":"eb33244d-de87-45ba-90b9-541980ce4093","_cell_guid":"4fb10eae-003e-4f2e-a769-dc9f85dc81a1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T22:38:50.552465Z","iopub.status.idle":"2022-06-20T22:38:50.553084Z","shell.execute_reply.started":"2022-06-20T22:38:50.552844Z","shell.execute_reply":"2022-06-20T22:38:50.552869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sims = df_all[[\"anchor_parsed\", \"target_parsed\"]]\nsimilarityValue = []\nfor i in range(sims.count()[0]):\n    sentence_1 = nlp(sims.iloc[i][0])\n    sentence_2 = nlp(sims.iloc[i][1])\n    similarityValue.append(sentence_1.similarity(sentence_2))\n\ndf_all['anchor_target_cos_sim'] = similarityValue\n\ntrain = df_all.loc[df_all['dataset'] == 'train']\ntest = df_all.loc[df_all['dataset'] == 'test']","metadata":{"_uuid":"00148a52-36d5-48d5-8600-875693a2172c","_cell_guid":"ca883518-7c1f-4112-978b-5a0dac56b352","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-20T22:38:50.554281Z","iopub.status.idle":"2022-06-20T22:38:50.554877Z","shell.execute_reply.started":"2022-06-20T22:38:50.554649Z","shell.execute_reply":"2022-06-20T22:38:50.554673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['text'] = train['anchor'] + '[SEP]' + train['target'] + '[SEP]' + train['context_text']\ntest['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]' + test['context_text']","metadata":{"execution":{"iopub.status.busy":"2022-06-20T22:38:50.556094Z","iopub.status.idle":"2022-06-20T22:38:50.556721Z","shell.execute_reply.started":"2022-06-20T22:38:50.556495Z","shell.execute_reply":"2022-06-20T22:38:50.556520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transformers","metadata":{}},{"cell_type":"code","source":"class CFG:\n    input_path = '../input/us-patent-phrase-to-phrase-matching/'\n    model_path = [\n                  '../input/deberta-v3-5folds/',\n                  '../input/xlm-roberta-large-5folds/',\n                  '../input/electra-upppm/electra_upppm/',\n                 ]\n    model_num = 3\n    num_fold = 5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_test(unit):\n        return {\n        **tokenizer(unit['text'])\n    }\n    \nfor i in range (CFG.model_num):   \n    tokenizer = AutoTokenizer.from_pretrained(f'{CFG.model_path[i]}fold0')\n    test_ds = datasets.Dataset.from_pandas(test[['text']])\n    test_ds = test_ds.map(process_test)\n\n    predictions_test = []\n    for fold in range(CFG.num_fold):        \n        trainer = Trainer(\n                AutoModelForSequenceClassification.from_pretrained(f'{CFG.model_path[i]}fold{fold}', \n                                                                   num_labels=5, problem_type='multi_label_classification'),\n                tokenizer=tokenizer,\n            )\n        \n        predictions_test.append(trainer.predict(test_ds).predictions)\n        del trainer\n        gc.collect()\n        \n    test[f\"predictions_{CFG.model_path[i].split('/')[-2]}\"] = np.average(predictions_test, axis=0)\n\n    del tokenizer, test_ds\n    gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_valid(unit):\n        return {\n        **tokenizer(unit['text'])\n    }\n    \nfor i in range (CFG.model_num):   \n    tokenizer = AutoTokenizer.from_pretrained(f'{CFG.model_path[i]}fold0')\n    valid_ds = datasets.Dataset.from_pandas(train[['text']])\n    valid_ds = valid_ds.map(process_valid)\n\n    predictions_valid = []\n    for fold in range(CFG.num_fold):        \n        trainer = Trainer(\n                AutoModelForSequenceClassification.from_pretrained(f'{CFG.model_path[i]}fold{fold}', \n                                                                   num_labels=1),\n                tokenizer=tokenizer,\n            )\n        \n        predictions_valid.append(trainer.predict(valid_ds).predictions)\n        del trainer\n        gc.collect()\n\n    train[f\"predictions_{CFG.model_path[i].split('/')[-2]}\"] = np.average(predictions_valid, axis=0)\n\n    del tokenizer, valid_ds\n    gc.collect()","metadata":{"_uuid":"f7e15874-fc82-4243-9a91-34cb24ab04bc","_cell_guid":"aa4a21af-9cd7-4051-be66-6f9837acf680","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train.drop(columns=['id', 'anchor', 'target', 'context', 'score', 'general_context', 'context_text',\n       'section', 'classes', 'dataset', 'anchor_parsed', 'target_parsed', 'anchor_nlp', 'target_nlp', 'text']).astype('float32')\ny = train['score']","metadata":{"_uuid":"c6e4839b-efc5-4086-a590-2f7b7b65e8de","_cell_guid":"46bdead9-8e05-4907-bc48-78c2be20cb9a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def slice_by_corr(X, r_min=0):\n    # Create correlation matrix\n    corr_matrix = X.corr().abs()\n\n    # Select upper triangle of correlation matrix\n    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n\n    # Find features with correlation greater than r_min\n    return X[[column for column in upper.columns if any(upper[column] > r_min)]]\n\ndef variance_inflation_factor(X, exog_idx):\n    clf = LinearRegression(fit_intercept=True)\n    sub_X = np.delete(np.nan_to_num(X), exog_idx, axis=1)\n    sub_y = X[:, exog_idx][np.newaxis].T\n    sub_clf = clf.fit(sub_X, sub_y)\n    return 1 / (1 - r2_score(sub_y, sub_clf.predict(sub_X)))\n\nclass ReduceVIF(BaseEstimator, TransformerMixin):\n\n    def __init__(self, thresh=10.0, nthreads=4, r_min=0, obs=250):\n        self.thresh = thresh\n        self.nthreads = nthreads\n        self.r_min = r_min\n        self.obs = obs\n        \n    def fit(self, X):\n        self.X = X\n        return self\n\n    def transform(self, X):\n        return ReduceVIF.calculate_vif(X, self.thresh, \n                                       self.nthreads, \n                                       self.r_min, \n                                       self.obs)\n\n    @staticmethod\n    def calculate_vif(X, thresh=10.0, nthreads=16, r_min=0, obs=250):        \n        dropped = True\n        vif_cols = []\n        X_vif_candidates = slice_by_corr(X, r_min)\n        X_vif_candidates = X_vif_candidates.sample(n=obs)\n        while dropped:\n            variables = X_vif_candidates.columns\n            dropped = False\n            with Parallel(n_jobs=nthreads, backend='threading') as parallel:\n                vif = parallel(\n                    delayed(variance_inflation_factor)(\n                        np.asarray(X_vif_candidates[variables].values),\n                        X_vif_candidates.columns.get_loc(var)) for var in \n                    X_vif_candidates.columns)\n            max_vif = max(vif)\n            if max_vif > thresh:\n                maxloc = vif.index(max_vif)\n                print(f'Dropping {X_vif_candidates.columns[maxloc]} with vif={max_vif}')\n                vif_cols.append(X_vif_candidates.columns.tolist()[maxloc])\n                X_vif_candidates = X_vif_candidates.drop(\n                    [X_vif_candidates.columns.tolist()[maxloc]], axis=1)\n                dropped = True\n        \n        if len(vif_cols) > 0:\n            return X.drop(columns=vif_cols), vif_cols\n        else:\n            return X, vif_cols\n\n    \ndef preprocess_x_y(X, nodrop_columns=[],\n                   var_thr=0.95, remove_multi=True,\n                   standardize=True, standardizer='mm',\n                   std_dev=3, vif_thr=10, missingness_thr=0.50,\n                   zero_thr=0.99, nthreads=4):\n    from colorama import Fore, Style\n\n    # Replace all near-zero with zeros\n    # Drop excessively sparse columns with >zero_thr zeros\n    if zero_thr > 0:\n        X = X.apply(lambda x: np.where(np.abs(x) < 0.000001, 0, x))\n        X_tmp = X.T.loc[(X == 0).sum() < (float(zero_thr)) * X.shape[0]].T\n\n        if len(nodrop_columns) > 0:\n            X = pd.concat([X_tmp, X[[i for i in X.columns if i in\n                                     nodrop_columns and i not in\n                                     X_tmp.columns]]], axis=1)\n        else:\n            X = X_tmp\n        del X_tmp\n\n        if X.empty or len(X.columns) < 5:\n            print(f\"\\n\\n{Fore.RED}Empty feature-space (Zero Columns): \"\n                  f\"{X}{Style.RESET_ALL}\\n\\n\")\n            return X\n\n    # Remove columns with excessive missing values\n    X = X.dropna(thresh=len(X) * (1 - missingness_thr), axis=1)\n    if X.empty:\n        print(f\"\\n\\n{Fore.RED}Empty feature-space (missingness): \"\n              f\"{X}{Style.RESET_ALL}\\n\\n\")\n        return X\n\n    # Apply a simple imputer (note that this assumes extreme cases of\n    # missingness have already been addressed). The SimpleImputer is better\n    # for smaller datasets, whereas the IterativeImputer performs best on\n    # larger sets.\n\n    # from sklearn.experimental import enable_iterative_imputer\n    # from sklearn.impute import IterativeImputer\n    # imp = IterativeImputer(random_state=0, sample_posterior=True)\n    # X = pd.DataFrame(imp.fit_transform(X, y), columns=X.columns)\n    imp1 = SimpleImputer()\n    X = pd.DataFrame(imp1.fit_transform(X.astype('float32')),\n                     columns=X.columns)\n\n    # Standardize X\n    if standardize is True:\n        if standardizer == 'ss':\n            scaler = StandardScaler()\n        else:\n            scaler = MinMaxScaler()\n        X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n\n    # Remove low-variance columns\n    sel = VarianceThreshold(threshold=(var_thr*(1-var_thr)))\n    sel.fit(X)\n    if len(nodrop_columns) > 0:\n        good_var_cols = X.columns[np.concatenate(\n            [sel.get_support(indices=True), np.array([X.columns.get_loc(c)\n                                                      for c in\n                                                      nodrop_columns if\n                                                      c in X])])]\n    else:\n        good_var_cols = X.columns[sel.get_support(indices=True)]\n    low_var_cols = [i for i in X.columns if i not in list(good_var_cols)]\n    if len(low_var_cols) > 0:\n        print(f\"Dropping {low_var_cols} for low variance...\")\n    X = X[good_var_cols]\n\n    if X.empty:\n        print(f\"\\n\\n{Fore.RED}Empty feature-space (low-variance): \"\n              f\"{X}{Style.RESET_ALL}\\n\\n\")\n        return X\n        \n    # Remove multicollinear columns\n    if remove_multi is True:\n        try:\n            rvif = ReduceVIF(thresh=vif_thr, nthreads=nthreads)\n            X = rvif.fit_transform(X)[0]\n            if X.empty or len(X.columns) < 5:\n                print(f\"\\n\\n{Fore.RED}Empty feature-space \"\n                      f\"(multicollinearity): \"\n                      f\"{X}{Style.RESET_ALL}\\n\\n\")\n                return X\n        except:\n            print(f\"\\n\\n{Fore.RED}Empty feature-space (multicollinearity): \"\n                  f\"{X}{Style.RESET_ALL}\\n\\n\")\n            return X\n\n    print(f\"\\nX: {X}\\n\")\n    print(f\"Features: {list(X.columns)}\\n\")\n    return X\n\n\nclass Razors(object):\n    \"\"\"\n    Razors is a callable refit option for `GridSearchCV` whose aim is to\n    balance model complexity and cross-validated score in the spirit of the\n    \"one standard error\" rule of Breiman et al. (1984), which showed that\n    the tuning hyperparameter associated with the best performing model may be\n    prone to overfit. To help mitigate this risk, we can instead instruct\n    gridsearch to refit the highest performing 'parsimonious' model, as defined\n    using simple statistical rules (e.g. standard error (`sigma`),\n    percentile (`eta`), or significance level (`alpha`)) to compare\n    distributions of model performance across folds. Importantly, this\n    strategy assumes that the grid of multiple cross-validated models\n    can be principly ordered from simplest to most complex with respect to some\n    target hyperparameter of interest. To use the razors suite, supply\n    the `simplify` function partial of the `Razors` class as a callable\n    directly to the `refit` argument of `GridSearchCV`.\n\n    Parameters\n    ----------\n    cv_results : dict of numpy(masked) ndarrays\n        See attribute cv_results_ of `GridSearchCV`.\n    scoring : str\n        Refit scoring metric.\n    param : str\n        Parameter whose complexity will be optimized.\n    rule : str\n        Rule for balancing model complexity with performance.\n        Options are 'se', 'percentile', and 'ranksum'. Default is 'se'.\n    sigma : int\n        Number of standard errors tolerance in the case that a standard error\n        threshold is used to filter outlying scores across folds. Required if\n        `rule`=='se'. Default is 1.\n    eta : float\n        Percentile tolerance in the case that a percentile threshold\n        is used to filter outlier scores across folds. Required if\n        `rule`=='percentile'. Default is 0.68.\n    alpha : float\n        An alpha significance level in the case that wilcoxon rank sum\n        hypothesis testing is used to filter outlying scores across folds.\n        Required if `rule`=='ranksum'. Default is 0.05.\n\n    References\n    ----------\n    Breiman, Friedman, Olshen, and Stone. (1984) Classification and Regression\n    Trees. Wadsworth.\n\n    Notes\n    -----\n    Here, 'simplest' is defined by the complexity of the model as influenced by\n    some user-defined target parameter (e.g. number of components, number of\n    estimators, polynomial degree, cost, scale, number hidden units, weight\n    decay, number of nearest neighbors, L1/L2 penalty, etc.).\n\n    The callable API accordingly assumes that the `params` attribute of\n    `cv_results_` 1) contains the indicated hyperparameter (`param`) of\n    interest, and 2) contains a sequence of values (numeric, boolean, or\n    categorical) that are ordered from least to most complex.\n    \"\"\"\n    __slots__ = ('cv_results', 'param', 'param_complexity', 'scoring',\n                 'rule', 'greater_is_better',\n                 '_scoring_funcs', '_scoring_dict',\n                 '_n_folds', '_splits', '_score_grid',\n                 '_cv_means', '_sigma', '_eta', '_alpha')\n\n    def __init__(\n            self,\n            cv_results_,\n            param,\n            scoring,\n            rule,\n            sigma=1,\n            eta=0.95,\n            alpha=0.01,\n    ):\n        import sklearn.metrics\n\n        self.cv_results = cv_results_\n        self.param = param\n        self.scoring = scoring\n        self.rule = rule\n        self._scoring_funcs = [\n            met\n            for met in sklearn.metrics.__all__\n            if (met.endswith(\"_score\")) or (met.endswith(\"_error\"))\n        ]\n        # Set _score metrics to True and _error metrics to False\n        self._scoring_dict = dict(\n            zip(\n                self._scoring_funcs,\n                [met.endswith(\"_score\") for met in self._scoring_funcs],\n            )\n        )\n        self.greater_is_better = self._check_scorer()\n        self._n_folds = len(list(set([i.split('_')[0] for i in\n                                     list(self.cv_results.keys()) if\n                                     i.startswith('split')])))\n        # Extract subgrid corresponding to the scoring metric of interest\n        self._splits = [i for i in list(self.cv_results.keys()) if\n                        i.endswith(f\"test_{self.scoring}\") and\n                        i.startswith('split')]\n        self._score_grid = np.vstack([self.cv_results[cv] for cv in\n                                      self._splits]).T\n        self._cv_means = np.array(np.nanmean(self._score_grid, axis=1))\n        self._sigma = sigma\n        self._eta = eta\n        self._alpha = alpha\n\n    def _check_scorer(self):\n        \"\"\"\n        Check whether the target refit scorer is negated. If so, adjust\n        greater_is_better accordingly.\n        \"\"\"\n\n        if (\n                self.scoring not in self._scoring_dict.keys()\n                and f\"{self.scoring}_score\" not in self._scoring_dict.keys()\n        ):\n            if self.scoring.startswith(\"neg_\"):\n                self.greater_is_better = True\n            else:\n                raise NotImplementedError(f\"Scoring metric {self.scoring} not \"\n                                          f\"recognized.\")\n        else:\n            self.greater_is_better = [\n                value for key, value in self._scoring_dict.items() if\n                self.scoring in key][0]\n        return self.greater_is_better\n\n    def _best_low_complexity(self):\n        \"\"\"\n        Balance model complexity with cross-validated score.\n\n        Return\n        ------\n        int\n            Index of a model that has the lowest complexity but its test score\n            is the highest on average across folds as compared to other models\n            that are equally likely to occur.\n        \"\"\"\n\n        # Check parameter(s) whose complexity we seek to restrict\n        if not any(self.param in x for x in\n                   self.cv_results[\"params\"][0].keys()):\n            raise KeyError(f\"Parameter {self.param} not found in cv grid.\")\n        else:\n            hyperparam = [\n                i for i in self.cv_results[\"params\"][0].keys() if\n                i.endswith(self.param)][0]\n\n        # Select low complexity threshold based on specified evaluation rule\n        if self.rule == \"se\":\n            if not self._sigma:\n                raise ValueError(\n                    \"For `se` rule, the tolerance \"\n                    \"(i.e. `_sigma`) parameter cannot be null.\"\n                )\n            l_cutoff, h_cutoff = self.call_standard_error()\n        elif self.rule == \"percentile\":\n            if not self._eta:\n                raise ValueError(\n                    \"For `percentile` rule, the tolerance \"\n                    \"(i.e. `_eta`) parameter cannot be null.\"\n                )\n            l_cutoff, h_cutoff = self.call_percentile()\n        elif self.rule == \"ranksum\":\n            if not self._alpha:\n                raise ValueError(\n                    \"For `ranksum` rule, the alpha-level \"\n                    \"(i.e. `_alpha`) parameter cannot be null.\"\n                )\n            l_cutoff, h_cutoff = self.call_rank_sum_test()\n        else:\n            raise NotImplementedError(f\"{self.rule} is not a valid \"\n                                      f\"rule of RazorCV.\")\n\n        self.cv_results[f\"param_{hyperparam}\"].mask = np.where(\n            (self._cv_means >= float(l_cutoff)) &\n            (self._cv_means <= float(h_cutoff)),\n            True, False)\n\n        if np.sum(self.cv_results[f\"param_{hyperparam}\"].mask) == 0:\n            print(f\"\\nLow: {l_cutoff}\")\n            print(f\"High: {h_cutoff}\")\n            print(f\"{self._cv_means}\")\n            print(f\"hyperparam: {hyperparam}\\n\")\n            raise ValueError(\"No valid grid columns remain within the \"\n                             \"boundaries of the specified razor\")\n\n        highest_surviving_rank = np.nanmin(\n            self.cv_results[f\"rank_test_{self.scoring}\"][\n                self.cv_results[f\"param_{hyperparam}\"].mask])\n\n        # print(f\"Highest surviving rank: {highest_surviving_rank}\\n\")\n\n        return np.flatnonzero(np.isin(\n            self.cv_results[f\"rank_test_{self.scoring}\"],\n            highest_surviving_rank))[0]\n\n    def call_standard_error(self):\n        \"\"\"\n        Returns the simplest model whose performance is within `sigma`\n        standard errors of the average highest performing model.\n        \"\"\"\n\n        # Estimate the standard error across folds for each column of the grid\n        cv_se = np.array(np.nanstd(self._score_grid, axis=1) /\n                         np.sqrt(self._n_folds))\n\n        # Determine confidence interval\n        if self.greater_is_better:\n            best_score_idx = np.nanargmax(self._cv_means)\n            h_cutoff = self._cv_means[best_score_idx] + cv_se[best_score_idx]\n            l_cutoff = self._cv_means[best_score_idx] - cv_se[best_score_idx]\n        else:\n            best_score_idx = np.nanargmin(self._cv_means)\n            h_cutoff = self._cv_means[best_score_idx] - cv_se[best_score_idx]\n            l_cutoff = self._cv_means[best_score_idx] + cv_se[best_score_idx]\n\n        return l_cutoff, h_cutoff\n\n    def call_rank_sum_test(self):\n        \"\"\"\n        Returns the simplest model whose paired performance across folds is\n        insignificantly different from the average highest performing,\n        at a predefined `alpha` level of significance.\n        \"\"\"\n\n        from scipy.stats import wilcoxon\n        import itertools\n\n        if self.greater_is_better:\n            best_score_idx = np.nanargmax(self._cv_means)\n        else:\n            best_score_idx = np.nanargmin(self._cv_means)\n\n        # Perform signed Wilcoxon rank sum test for each pair combination of\n        # columns against the best average score column\n        tests = [pair for pair in list(itertools.combinations(range(\n            self._score_grid.shape[0]), 2)) if best_score_idx in pair]\n\n        p_dict = {}\n        for i, test in enumerate(tests):\n            p_dict[i] = wilcoxon(self._score_grid[test[0], :],\n                                 self._score_grid[test[1], :])[1]\n\n        # Sort and prune away significant tests\n        p_dict = {k: v for k, v in sorted(p_dict.items(),\n                                          key=lambda item: item[1]) if\n                  v > self._alpha}\n\n        # Flatten list of tuples, remove best score index, and take the\n        # lowest and highest remaining bounds\n        tests = [j for j in list(set(list(sum([tests[i] for i in\n                                               list(p_dict.keys())],\n                                              ())))) if j != best_score_idx]\n        if self.greater_is_better:\n            h_cutoff = self._cv_means[\n                np.nanargmin(self.cv_results[\n                                 f\"rank_test_{self.scoring}\"][tests])]\n            l_cutoff = self._cv_means[\n                np.nanargmax(self.cv_results[\n                                 f\"rank_test_{self.scoring}\"][tests])]\n        else:\n            h_cutoff = self._cv_means[\n                np.nanargmax(self.cv_results[\n                                 f\"rank_test_{self.scoring}\"][tests])]\n            l_cutoff = self._cv_means[\n                np.nanargmin(self.cv_results[\n                                 f\"rank_test_{self.scoring}\"][tests])]\n\n        return l_cutoff, h_cutoff\n\n\n    def call_percentile(self):\n        \"\"\"\n        Returns the simplest model whose performance is within the `eta`\n        percentile of the average highest performing model.\n        \"\"\"\n\n        # Estimate the indicated percentile, and its inverse, across folds for\n        # each column of the grid\n        perc_cutoff = np.nanpercentile(self._score_grid,\n                                       [100 * self._eta,\n                                        100 - 100 * self._eta], axis=1)\n\n        # Determine bounds of the percentile interval\n        if self.greater_is_better:\n            best_score_idx = np.nanargmax(self._cv_means)\n            h_cutoff = perc_cutoff[0, best_score_idx]\n            l_cutoff = perc_cutoff[1, best_score_idx]\n        else:\n            best_score_idx = np.nanargmin(self._cv_means)\n            h_cutoff = perc_cutoff[0, best_score_idx]\n            l_cutoff = perc_cutoff[1, best_score_idx]\n\n        return l_cutoff, h_cutoff\n\n    @staticmethod\n    def simplify(param, scoring, rule='se', sigma=1, eta=0.68, alpha=0.01):\n        \"\"\"\n        Callable to be run as `refit` argument of `GridsearchCV`.\n\n        Parameters\n        ----------\n        param : str\n            Parameter with the largest influence on model complexity.\n        scoring : str\n            Refit scoring metric.\n        sigma : int\n            Number of standard errors tolerance in the case that a standard\n            error threshold is used to filter outlying scores across folds.\n            Only applicable if `rule`=='se'. Default is 1.\n        eta : float\n            Acceptable percent tolerance in the case that a percentile\n            threshold is used. Only applicable if `rule`=='percentile'.\n            Default is 0.68.\n        alpha : float\n            Alpha-level to use for signed wilcoxon rank sum testing.\n            Only applicable if `rule`=='ranksum'. Default is 0.01.\n        \"\"\"\n        from functools import partial\n\n        def razor_pass(\n                cv_results_, param, scoring, rule, sigma, alpha, eta\n        ):\n            rcv = Razors(cv_results_, param, scoring, rule=rule,\n                         sigma=sigma, alpha=alpha, eta=eta)\n            return rcv._best_low_complexity()\n\n        return partial(\n            razor_pass,\n            param=param,\n            scoring=scoring,\n            rule=rule,\n            sigma=sigma,\n            alpha=alpha,\n            eta=eta,\n        )\n\ndef divide_df(df_all,train_len):\n    return df_all.loc[:train_len-1], df_all.loc[train_len:].drop('target',axis=1)\n\ndef concat_df(train_data, test_data):\n    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)","metadata":{"_uuid":"07381d69-4197-43f3-9ab8-44ec5d3e32cc","_cell_guid":"cb66bafc-95ec-44f7-871c-b4d825158399","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocess = FunctionTransformer(preprocess_x_y)\nX_clean = preprocess.fit_transform(X=X)\nsurviving_features = list(X_clean.columns)","metadata":{"_uuid":"babc5fa2-709b-49bd-9ad2-f9753ac17822","_cell_guid":"2712eda4-f76c-499e-acae-26b8f5b934c8","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed=42\nX_train, X_test, y_train, y_test = train_test_split(X_clean, y, random_state=seed)\n\nX_train = X_train.reset_index(drop=True)\ny_train = pd.DataFrame(y_train).reset_index(drop=True)\n\nX_train = X_train.head(10000)\ny_train = y_train.head(10000)\n\nX_test = X_test.reset_index(drop=True)\ny_test = pd.DataFrame(y_test).reset_index(drop=True)\n\nX_test = X_test.head(2000)\ny_test = y_test.head(2000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = [\n            'rf'\n         ]\n\nestimators = [\n        RandomForestRegressor(random_state=42, min_samples_split=3)\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params={models[0]: {\n                    'max_depth': [3, 4],\n                    'n_estimators': [50, 75, 100],\n                    'min_samples_leaf': [3, 5, 7]\n                   }\n       }","metadata":{"_uuid":"4c5a010d-7329-46a0-b904-4af8032697d6","_cell_guid":"3cb8358e-126b-4b91-ae6f-ba4d70386c2a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_factory = {}\n\ninner_scoring = \"neg_mean_absolute_error\"\n\nfor name, estimator in zip(models, estimators):\n    print(name)\n    model_factory[name] = {}\n    \n    pipe = Pipeline([\n        (name, TransformedTargetRegressor(regressor=estimator, transformer=MinMaxScaler()))\n    ])\n    model_params = {}\n    for hyperparam in params[name].keys():\n        model_params[f\"{name}__regressor__{hyperparam}\"] = params[name][hyperparam]\n    pipe_grid_cv = GridSearchCV(pipe, model_params, scoring=[inner_scoring],\n                       refit=Razors.simplify(param=f'{name}__regressor__n_estimators',\n                                             scoring=inner_scoring, rule=\"se\", sigma=1),\n                       cv=KFold(n_splits=5, shuffle=True, random_state=seed), n_jobs=-1)\n    pipe_grid_cv.fit(X_train, y_train.values.ravel())\n    model_factory[name]['oos_score'] = cross_val_score(pipe_grid_cv, X_test, y_test.values.ravel(),\n                                                       scoring='r2',\n                                                       cv=KFold(n_splits=10, shuffle=True,\n                                                                random_state=seed + 1))\n    model_factory[name]['best_params'] = pipe_grid_cv.best_params_\n    model_factory[name]['best_estimator'] = pipe_grid_cv.best_estimator_\n\nleaderboard = {}\nfor mod in model_factory.keys():\n    leaderboard[mod] = np.mean(model_factory[mod]['oos_score'])\n\nbest_estimator_name = max(leaderboard, key=leaderboard.get)\n\nbest_estimator = model_factory[best_estimator_name]['best_estimator']\n\nmodel_factory","metadata":{"_uuid":"8036d58b-7c10-49bf-a571-6a0567094cff","_cell_guid":"47c28da5-8a5f-4096-a8f2-38710f345686","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_factory[name]['best_params']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outer_best = KFold(n_splits=10, shuffle=True, random_state=seed)\n\nbest_estimator.fit(X_clean, y)\n\nscores = cross_val_score(best_estimator, X_clean, y, scoring='r2', cv=outer_best, n_jobs=-1, error_score='raise')\nscores","metadata":{"_uuid":"b1d45736-646e-4036-98ef-126d90fde156","_cell_guid":"759be8eb-545f-42c1-aa8b-7b465db135e7","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"viz = FeatureImportances(best_estimator.named_steps['rf'].regressor_)\nviz.fit(X_clean, y)\nviz.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = (\n    f\"/kaggle/working/rf_model.joblib\"\n)\ndump(best_estimator, model_path)","metadata":{"_uuid":"aad5fc5b-78b8-4bd7-b3ca-b4097950aad0","_cell_guid":"b4965bcb-bb94-422b-99b6-4a6f29e5ad94","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('../input/us-patent-phrase-to-phrase-matching/sample_submission.csv')","metadata":{"_uuid":"6d5556c8-1701-499c-a956-3d8b3152f27e","_cell_guid":"26c18b6f-bbd2-44d7-be32-04ab3ddcf43e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler()\ny_pred = best_estimator.predict(pd.DataFrame(scaler.fit_transform(test[surviving_features]), columns=surviving_features))","metadata":{"_uuid":"872795a1-5df7-47e3-b646-8457869d79db","_cell_guid":"5798fccc-7530-4166-a31d-82295021445b","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['id'] = test['id']\nsubmission['score'] = y_pred","metadata":{"_uuid":"e87dd27c-b526-4099-80a7-680fd95e7d09","_cell_guid":"9822b0f9-7585-4c97-992d-b0b18cbcc8b0","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"_uuid":"804eee29-db36-4b3a-9229-b78f2f05bf59","_cell_guid":"35399c7a-1c57-40db-aeac-4f6b8e9b0ece","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.append(\"../input/tez-lib/\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-23T04:58:50.381138Z","iopub.execute_input":"2022-03-23T04:58:50.381508Z","iopub.status.idle":"2022-03-23T04:58:50.408953Z","shell.execute_reply.started":"2022-03-23T04:58:50.381426Z","shell.execute_reply":"2022-03-23T04:58:50.408348Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\n\nimport pandas as pd\nimport torch.nn as nn\n\nfrom scipy import stats\nfrom tez import Tez, TezConfig\nfrom tez.callbacks import EarlyStopping\nfrom transformers import AutoModel, AutoConfig, AutoTokenizer, get_linear_schedule_with_warmup","metadata":{"execution":{"iopub.status.busy":"2022-03-23T04:58:50.410242Z","iopub.execute_input":"2022-03-23T04:58:50.410548Z","iopub.status.idle":"2022-03-23T04:58:57.432914Z","shell.execute_reply.started":"2022-03-23T04:58:50.410514Z","shell.execute_reply":"2022-03-23T04:58:57.432177Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class args:\n    model = \"../input/anferico-bert-for-patents/\"\n    max_len = 32\n    accumulation_steps = 1\n    batch_size = 64\n    epochs = 5\n    learning_rate = 2e-5","metadata":{"execution":{"iopub.status.busy":"2022-03-23T04:58:57.434297Z","iopub.execute_input":"2022-03-23T04:58:57.434556Z","iopub.status.idle":"2022-03-23T04:58:57.438848Z","shell.execute_reply.started":"2022-03-23T04:58:57.434520Z","shell.execute_reply":"2022-03-23T04:58:57.438176Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class PhraseDataset:\n    def __init__(self, anchor, target, context, tokenizer, max_len):\n        self.anchor = anchor\n        self.target = target\n        self.context = context\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.anchor)\n\n    def __getitem__(self, item):\n        anchor = self.anchor[item]\n        context = self.context[item]\n        target = self.target[item]\n\n        encoded_text = self.tokenizer.encode_plus(\n            f\"{context} {anchor}\",\n            target,\n            padding=\"max_length\",\n            max_length=self.max_len,\n            truncation=True,\n        )\n        input_ids = encoded_text[\"input_ids\"]\n        attention_mask = encoded_text[\"attention_mask\"]\n        token_type_ids = encoded_text[\"token_type_ids\"]\n\n        return {\n            \"ids\": torch.tensor(input_ids, dtype=torch.long),\n            \"mask\": torch.tensor(attention_mask, dtype=torch.long),\n            \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n        }","metadata":{"execution":{"iopub.status.busy":"2022-03-23T04:59:27.883007Z","iopub.execute_input":"2022-03-23T04:59:27.883268Z","iopub.status.idle":"2022-03-23T04:59:27.892426Z","shell.execute_reply.started":"2022-03-23T04:59:27.883237Z","shell.execute_reply":"2022-03-23T04:59:27.891604Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class PhraseModel(nn.Module):\n    def __init__(self, model_name):\n        super().__init__()\n        self.model_name = model_name\n\n        config = AutoConfig.from_pretrained(model_name)\n        config.update(\n            {\n                \"output_hidden_states\": True,\n                \"add_pooling_layer\": True,\n                \"num_labels\": 1,\n            }\n        )\n        self.transformer = AutoModel.from_pretrained(model_name, config=config)\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n        self.output = nn.Linear(config.hidden_size, 1)\n\n    def forward(self, ids, mask, token_type_ids):\n        transformer_out = self.transformer(ids, mask, token_type_ids)\n        output = transformer_out.pooler_output\n        output = self.dropout(output)\n        output = self.output(output)\n        return output, 0, {}","metadata":{"execution":{"iopub.status.busy":"2022-03-23T04:59:41.614228Z","iopub.execute_input":"2022-03-23T04:59:41.614502Z","iopub.status.idle":"2022-03-23T04:59:41.623971Z","shell.execute_reply.started":"2022-03-23T04:59:41.614465Z","shell.execute_reply":"2022-03-23T04:59:41.623162Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/us-patent-phrase-to-phrase-matching/test.csv\")\n\ncontext_mapping = {\n    \"A\": \"Human Necessities\",\n    \"B\": \"Operations and Transport\",\n    \"C\": \"Chemistry and Metallurgy\",\n    \"D\": \"Textiles\",\n    \"E\": \"Fixed Constructions\",\n    \"F\": \"Mechanical Engineering\",\n    \"G\": \"Physics\",\n    \"H\": \"Electricity\",\n    \"Y\": \"Emerging Cross-Sectional Technologies\",\n}\n\ndf.context = df.context.apply(lambda x: context_mapping[x[0]])\n\ntokenizer = AutoTokenizer.from_pretrained(args.model)\ntest_dataset = PhraseDataset(\n    anchor=df.anchor.values,\n    target=df.target.values,\n    context=df.context.values,\n    tokenizer=tokenizer,\n    max_len=args.max_len,\n)\n\nmodel = PhraseModel(model_name=args.model)\nmodel = Tez(model)\nmodel_path = \"../input/uspppm-tez-models/model_f0.bin\"\nconfig = TezConfig(\n    test_batch_size=64,\n    device=\"cuda\",\n)\nmodel.load(model_path, weights_only=True, config=config)\n\npreds_iter = model.predict(test_dataset)\nfinal_preds = []\nfor preds in preds_iter:\n    preds[preds < 0] = 0\n    preds[preds > 1] = 1\n    final_preds.extend(preds.ravel().tolist())","metadata":{"execution":{"iopub.status.busy":"2022-03-23T04:59:55.547148Z","iopub.execute_input":"2022-03-23T04:59:55.547420Z","iopub.status.idle":"2022-03-23T05:00:31.394428Z","shell.execute_reply.started":"2022-03-23T04:59:55.547387Z","shell.execute_reply":"2022-03-23T05:00:31.393554Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at ../input/anferico-bert-for-patents/ were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"sample_submission = pd.read_csv(\"../input/us-patent-phrase-to-phrase-matching/sample_submission.csv\")\nsample_submission.score = final_preds\nsample_submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:32:15.566189Z","iopub.execute_input":"2022-03-22T14:32:15.566505Z","iopub.status.idle":"2022-03-22T14:32:15.578832Z","shell.execute_reply.started":"2022-03-22T14:32:15.566475Z","shell.execute_reply":"2022-03-22T14:32:15.578114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-22T14:32:17.137127Z","iopub.execute_input":"2022-03-22T14:32:17.137444Z","iopub.status.idle":"2022-03-22T14:32:17.147124Z","shell.execute_reply.started":"2022-03-22T14:32:17.137413Z","shell.execute_reply":"2022-03-22T14:32:17.146431Z"},"trusted":true},"execution_count":null,"outputs":[]}]}